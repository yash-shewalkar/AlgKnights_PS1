

























SQL statement syntax — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SQL statement syntax 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language



 SQL statement syntax 
SQL statement syntax






ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes



















SQL statement syntax#
This section describes the syntax for SQL statements that can be executed in
Trino.
Refer to the following sections for further details:

SQL data types and other general aspects
SQL functions and operators



ALTER MATERIALIZED VIEW
ALTER SCHEMA
ALTER TABLE
ALTER VIEW
ANALYZE
CALL
COMMENT
COMMIT
CREATE CATALOG
CREATE FUNCTION
CREATE MATERIALIZED VIEW
CREATE ROLE
CREATE SCHEMA
CREATE TABLE
CREATE TABLE AS
CREATE VIEW
DEALLOCATE PREPARE
DELETE
DENY
DESCRIBE
DESCRIBE INPUT
DESCRIBE OUTPUT
DROP CATALOG
DROP FUNCTION
DROP MATERIALIZED VIEW
DROP ROLE
DROP SCHEMA
DROP TABLE
DROP VIEW
EXECUTE
EXECUTE IMMEDIATE
EXPLAIN
EXPLAIN ANALYZE
GRANT privilege
GRANT role
INSERT
MATCH_RECOGNIZE
MERGE
PREPARE
REFRESH MATERIALIZED VIEW
RESET SESSION
RESET SESSION AUTHORIZATION
REVOKE privilege
REVOKE role
ROLLBACK
SELECT
SET PATH
SET ROLE
SET SESSION
SET SESSION AUTHORIZATION
SET TIME ZONE
SHOW CATALOGS
SHOW COLUMNS
SHOW CREATE FUNCTION
SHOW CREATE MATERIALIZED VIEW
SHOW CREATE SCHEMA
SHOW CREATE TABLE
SHOW CREATE VIEW
SHOW FUNCTIONS
SHOW GRANTS
SHOW ROLE GRANTS
SHOW ROLES
SHOW SCHEMAS
SHOW SESSION
SHOW STATS
SHOW TABLES
START TRANSACTION
TRUNCATE
UPDATE
USE
VALUES



















 Previous  Comments 



  Next  ALTER MATERIALIZED VIEW 











































SQL language — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SQL language 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions



 SQL language 
SQL language






SQL statement support


Data types


Keywords and identifiers


Comments



SQL statement syntax


Developer guide


Glossary


Appendix


Release notes



















SQL language#
Trino is an ANSI SQL compliant query engine. This standard compliance allows
Trino users to integrate their favorite data tools, including BI and ETL tools
with any underlying data source.
Trino validates and translates the received SQL statements into the necessary
operations on the connected data source.
This section provides a reference to the supported SQL data types and other
general characteristics of the SQL support of Trino.
Refer to the following sections for further details:

SQL statement and syntax reference
SQL functions and operators



SQL statement support
Globally available statements
Read operations
Write operations
Security operations
Transactions


Data types
Trino type support and mapping
Boolean
Integer
Floating-point
Exact numeric
String
Date and time
Structural
Network address
UUID
HyperLogLog
SetDigest
Quantile digest
T-Digest






Keywords and identifiers
Comments

















 Previous  Example Python UDFs 



  Next  SQL statement support 











































AI functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 AI functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate



 AI 
AI

Contents

Configuration

Providers

Anthropic

OpenAI

Ollama



Model configuration



Functions

ai_analyze_sentiment()

ai_classify()

ai_extract()

ai_fix_grammar()

ai_gen()

ai_mask()

ai_translate()







Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Configuration

Providers

Anthropic

OpenAI

Ollama



Model configuration



Functions

ai_analyze_sentiment()

ai_classify()

ai_extract()

ai_fix_grammar()

ai_gen()

ai_mask()

ai_translate()











AI functions#
The AI functions allow you to invoke a large language model (LLM) to perform
various textual tasks. Multiple LLM providers are supported, specifically
OpenAI and
Anthropic directly, and many others such as
Llama, DeepSeek, Phi, Mistral, or Gemma using Ollama.
The LLM must be provided outside Trino as an external service.

Configuration#
Because the AI functions require an external LLM service, they are not available
by default. To enable them, you must configure a catalog properties
file to register the functions invoking the configured LLM
with the specified catalog name.
Create a catalog properties file etc/catalog/llm.properties that references
the ai connector:
connector.name=ai


The AI functions are available with the ai schema name. For the preceding
example, the functions use the llm.ai catalog and schema prefix.
To avoid needing to reference the functions with their fully qualified name,
configure the sql.path SQL environment
property in the config.properties file to
include the catalog and schema prefix:
sql.path=llm.ai


Configure multiple catalogs to use the same functions with different LLM
providers. In this case, the functions must be referenced using their
fully qualified name, rather than relying on the SQL path.

Providers#
The AI functions invoke an external LLM. Access to the LLM API must be
configured in the catalog. Performance, results, and cost of all AI function
invocations are dependent on the LLM provider and the model used. You must
specify a model that is suitable for textual analysis.

AI functions provider configuration properties#





Property name
Description



ai.provider
Required name of the provider. Must be anthropic for using the
Anthropic provider or openai for OpenAI or
Ollama.

ai.anthropic.endpoint
URL for the Anthropic API endpoint. Defaults to https://api.anthropic.com.

ai.anthropic.api-key
API key value for Anthropic API access. Required with ai.provider set to
anthropic.

ai.openai.endpoint
URL for the OpenAI API or Ollama endpoint. Defaults to
https://api.openai.com. Set to the URL endpoint for Ollama when using
models via Ollama and add any string for the ai.openai.api-key.

ai.openai.api-key
API key value for OpenAI API access. Required with ai.provider set to
openai. Required and ignored with Ollama use.



The AI functions connect to the providers over HTTP. Configure the connection
using the ai prefix with the HTTP client properties.
The following sections show minimal configurations for Anthropic, OpenAI, and
Ollama use.

Anthropic#
The Anthropic provider uses the Anthropic API
to perform the AI functions:
ai.provider=anthropic
ai.model=claude-3-5-sonnet-latest
ai.anthropic.api-key=xxx


Use secrets to avoid actual API key values in the catalog
properties files.


OpenAI#
The OpenAI provider uses the OpenAI API
to perform the AI functions:
ai.provider=openai
ai.model=gpt-4o-mini
ai.openai.api-key=xxx


Use secrets to avoid actual API key values in the catalog
properties files.


Ollama#
The OpenAI provider can be used with Ollama
to perform the AI functions, as Ollama is compatible with the OpenAI API:
ai.provider=openai
ai.model=llama3.3
ai.openai.endpoint=http://localhost:11434
ai.openai.api-key=none


An API key must be specified, but is ignored by Ollama.
Ollama allows you to use Llama, DeepSeek, Phi, Mistral, Gemma and other
models on a self-hosted deployment or from a vendor.



Model configuration#
All providers support a number of different models. You must configure at least
one model to use for the AI function. The model must be suitable for textual
analysis. Provider and model choice impacts performance, results, and cost of
all AI functions.
Costs vary with AI function used based on the implementation prompt size, the
length of the input, and the length of the output from the model, because model
providers charge based input and output tokens.
Optionally configure different models from the same provider for each functions
as an override:

AI function model configuration properties#





Property name
Description



ai.model
Required name of the model. Valid names vary by provider. Model must be
suitable for textual analysis. The model is used for all functions, unless a
specific model is configured for a function as override.

ai.analyze-sentiment.model
Optional override to use a different model for ai_analyze_sentiment().

ai.classify.model
Optional override to use a different model for ai_classify().

ai.extract.model
Optional override to use a different model for ai_extract().

ai.fix-grammar.model
Optional override to use a different model for ai_fix_grammar().

ai.generate.model
Optional override to use a different model for ai_gen().

ai.mask.model
Optional override to use a different model for ai_mask().

ai.translate.model
Optional override to use a different model for ai_translate().






Functions#
The following functions are available in each catalog configured with the ai
connector under the ai schema and use the configured LLM provider:


ai_analyze_sentiment(text) → varchar#
Analyzes the sentiment of the input text.
The sentiment result is positive, negative, neutral, or mixed.
SELECT ai_analyze_sentiment('I love Trino');
-- positive





ai_classify(text, labels) → varchar#
Classifies the input text according to the provided labels.
SELECT ai_classify('Buy now!', ARRAY['spam', 'not spam']);
-- spam





ai_extract(text, labels)#
Extracts values for the provided labels from the input text.
SELECT ai_extract('John is 25 years old', ARRAY['name', 'age']);
-- {name=John, age=25}





ai_fix_grammar(text) → varchar#
Corrects grammatical errors in the input text.
SELECT ai_fix_grammar('I are happy. What you doing?');
-- I am happy. What are you doing?





ai_gen(prompt) → varchar#
Generates text based on the input prompt.
SELECT ai_gen('Describe Trino in a few words');
-- Distributed SQL query engine.





ai_mask(text, labels) → varchar#
Masks the values for the provided labels in the input text by replacing them
with the text [MASKED].
SELECT ai_mask(
    'Contact me at 555-1234 or visit us at 123 Main St.',
    ARRAY['phone', 'address']);
-- Contact me at [MASKED] or visit us at [MASKED].





ai_translate(text, language) → varchar#
Translates the input text to the specified language.
SELECT ai_translate('I like coffee', 'es');
-- Me gusta el café

SELECT ai_translate('I like coffee', 'zh-TW');
-- 我喜歡咖啡



















 Previous  Aggregate functions 



  Next  Array functions and operators 











































Aggregate functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Aggregate functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic



 Aggregate 
Aggregate

Contents

Ordering during aggregation

Filtering during aggregation

General aggregate functions

any_value()

arbitrary()

array_agg()

avg()

bool_and()

bool_or()

checksum()

count()

count_if()

every()

geometric_mean()

listagg()

max()

max_by()

min()

min_by()

sum()



Bitwise aggregate functions

bitwise_and_agg()

bitwise_or_agg()

bitwise_xor_agg()



Map aggregate functions

histogram()

map_agg()

map_union()

multimap_agg()



Approximate aggregate functions

approx_distinct()

approx_most_frequent()

approx_percentile()

numeric_histogram()



Statistical aggregate functions

corr()

covar_pop()

covar_samp()

kurtosis()

regr_intercept()

regr_slope()

skewness()

stddev()

stddev_pop()

stddev_samp()

variance()

var_pop()

var_samp()



Lambda aggregate functions

reduce_agg()







AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Ordering during aggregation

Filtering during aggregation

General aggregate functions

any_value()

arbitrary()

array_agg()

avg()

bool_and()

bool_or()

checksum()

count()

count_if()

every()

geometric_mean()

listagg()

max()

max_by()

min()

min_by()

sum()



Bitwise aggregate functions

bitwise_and_agg()

bitwise_or_agg()

bitwise_xor_agg()



Map aggregate functions

histogram()

map_agg()

map_union()

multimap_agg()



Approximate aggregate functions

approx_distinct()

approx_most_frequent()

approx_percentile()

numeric_histogram()



Statistical aggregate functions

corr()

covar_pop()

covar_samp()

kurtosis()

regr_intercept()

regr_slope()

skewness()

stddev()

stddev_pop()

stddev_samp()

variance()

var_pop()

var_samp()



Lambda aggregate functions

reduce_agg()











Aggregate functions#
Aggregate functions operate on a set of values to compute a single result.
Except for count(), count_if(), max_by(), min_by() and
approx_distinct(), all of these aggregate functions ignore null values
and return null for no input rows or when all values are null. For example,
sum() returns null rather than zero and avg() does not include null
values in the count. The coalesce function can be used to convert null into
zero.

Ordering during aggregation#
Some aggregate functions such as array_agg() produce different results
depending on the order of input values. This ordering can be specified by writing
an ORDER BY clause within the aggregate function:
array_agg(x ORDER BY y DESC)
array_agg(x ORDER BY x, y, z)




Filtering during aggregation#
The FILTER keyword can be used to remove rows from aggregation processing
with a condition expressed using a WHERE clause. This is evaluated for each
row before it is used in the aggregation and is supported for all aggregate
functions.
aggregate_function(...) FILTER (WHERE <condition>)


A common and very useful example is to use FILTER to remove nulls from
consideration when using array_agg:
SELECT array_agg(name) FILTER (WHERE name IS NOT NULL)
FROM region;


As another example, imagine you want to add a condition on the count for Iris
flowers, modifying the following query:
SELECT species,
       count(*) AS count
FROM iris
GROUP BY species;


species    | count
-----------+-------
setosa     |   50
virginica  |   50
versicolor |   50


If you just use a normal WHERE statement you lose information:
SELECT species,
    count(*) AS count
FROM iris
WHERE petal_length_cm > 4
GROUP BY species;


species    | count
-----------+-------
virginica  |   50
versicolor |   34


Using a filter you retain all information:
SELECT species,
       count(*) FILTER (where petal_length_cm > 4) AS count
FROM iris
GROUP BY species;


species    | count
-----------+-------
virginica  |   50
setosa     |    0
versicolor |   34




General aggregate functions#


any_value(x) → [same as input]#
Returns an arbitrary non-null value x, if one exists. x can be any
valid expression. This allows you to return values from columns that are not
directly part of the aggregation, inluding expressions using these columns,
in a query.
For example, the following query returns the customer name from the name
column, and returns the sum of all total prices as customer spend. The
aggregation however uses the rows grouped by the customer identifier
custkey a required, since only that column is guaranteed to be unique:
SELECT sum(o.totalprice) as spend,
    any_value(c.name)
FROM tpch.tiny.orders o
JOIN tpch.tiny.customer c
ON o.custkey  = c.custkey
GROUP BY c.custkey;
ORDER BY spend;





arbitrary(x) → [same as input]#
Returns an arbitrary non-null value of x, if one exists. Identical to
any_value().



array_agg(x) → array<[same as input]>#
Returns an array created from the input x elements.



avg(x) → double#
Returns the average (arithmetic mean) of all input values.



avg(time interval type) → time interval type
Returns the average interval length of all input values.



bool_and(boolean) → boolean#
Returns TRUE if every input value is TRUE, otherwise FALSE.



bool_or(boolean) → boolean#
Returns TRUE if any input value is TRUE, otherwise FALSE.



checksum(x) → varbinary#
Returns an order-insensitive checksum of the given values.



count(*) → bigint#
Returns the number of input rows.



count(x) → bigint
Returns the number of non-null input values.



count_if(x) → bigint#
Returns the number of TRUE input values.
This function is equivalent to count(CASE WHEN x THEN 1 END).



every(boolean) → boolean#
This is an alias for bool_and().



geometric_mean(x) → double#
Returns the geometric mean of all input values.



listagg(x, separator) → varchar#
Returns the concatenated input values, separated by the separator string.
Synopsis:
LISTAGG( expression [, separator] [ON OVERFLOW overflow_behaviour])
    WITHIN GROUP (ORDER BY sort_item, [...]) [FILTER (WHERE condition)]


If separator is not specified, the empty string will be used as separator.
In its simplest form the function looks like:
SELECT listagg(value, ',') WITHIN GROUP (ORDER BY value) csv_value
FROM (VALUES 'a', 'c', 'b') t(value);


and results in:
csv_value
-----------
'a,b,c'


The overflow behaviour is by default to throw an error in case that the length of the output
of the function exceeds 1048576 bytes:
SELECT listagg(value, ',' ON OVERFLOW ERROR) WITHIN GROUP (ORDER BY value) csv_value
FROM (VALUES 'a', 'b', 'c') t(value);


There exists also the possibility to truncate the output WITH COUNT or WITHOUT COUNT
of omitted non-null values in case that the length of the output of the
function exceeds 1048576 bytes:
SELECT listagg(value, ',' ON OVERFLOW TRUNCATE '.....' WITH COUNT) WITHIN GROUP (ORDER BY value)
FROM (VALUES 'a', 'b', 'c') t(value);


If not specified, the truncation filler string is by default '...'.
This aggregation function can be also used in a scenario involving grouping:
SELECT id, listagg(value, ',') WITHIN GROUP (ORDER BY o) csv_value
FROM (VALUES
    (100, 1, 'a'),
    (200, 3, 'c'),
    (200, 2, 'b')
) t(id, o, value)
GROUP BY id
ORDER BY id;


results in:
 id  | csv_value
-----+-----------
 100 | a
 200 | b,c


This aggregation function supports
filtering during aggregation
for scenarios where the aggregation for the data not matching the filter
condition still needs to show up in the output:
SELECT 
    country,
    listagg(city, ',')
        WITHIN GROUP (ORDER BY population DESC)
        FILTER (WHERE population >= 10_000_000) megacities
FROM (VALUES 
    ('India', 'Bangalore', 13_700_000),
    ('India', 'Chennai', 12_200_000),
    ('India', 'Ranchi', 1_547_000),
    ('Austria', 'Vienna', 1_897_000),
    ('Poland', 'Warsaw', 1_765_000)
) t(country, city, population)
GROUP BY country
ORDER BY country;


results in:
 country |    megacities     
---------+-------------------
 Austria | NULL              
 India   | Bangalore,Chennai 
 Poland  | NULL


The current implementation of listagg function does not support window frames.



max(x) → [same as input]#
Returns the maximum value of all input values.



max(x, n) → array<[same as x]>
Returns n largest values of all input values of x.



max_by(x, y) → [same as x]#
Returns the value of x associated with the maximum value of y over all input values.



max_by(x, y, n) → array<[same as x]>
Returns n values of x associated with the n largest of all input values of y
in descending order of y.



min(x) → [same as input]#
Returns the minimum value of all input values.



min(x, n) → array<[same as x]>
Returns n smallest values of all input values of x.



min_by(x, y) → [same as x]#
Returns the value of x associated with the minimum value of y over all input values.



min_by(x, y, n) → array<[same as x]>
Returns n values of x associated with the n smallest of all input values of y
in ascending order of y.



sum(x) → [same as input]#
Returns the sum of all input values.



Bitwise aggregate functions#


bitwise_and_agg(x) → bigint#
Returns the bitwise AND of all input non-NULL values in 2’s complement representation.
If all records inside the group are NULL, or if the group is empty, the function returns NULL.



bitwise_or_agg(x) → bigint#
Returns the bitwise OR of all input non-NULL values in 2’s complement representation.
If all records inside the group are NULL, or if the group is empty, the function returns NULL.



bitwise_xor_agg(x) → bigint#
Returns the bitwise XOR of all input non-NULL values in 2’s complement representation.
If all records inside the group are NULL, or if the group is empty, the function returns NULL.



Map aggregate functions#


histogram(x) → map<K,bigint>#
Returns a map containing the count of the number of times each input value occurs.



map_agg(key, value) → map<K,V>#
Returns a map created from the input key / value pairs.



map_union(x(K, V)) → map<K,V>#
Returns the union of all the input maps. If a key is found in multiple
input maps, that key’s value in the resulting map comes from an arbitrary input map.
For example, take the following histogram function that creates multiple maps from the Iris dataset:
SELECT histogram(floor(petal_length_cm)) petal_data
FROM memory.default.iris
GROUP BY species;

        petal_data
-- {4.0=6, 5.0=33, 6.0=11}
-- {4.0=37, 5.0=2, 3.0=11}
-- {1.0=50}


You can combine these maps using map_union:
SELECT map_union(petal_data) petal_data_union
FROM (
       SELECT histogram(floor(petal_length_cm)) petal_data
       FROM memory.default.iris
       GROUP BY species
       );

             petal_data_union
--{4.0=6, 5.0=2, 6.0=11, 1.0=50, 3.0=11}





multimap_agg(key, value) → map<K,array(V)>#
Returns a multimap created from the input key / value pairs.
Each key can be associated with multiple values.



Approximate aggregate functions#


approx_distinct(x) → bigint#
Returns the approximate number of distinct input values.
This function provides an approximation of count(DISTINCT x).
Zero is returned if all input values are null.
This function should produce a standard error of 2.3%, which is the
standard deviation of the (approximately normal) error distribution over
all possible sets. It does not guarantee an upper bound on the error for
any specific input set.



approx_distinct(x, e) → bigint
Returns the approximate number of distinct input values.
This function provides an approximation of count(DISTINCT x).
Zero is returned if all input values are null.
This function should produce a standard error of no more than e, which
is the standard deviation of the (approximately normal) error distribution
over all possible sets. It does not guarantee an upper bound on the error
for any specific input set. The current implementation of this function
requires that e be in the range of [0.0040625, 0.26000].



approx_most_frequent(buckets, value, capacity) → map<[same as value], bigint>#
Computes the top frequent values up to buckets elements approximately.
Approximate estimation of the function enables us to pick up the frequent
values with less memory. Larger capacity improves the accuracy of
underlying algorithm with sacrificing the memory capacity. The returned
value is a map containing the top elements with corresponding estimated
frequency.
The error of the function depends on the permutation of the values and its
cardinality. We can set the capacity same as the cardinality of the
underlying data to achieve the least error.
buckets and capacity must be bigint. value can be numeric
or string type.
The function uses the stream summary data structure proposed in the paper
Efficient Computation of Frequent and Top-k Elements in Data Streams
by A. Metwalley, D. Agrawl and A. Abbadi.



approx_percentile(x, percentage) → [same as x]#
Returns the approximate percentile for all input values of x at the
given percentage. The value of percentage must be between zero and
one and must be constant for all input rows.



approx_percentile(x, percentages) → array<[same as x]>
Returns the approximate percentile for all input values of x at each of
the specified percentages. Each element of the percentages array must be
between zero and one, and the array must be constant for all input rows.



approx_percentile(x, w, percentage) → [same as x]
Returns the approximate weighed percentile for all input values of x
using the per-item weight w at the percentage percentage. Weights must be
greater or equal to 1. Integer-value weights can be thought of as a replication
count for the value x in the percentile set. The value of percentage must be
between zero and one and must be constant for all input rows.



approx_percentile(x, w, percentages) → array<[same as x]>
Returns the approximate weighed percentile for all input values of x
using the per-item weight w at each of the given percentages specified
in the array. Weights must be greater or equal to 1. Integer-value weights can
be thought of as a replication count for the value x in the percentile
set. Each element of the percentages array must be between zero and one, and the array
must be constant for all input rows.



approx_set(x) → HyperLogLog
See HyperLogLog functions.



merge(x) → HyperLogLog
See HyperLogLog functions.



merge(qdigest(T)) -> qdigest(T)
See Quantile digest functions.



merge(tdigest) → tdigest
See T-Digest functions.



numeric_histogram(buckets, value) → map<double, double>
Computes an approximate histogram with up to buckets number of buckets
for all values. This function is equivalent to the variant of
numeric_histogram() that takes a weight, with a per-item weight of 1.



numeric_histogram(buckets, value, weight) → map<double, double>#
Computes an approximate histogram with up to buckets number of buckets
for all values with a per-item weight of weight. The algorithm
is based loosely on:
Yael Ben-Haim and Elad Tom-Tov, "A streaming parallel decision tree algorithm",
J. Machine Learning Research 11 (2010), pp. 849--872.


buckets must be a bigint. value and weight must be numeric.



qdigest_agg(x) -> qdigest([same as x])
See Quantile digest functions.



qdigest_agg(x, w) -> qdigest([same as x])
See Quantile digest functions.



qdigest_agg(x, w, accuracy) -> qdigest([same as x])
See Quantile digest functions.



tdigest_agg(x) → tdigest
See T-Digest functions.



tdigest_agg(x, w) → tdigest
See T-Digest functions.



Statistical aggregate functions#


corr(y, x) → double#
Returns correlation coefficient of input values.



covar_pop(y, x) → double#
Returns the population covariance of input values.



covar_samp(y, x) → double#
Returns the sample covariance of input values.



kurtosis(x) → double#
Returns the excess kurtosis of all input values. Unbiased estimate using
the following expression:
kurtosis(x) = n(n+1)/((n-1)(n-2)(n-3))sum[(x_i-mean)^4]/stddev(x)^4-3(n-1)^2/((n-2)(n-3))





regr_intercept(y, x) → double#
Returns linear regression intercept of input values. y is the dependent
value. x is the independent value.



regr_slope(y, x) → double#
Returns linear regression slope of input values. y is the dependent
value. x is the independent value.



skewness(x) → double#
Returns the Fisher’s moment coefficient of skewness of all input values.



stddev(x) → double#
This is an alias for stddev_samp().



stddev_pop(x) → double#
Returns the population standard deviation of all input values.



stddev_samp(x) → double#
Returns the sample standard deviation of all input values.



variance(x) → double#
This is an alias for var_samp().



var_pop(x) → double#
Returns the population variance of all input values.



var_samp(x) → double#
Returns the sample variance of all input values.



Lambda aggregate functions#


reduce_agg(inputValue T, initialState S, inputFunction(S, T, S), combineFunction(S, S, S)) → S#
Reduces all input values into a single value. inputFunction will be invoked
for each non-null input value. In addition to taking the input value, inputFunction
takes the current state, initially initialState, and returns the new state.
combineFunction will be invoked to combine two states into a new state.
The final state is returned:
SELECT id, reduce_agg(value, 0, (a, b) -> a + b, (a, b) -> a + b)
FROM (
    VALUES
        (1, 3),
        (1, 4),
        (1, 5),
        (2, 6),
        (2, 7)
) AS t(id, value)
GROUP BY id;
-- (1, 12)
-- (2, 13)

SELECT id, reduce_agg(value, 1, (a, b) -> a * b, (a, b) -> a * b)
FROM (
    VALUES
        (1, 3),
        (1, 4),
        (1, 5),
        (2, 6),
        (2, 7)
) AS t(id, value)
GROUP BY id;
-- (1, 60)
-- (2, 42)


The state type must be a boolean, integer, floating-point, char, varchar or date/time/interval.

















 Previous  List of functions by topic 



  Next  AI functions 











































Array functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Array functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI



 Array 
Array

Contents

Subscript operator: []

Concatenation operator: ||

Array functions

all_match()

any_match()

array_distinct()

array_intersect()

array_union()

array_except()

array_histogram()

array_join()

array_max()

array_min()

array_position()

array_remove()

array_sort()

arrays_overlap()

cardinality()

combinations()

contains()

contains_sequence()

element_at()

filter()

flatten()

ngrams()

none_match()

reduce()

repeat()

sequence()

shuffle()

slice()

trim_array()

transform()

euclidean_distance()

dot_product()

zip()

zip_with()







Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Subscript operator: []

Concatenation operator: ||

Array functions

all_match()

any_match()

array_distinct()

array_intersect()

array_union()

array_except()

array_histogram()

array_join()

array_max()

array_min()

array_position()

array_remove()

array_sort()

arrays_overlap()

cardinality()

combinations()

contains()

contains_sequence()

element_at()

filter()

flatten()

ngrams()

none_match()

reduce()

repeat()

sequence()

shuffle()

slice()

trim_array()

transform()

euclidean_distance()

dot_product()

zip()

zip_with()











Array functions and operators#
Array functions and operators use the ARRAY type. Create an array
with the data type constructor.
Create an array of integer numbers:
SELECT ARRAY[1, 2, 4];
-- [1, 2, 4]


Create an array of character values:
SELECT ARRAY['foo', 'bar', 'bazz'];
-- [foo, bar, bazz]


Array elements must use the same type or it must be possible to coerce values to
a common type. The following example uses integer and decimal values and the
resulting array contains decimals:
SELECT ARRAY[1, 1.2, 4];
-- [1.0, 1.2, 4.0]


Null values are allowed:
SELECT ARRAY[1, 2, NULL, -4, NULL];
-- [1, 2, NULL, -4, NULL]



Subscript operator: []#
The [] operator is used to access an element of an array and is indexed
starting from one:
SELECT my_array[1] AS first_element


The following example constructs an array and then accesses the second element:
SELECT ARRAY[1, 1.2, 4][2];
-- 1.2




Concatenation operator: ||#
The || operator is used to concatenate an array with an array or an element of the same type:
SELECT ARRAY[1] || ARRAY[2];
-- [1, 2]

SELECT ARRAY[1] || 2;
-- [1, 2]

SELECT 2 || ARRAY[1];
-- [2, 1]




Array functions#


all_match(array(T), function(T, boolean)) → boolean#
Returns whether all elements of an array match the given predicate. Returns true if all the elements
match the predicate (a special case is when the array is empty); false if one or more elements don’t
match; NULL if the predicate function returns NULL for one or more elements and true for all
other elements.



any_match(array(T), function(T, boolean)) → boolean#
Returns whether any elements of an array match the given predicate. Returns true if one or more
elements match the predicate; false if none of the elements matches (a special case is when the
array is empty); NULL if the predicate function returns NULL for one or more elements and false
for all other elements.



array_distinct(x) → array#
Remove duplicate values from the array x.



array_intersect(x, y) → array#
Returns an array of the elements in the intersection of x and y, without duplicates.



array_union(x, y) → array#
Returns an array of the elements in the union of x and y, without duplicates.



array_except(x, y) → array#
Returns an array of elements in x but not in y, without duplicates.



array_histogram(x) → map<K, bigint>#
Returns a map where the keys are the unique elements in the input array
x and the values are the number of times that each element appears in
x. Null values are ignored.
SELECT array_histogram(ARRAY[42, 7, 42, NULL]);
-- {42=2, 7=1}


Returns an empty map if the input array has no non-null elements.
SELECT array_histogram(ARRAY[NULL, NULL]);
-- {}





array_join(x, delimiter) → varchar#
Concatenates the elements of the given array using the delimiter.
Null elements are omitted in the result.



array_join(x, delimiter, null_replacement) → varchar
Concatenates the elements of the given array using the delimiter and an optional string to replace nulls.



array_max(x) → x#
Returns the maximum value of input array.



array_min(x) → x#
Returns the minimum value of input array.



array_position(x, element) → bigint#
Returns the position of the first occurrence of the element in array x (or 0 if not found).



array_remove(x, element) → array#
Remove all elements that equal element from array x.



array_sort(x) → array#
Sorts and returns the array x. The elements of x must be orderable.
Null elements will be placed at the end of the returned array.



array_sort(array(T), function(T, T, int)) -> array(T)
Sorts and returns the array based on the given comparator function.
The comparator will take two nullable arguments representing two nullable
elements of the array. It returns -1, 0, or 1 as the first nullable
element is less than, equal to, or greater than the second nullable element.
If the comparator function returns other values (including NULL), the
query will fail and raise an error.
SELECT array_sort(ARRAY[3, 2, 5, 1, 2],
                  (x, y) -> IF(x < y, 1, IF(x = y, 0, -1)));
-- [5, 3, 2, 2, 1]

SELECT array_sort(ARRAY['bc', 'ab', 'dc'],
                  (x, y) -> IF(x < y, 1, IF(x = y, 0, -1)));
-- ['dc', 'bc', 'ab']


SELECT array_sort(ARRAY[3, 2, null, 5, null, 1, 2],
                  -- sort null first with descending order
                  (x, y) -> CASE WHEN x IS NULL THEN -1
                                 WHEN y IS NULL THEN 1
                                 WHEN x < y THEN 1
                                 WHEN x = y THEN 0
                                 ELSE -1 END);
-- [null, null, 5, 3, 2, 2, 1]

SELECT array_sort(ARRAY[3, 2, null, 5, null, 1, 2],
                  -- sort null last with descending order
                  (x, y) -> CASE WHEN x IS NULL THEN 1
                                 WHEN y IS NULL THEN -1
                                 WHEN x < y THEN 1
                                 WHEN x = y THEN 0
                                 ELSE -1 END);
-- [5, 3, 2, 2, 1, null, null]

SELECT array_sort(ARRAY['a', 'abcd', 'abc'],
                  -- sort by string length
                  (x, y) -> IF(length(x) < length(y), -1,
                               IF(length(x) = length(y), 0, 1)));
-- ['a', 'abc', 'abcd']

SELECT array_sort(ARRAY[ARRAY[2, 3, 1], ARRAY[4, 2, 1, 4], ARRAY[1, 2]],
                  -- sort by array length
                  (x, y) -> IF(cardinality(x) < cardinality(y), -1,
                               IF(cardinality(x) = cardinality(y), 0, 1)));
-- [[1, 2], [2, 3, 1], [4, 2, 1, 4]]





arrays_overlap(x, y) → boolean#
Tests if arrays x and y have any non-null elements in common.
Returns null if there are no non-null elements in common but either array contains null.



cardinality(x) → bigint#
Returns the cardinality (size) of the array x.



concat(array1, array2, ..., arrayN) → array
Concatenates the arrays array1, array2, ..., arrayN.
This function provides the same functionality as the SQL-standard concatenation operator (||).



combinations(array(T), n) -> array(array(T))#
Returns n-element sub-groups of input array. If the input array has no duplicates,
combinations returns n-element subsets.
SELECT combinations(ARRAY['foo', 'bar', 'baz'], 2);
-- [['foo', 'bar'], ['foo', 'baz'], ['bar', 'baz']]

SELECT combinations(ARRAY[1, 2, 3], 2);
-- [[1, 2], [1, 3], [2, 3]]

SELECT combinations(ARRAY[1, 2, 2], 2);
-- [[1, 2], [1, 2], [2, 2]]


Order of sub-groups is deterministic but unspecified. Order of elements within
a sub-group deterministic but unspecified. n must be not be greater than 5,
and the total size of sub-groups generated must be smaller than 100,000.



contains(x, element) → boolean#
Returns true if the array x contains the element.



contains_sequence(x, seq) → boolean#
Return true if array x contains all of array seq as a subsequence (all values in the same consecutive order).



element_at(array(E), index) → E#
Returns element of array at given index.
If index > 0, this function provides the same functionality as the SQL-standard subscript operator ([]),
except that the function returns NULL when accessing an index larger than array length, whereas
the subscript operator would fail in such a case.
If index < 0, element_at accesses elements from the last to the first.



filter(array(T), function(T, boolean)) -> array(T)#
Constructs an array from those elements of array for which function returns true:
SELECT filter(ARRAY[], x -> true);
-- []

SELECT filter(ARRAY[5, -6, NULL, 7], x -> x > 0);
-- [5, 7]

SELECT filter(ARRAY[5, NULL, 7, NULL], x -> x IS NOT NULL);
-- [5, 7]





flatten(x) → array#
Flattens an array(array(T)) to an array(T) by concatenating the contained arrays.



ngrams(array(T), n) -> array(array(T))#
Returns n-grams (sub-sequences of adjacent n elements) for the array.
The order of the n-grams in the result is unspecified.
SELECT ngrams(ARRAY['foo', 'bar', 'baz', 'foo'], 2);
-- [['foo', 'bar'], ['bar', 'baz'], ['baz', 'foo']]

SELECT ngrams(ARRAY['foo', 'bar', 'baz', 'foo'], 3);
-- [['foo', 'bar', 'baz'], ['bar', 'baz', 'foo']]

SELECT ngrams(ARRAY['foo', 'bar', 'baz', 'foo'], 4);
-- [['foo', 'bar', 'baz', 'foo']]

SELECT ngrams(ARRAY['foo', 'bar', 'baz', 'foo'], 5);
-- [['foo', 'bar', 'baz', 'foo']]

SELECT ngrams(ARRAY[1, 2, 3, 4], 2);
-- [[1, 2], [2, 3], [3, 4]]





none_match(array(T), function(T, boolean)) → boolean#
Returns whether no elements of an array match the given predicate. Returns true if none of the elements
matches the predicate (a special case is when the array is empty); false if one or more elements match;
NULL if the predicate function returns NULL for one or more elements and false for all other elements.



reduce(array(T), initialState S, inputFunction(S, T, S), outputFunction(S, R)) → R#
Returns a single value reduced from array. inputFunction will
be invoked for each element in array in order. In addition to taking
the element, inputFunction takes the current state, initially
initialState, and returns the new state. outputFunction will be
invoked to turn the final state into the result value. It may be the
identity function (i -> i).
SELECT reduce(ARRAY[], 0,
              (s, x) -> s + x,
              s -> s);
-- 0

SELECT reduce(ARRAY[5, 20, 50], 0,
              (s, x) -> s + x,
              s -> s);
-- 75

SELECT reduce(ARRAY[5, 20, NULL, 50], 0,
              (s, x) -> s + x,
              s -> s);
-- NULL

SELECT reduce(ARRAY[5, 20, NULL, 50], 0,
              (s, x) -> s + coalesce(x, 0),
              s -> s);
-- 75

SELECT reduce(ARRAY[5, 20, NULL, 50], 0,
              (s, x) -> IF(x IS NULL, s, s + x),
              s -> s);
-- 75

SELECT reduce(ARRAY[2147483647, 1], BIGINT '0',
              (s, x) -> s + x,
              s -> s);
-- 2147483648

-- calculates arithmetic average
SELECT reduce(ARRAY[5, 6, 10, 20],
              CAST(ROW(0.0, 0) AS ROW(sum DOUBLE, count INTEGER)),
              (s, x) -> CAST(ROW(x + s.sum, s.count + 1) AS
                             ROW(sum DOUBLE, count INTEGER)),
              s -> IF(s.count = 0, NULL, s.sum / s.count));
-- 10.25





repeat(element, count) → array#
Repeat element for count times.



reverse(x) → array
Returns an array which has the reversed order of array x.



sequence(start, stop)#
Generate a sequence of integers from start to stop, incrementing
by 1 if start is less than or equal to stop, otherwise -1.



sequence(start, stop, step)
Generate a sequence of integers from start to stop, incrementing by step.



sequence(start, stop)
Generate a sequence of dates from start date to stop date, incrementing
by 1 day if start date is less than or equal to stop date, otherwise -1 day.



sequence(start, stop, step)
Generate a sequence of dates from start to stop, incrementing by step.
The type of step can be either INTERVAL DAY TO SECOND or INTERVAL YEAR TO MONTH.



sequence(start, stop, step)
Generate a sequence of timestamps from start to stop, incrementing by step.
The type of step can be either INTERVAL DAY TO SECOND or INTERVAL YEAR TO MONTH.



shuffle(x) → array#
Generate a random permutation of the given array x.



slice(x, start, length) → array#
Subsets array x starting from index start (or starting from the end
if start is negative) with a length of length.



trim_array(x, n) → array#
Remove n elements from the end of array:
SELECT trim_array(ARRAY[1, 2, 3, 4], 1);
-- [1, 2, 3]

SELECT trim_array(ARRAY[1, 2, 3, 4], 2);
-- [1, 2]





transform(array(T), function(T, U)) -> array(U)#
Returns an array that is the result of applying function to each element of array:
SELECT transform(ARRAY[], x -> x + 1);
-- []

SELECT transform(ARRAY[5, 6], x -> x + 1);
-- [6, 7]

SELECT transform(ARRAY[5, NULL, 6], x -> coalesce(x, 0) + 1);
-- [6, 1, 7]

SELECT transform(ARRAY['x', 'abc', 'z'], x -> x || '0');
-- ['x0', 'abc0', 'z0']

SELECT transform(ARRAY[ARRAY[1, NULL, 2], ARRAY[3, NULL]],
                 a -> filter(a, x -> x IS NOT NULL));
-- [[1, 2], [3]]





euclidean_distance(array(double), array(double)) → double#
Calculates the euclidean distance:
SELECT euclidean_distance(ARRAY[1.0, 2.0], ARRAY[3.0, 4.0]);
-- 2.8284271247461903





dot_product(array(double), array(double)) → double#
Calculates the dot product:
SELECT dot_product(ARRAY[1.0, 2.0], ARRAY[3.0, 4.0]);
-- 11.0





zip(array1, array2[, ...]) -> array(row)#
Merges the given arrays, element-wise, into a single array of rows. The M-th element of
the N-th argument will be the N-th field of the M-th output element.
If the arguments have an uneven length, missing values are filled with NULL.
SELECT zip(ARRAY[1, 2], ARRAY['1b', null, '3b']);
-- [ROW(1, '1b'), ROW(2, null), ROW(null, '3b')]





zip_with(array(T), array(U), function(T, U, R)) -> array(R)#
Merges the two given arrays, element-wise, into a single array using function.
If one array is shorter, nulls are appended at the end to match the length of the
longer array, before applying function.
SELECT zip_with(ARRAY[1, 3, 5], ARRAY['a', 'b', 'c'],
                (x, y) -> (y, x));
-- [ROW('a', 1), ROW('b', 3), ROW('c', 5)]

SELECT zip_with(ARRAY[1, 2], ARRAY[3, 4],
                (x, y) -> x + y);
-- [4, 6]

SELECT zip_with(ARRAY['a', 'b', 'c'], ARRAY['d', 'e', 'f'],
                (x, y) -> concat(x, y));
-- ['ad', 'be', 'cf']

SELECT zip_with(ARRAY['a'], ARRAY['d', null, 'f'],
                (x, y) -> coalesce(x, y));
-- ['a', null, 'f']



















 Previous  AI functions 



  Next  Binary functions and operators 











































Binary functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Binary functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array



 Binary 
Binary

Contents

Binary operators

Binary functions

Base64 encoding functions

from_base64()

to_base64()

from_base64url()

to_base64url()

from_base32()

to_base32()



Hex encoding functions

from_hex()

to_hex()



Integer encoding functions

from_big_endian_32()

to_big_endian_32()

from_big_endian_64()

to_big_endian_64()



Floating-point encoding functions

from_ieee754_32()

to_ieee754_32()

from_ieee754_64()

to_ieee754_64()



Hashing functions

crc32()

md5()

sha1()

sha256()

sha512()

spooky_hash_v2_32()

spooky_hash_v2_64()

xxhash64()

murmur3()



HMAC functions

hmac_md5()

hmac_sha1()

hmac_sha256()

hmac_sha512()







Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Binary operators

Binary functions

Base64 encoding functions

from_base64()

to_base64()

from_base64url()

to_base64url()

from_base32()

to_base32()



Hex encoding functions

from_hex()

to_hex()



Integer encoding functions

from_big_endian_32()

to_big_endian_32()

from_big_endian_64()

to_big_endian_64()



Floating-point encoding functions

from_ieee754_32()

to_ieee754_32()

from_ieee754_64()

to_ieee754_64()



Hashing functions

crc32()

md5()

sha1()

sha256()

sha512()

spooky_hash_v2_32()

spooky_hash_v2_64()

xxhash64()

murmur3()



HMAC functions

hmac_md5()

hmac_sha1()

hmac_sha256()

hmac_sha512()











Binary functions and operators#

Binary operators#
The || operator performs concatenation.


Binary functions#


concat(binary1, ..., binaryN) → varbinary
Returns the concatenation of binary1, binary2, ..., binaryN.
This function provides the same functionality as the
SQL-standard concatenation operator (||).



length(binary) → bigint
Returns the length of binary in bytes.



lpad(binary, size, padbinary) → varbinary
Left pads binary to size bytes with padbinary.
If size is less than the length of binary, the result is
truncated to size characters. size must not be negative
and padbinary must be non-empty.



rpad(binary, size, padbinary) → varbinary
Right pads binary to size bytes with padbinary.
If size is less than the length of binary, the result is
truncated to size characters. size must not be negative
and padbinary must be non-empty.



substr(binary, start) → varbinary
Returns the rest of binary from the starting position start,
measured in bytes. Positions start with 1. A negative starting position
is interpreted as being relative to the end of the string.



substr(binary, start, length) → varbinary
Returns a substring from binary of length length from the starting
position start, measured in bytes. Positions start with 1. A
negative starting position is interpreted as being relative to the end of
the string.



reverse(binary) → varbinary
Returns binary with the bytes in reverse order.



Base64 encoding functions#
The Base64 functions implement the encoding specified in RFC 4648.


from_base64(string) → varbinary#
Decodes binary data from the base64 encoded string.



to_base64(binary) → varchar#
Encodes binary into a base64 string representation.



from_base64url(string) → varbinary#
Decodes binary data from the base64 encoded string using the URL safe alphabet.



to_base64url(binary) → varchar#
Encodes binary into a base64 string representation using the URL safe alphabet.



from_base32(string) → varbinary#
Decodes binary data from the base32 encoded string.



to_base32(binary) → varchar#
Encodes binary into a base32 string representation.



Hex encoding functions#


from_hex(string) → varbinary#
Decodes binary data from the hex encoded string.



to_hex(binary) → varchar#
Encodes binary into a hex string representation.



Integer encoding functions#


from_big_endian_32(binary) → integer#
Decodes the 32-bit two’s complement big-endian binary.
The input must be exactly 4 bytes.



to_big_endian_32(integer) → varbinary#
Encodes integer into a 32-bit two’s complement big-endian format.



from_big_endian_64(binary) → bigint#
Decodes the 64-bit two’s complement big-endian binary.
The input must be exactly 8 bytes.



to_big_endian_64(bigint) → varbinary#
Encodes bigint into a 64-bit two’s complement big-endian format.



Floating-point encoding functions#


from_ieee754_32(binary) → real#
Decodes the 32-bit big-endian binary in IEEE 754 single-precision floating-point format.
The input must be exactly 4 bytes.



to_ieee754_32(real) → varbinary#
Encodes real into a 32-bit big-endian binary according to IEEE 754 single-precision floating-point format.



from_ieee754_64(binary) → double#
Decodes the 64-bit big-endian binary in IEEE 754 double-precision floating-point format.
The input must be exactly 8 bytes.



to_ieee754_64(double) → varbinary#
Encodes double into a 64-bit big-endian binary according to IEEE 754 double-precision floating-point format.



Hashing functions#


crc32(binary) → bigint#
Computes the CRC-32 of binary. For general purpose hashing, use
xxhash64(), as it is much faster and produces a better quality hash.



md5(binary) → varbinary#
Computes the MD5 hash of binary.



sha1(binary) → varbinary#
Computes the SHA1 hash of binary.



sha256(binary) → varbinary#
Computes the SHA256 hash of binary.



sha512(binary) → varbinary#
Computes the SHA512 hash of binary.



spooky_hash_v2_32(binary) → varbinary#
Computes the 32-bit SpookyHashV2 hash of binary.



spooky_hash_v2_64(binary) → varbinary#
Computes the 64-bit SpookyHashV2 hash of binary.



xxhash64(binary) → varbinary#
Computes the xxHash64 hash of binary.



murmur3(binary) → varbinary#
Computes the 128-bit MurmurHash3
hash of binary.
SELECT murmur3(from_base64('aaaaaa'));
-- ba 58 55 63 55 69 b4 2f 49 20 37 2c a0 e3 96 ef





HMAC functions#


hmac_md5(binary, key) → varbinary#
Computes HMAC with MD5 of binary with the given key.



hmac_sha1(binary, key) → varbinary#
Computes HMAC with SHA1 of binary with the given key.



hmac_sha256(binary, key) → varbinary#
Computes HMAC with SHA256 of binary with the given key.



hmac_sha512(binary, key) → varbinary#
Computes HMAC with SHA512 of binary with the given key.

















 Previous  Array functions and operators 



  Next  Bitwise functions 











































Bitwise functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Bitwise functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary



 Bitwise 
Bitwise

Contents

bit_count()

bitwise_and()

bitwise_not()

bitwise_or()

bitwise_xor()

bitwise_left_shift()

bitwise_right_shift()

bitwise_right_shift_arithmetic()





Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

bit_count()

bitwise_and()

bitwise_not()

bitwise_or()

bitwise_xor()

bitwise_left_shift()

bitwise_right_shift()

bitwise_right_shift_arithmetic()









Bitwise functions#


bit_count(x, bits) → bigint#
Count the number of bits set in x (treated as bits-bit signed
integer) in 2’s complement representation:
SELECT bit_count(9, 64); -- 2
SELECT bit_count(9, 8); -- 2
SELECT bit_count(-7, 64); -- 62
SELECT bit_count(-7, 8); -- 6





bitwise_and(x, y) → bigint#
Returns the bitwise AND of x and y in 2’s complement representation.
Bitwise AND of 19 (binary: 10011) and 25 (binary: 11001) results in
17 (binary: 10001):
SELECT bitwise_and(19,25); -- 17





bitwise_not(x) → bigint#
Returns the bitwise NOT of x in 2’s complement representation
(NOT x = -x - 1):
SELECT bitwise_not(-12); --  11
SELECT bitwise_not(19);  -- -20
SELECT bitwise_not(25);  -- -26





bitwise_or(x, y) → bigint#
Returns the bitwise OR of x and y in 2’s complement representation.
Bitwise OR of 19 (binary: 10011) and 25 (binary: 11001) results in
27 (binary: 11011):
SELECT bitwise_or(19,25); -- 27





bitwise_xor(x, y) → bigint#
Returns the bitwise XOR of x and y in 2’s complement representation.
Bitwise XOR of 19 (binary: 10011) and 25 (binary: 11001) results in
10 (binary: 01010):
SELECT bitwise_xor(19,25); -- 10





bitwise_left_shift(value, shift) → [same as value]#
Returns the left shifted value of value.
Shifting 1 (binary: 001) by two bits results in 4 (binary: 00100):
SELECT bitwise_left_shift(1, 2); -- 4


Shifting 5 (binary: 0101) by two bits results in 20 (binary: 010100):
SELECT bitwise_left_shift(5, 2); -- 20


Shifting a value by 0 always results in the original value:
SELECT bitwise_left_shift(20, 0); -- 20
SELECT bitwise_left_shift(42, 0); -- 42


Shifting 0 by a shift always results in 0:
SELECT bitwise_left_shift(0, 1); -- 0
SELECT bitwise_left_shift(0, 2); -- 0





bitwise_right_shift(value, shift) → [same as value]#
Returns the logical right shifted value of value.
Shifting 8 (binary: 1000) by three bits results in 1 (binary: 001):
SELECT bitwise_right_shift(8, 3); -- 1


Shifting 9 (binary: 1001) by one bit results in 4 (binary: 100):
SELECT bitwise_right_shift(9, 1); -- 4


Shifting a value by 0 always results in the original value:
SELECT bitwise_right_shift(20, 0); -- 20
SELECT bitwise_right_shift(42, 0); -- 42


Shifting a value by 64 or more bits results in 0:
SELECT bitwise_right_shift( 12, 64); -- 0
SELECT bitwise_right_shift(-45, 64); -- 0


Shifting 0 by a shift always results in 0:
SELECT bitwise_right_shift(0, 1); -- 0
SELECT bitwise_right_shift(0, 2); -- 0





bitwise_right_shift_arithmetic(value, shift) → [same as value]#
Returns the arithmetic right shifted value of value.
Returns the same values as bitwise_right_shift() when shifting by less than
64 bits. Shifting by 64 or more bits results in 0 for a positive and
-1 for a negative value:
SELECT bitwise_right_shift_arithmetic( 12, 64); --  0
SELECT bitwise_right_shift_arithmetic(-45, 64); -- -1



See also bitwise_and_agg() and bitwise_or_agg().















 Previous  Binary functions and operators 



  Next  Color functions 











































Color functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Color functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise



 Color 
Color

Contents

bar()

color()

render()

rgb()





Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

bar()

color()

render()

rgb()









Color functions#


bar(x, width) → varchar#
Renders a single bar in an ANSI bar chart using a default
low_color of red and a high_color of green.  For example,
if x of 25% and width of 40 are passed to this function. A
10-character red bar will be drawn followed by 30 spaces to create
a bar of 40 characters.



bar(x, width, low_color, high_color) → varchar
Renders a single line in an ANSI bar chart of the specified
width. The parameter x is a double value between 0 and 1.
Values of x that fall outside the range [0, 1] will be
truncated to either a 0 or a 1 value. The low_color and
high_color capture the color to use for either end of
the horizontal bar chart.  For example, if x is 0.5, width
is 80, low_color is 0xFF0000, and high_color is 0x00FF00
this function will return a 40 character bar that varies from red
(0xFF0000) and yellow (0xFFFF00) and the remainder of the 80
character bar will be padded with spaces.






color(string) → color#
Returns a color capturing a decoded RGB value from a 4-character
string of the format “#000”.  The input string should be varchar
containing a CSS-style short rgb string or one of black,
red, green, yellow, blue, magenta, cyan,
white.



color(x, low, high, low_color, high_color) → color
Returns a color interpolated between low_color and
high_color using the double parameters x, low, and
high to calculate a fraction which is then passed to the
color(fraction, low_color, high_color) function shown below.
If x falls outside the range defined by low and high
its value is truncated to fit within this range.



color(x, low_color, high_color) → color
Returns a color interpolated between low_color and
high_color according to the double argument x between 0
and 1.  The parameter x is a double value between 0 and 1.
Values of x that fall outside the range [0, 1] will be
truncated to either a 0 or a 1 value.



render(x, color) → varchar#
Renders value x using the specific color using ANSI
color codes. x can be either a double, bigint, or varchar.



render(b) → varchar
Accepts boolean value b and renders a green true or a red
false using ANSI color codes.



rgb(red, green, blue) → color#
Returns a color value capturing the RGB value of three
component color values supplied as int parameters ranging from 0
to 255: red, green, blue.
















 Previous  Bitwise functions 



  Next  Comparison functions and operators 











































Comparison functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Comparison functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color



 Comparison 
Comparison

Contents

Comparison operators

Range operator: BETWEEN

IS NULL and IS NOT NULL

IS DISTINCT FROM and IS NOT DISTINCT FROM

GREATEST and LEAST

greatest()

least()



Quantified comparison predicates: ALL, ANY and SOME

Pattern comparison: LIKE

Row comparison: IN

Examples





Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Comparison operators

Range operator: BETWEEN

IS NULL and IS NOT NULL

IS DISTINCT FROM and IS NOT DISTINCT FROM

GREATEST and LEAST

greatest()

least()



Quantified comparison predicates: ALL, ANY and SOME

Pattern comparison: LIKE

Row comparison: IN

Examples









Comparison functions and operators#

Comparison operators#






Operator
Description



<
Less than

>
Greater than

<=
Less than or equal to

>=
Greater than or equal to

=
Equal

<>
Not equal

!=
Not equal (non-standard but popular syntax)





Range operator: BETWEEN#
The BETWEEN operator tests if a value is within a specified range. It uses the
syntax value BETWEEN min AND max:
SELECT 3 BETWEEN 2 AND 6;


The preceding statement is equivalent to the following statement:
SELECT 3 >= 2 AND 3 <= 6;


To test if a value does not fall within the specified range use NOT BETWEEN:
SELECT 3 NOT BETWEEN 2 AND 6;


The statement shown above is equivalent to the following statement:
SELECT 3 < 2 OR 3 > 6;


A NULL in a BETWEEN or NOT BETWEEN statement is evaluated using the
standard NULL evaluation rules applied to the equivalent expression above:
SELECT NULL BETWEEN 2 AND 4; -- null

SELECT 2 BETWEEN NULL AND 6; -- null

SELECT 2 BETWEEN 3 AND NULL; -- false

SELECT 8 BETWEEN NULL AND 6; -- false


The BETWEEN and NOT BETWEEN operators can also be used to evaluate any
orderable type. For example, a VARCHAR:
SELECT 'Paul' BETWEEN 'John' AND 'Ringo'; -- true


Note that the value, min, and max parameters to BETWEEN and NOT BETWEEN must
be the same type. For example, Trino produces an error if you ask it if John
is between 2.3 and 35.2.


IS NULL and IS NOT NULL#
The IS NULL and IS NOT NULL operators test whether a value is null
(undefined).  Both operators work for all data types.
Using NULL with IS NULL evaluates to true:
SELECT NULL IS NULL; -- true


But any other constant does not:
SELECT 3.0 IS NULL; -- false




IS DISTINCT FROM and IS NOT DISTINCT FROM#
In SQL a NULL value signifies an unknown value, so any comparison involving a
NULL produces NULL.  The  IS DISTINCT FROM and IS NOT DISTINCT FROM
operators treat NULL as a known value and both operators guarantee either a
true or false outcome even in the presence of NULL input:
SELECT NULL IS DISTINCT FROM NULL; -- false

SELECT NULL IS NOT DISTINCT FROM NULL; -- true


In the preceding example a NULL value is not considered distinct from NULL.
When you are comparing values which may include NULL use these operators to
guarantee either a TRUE or FALSE result.
The following truth table demonstrate the handling of NULL in
IS DISTINCT FROM and IS NOT DISTINCT FROM:


a
b
a = b
a <> b
a DISTINCT b
a NOT DISTINCT b



1
1
TRUE
FALSE
FALSE
TRUE

1
2
FALSE
TRUE
TRUE
FALSE

1
NULL
NULL
NULL
TRUE
FALSE

NULL
NULL
NULL
NULL
FALSE
TRUE





GREATEST and LEAST#
These functions are not in the SQL standard, but are a common extension.
Like most other functions in Trino, they return null if any argument is
null. Note that in some other databases, such as PostgreSQL, they only
return null if all arguments are null.
The following types are supported:

DOUBLE
BIGINT
VARCHAR
TIMESTAMP
TIMESTAMP WITH TIME ZONE
DATE



greatest(value1, value2, ..., valueN) → [same as input]#
Returns the largest of the provided values.



least(value1, value2, ..., valueN) → [same as input]#
Returns the smallest of the provided values.



Quantified comparison predicates: ALL, ANY and SOME#
The ALL, ANY and SOME quantifiers can be used together with comparison
operators in the following way:
expression operator quantifier ( subquery )


For example:
SELECT 'hello' = ANY (VALUES 'hello', 'world'); -- true

SELECT 21 < ALL (VALUES 19, 20, 21); -- false

SELECT 42 >= SOME (SELECT 41 UNION ALL SELECT 42 UNION ALL SELECT 43); -- true


Following are the meanings of some quantifier and comparison operator
combinations:






Expression
Meaning



A = ALL (...)
Evaluates to true when A is equal to all values.

A <> ALL (...)
Evaluates to true when A doesn’t match any value.

A < ALL (...)
Evaluates to true when A is smaller than the smallest value.

A = ANY (...)
Evaluates to true when A is equal to any of the values. This form
is equivalent to A IN (...).

A <> ANY (...)
Evaluates to true when A doesn’t match one or more values.

A < ANY (...)
Evaluates to true when A is smaller than the biggest value.



ANY and SOME have the same meaning and can be used interchangeably.


Pattern comparison: LIKE#
The LIKE operator can be used to compare values with a pattern:
... column [NOT] LIKE 'pattern' ESCAPE 'character';


Matching characters is case sensitive, and the pattern supports two symbols for
matching:

_ matches any single character
% matches zero or more characters

Typically it is often used as a condition in WHERE statements. An example is
a query to find all continents starting with E, which returns Europe:
SELECT * FROM (VALUES 'America', 'Asia', 'Africa', 'Europe', 'Australia', 'Antarctica') AS t (continent)
WHERE continent LIKE 'E%';


You can negate the result by adding NOT, and get all other continents, all
not starting with E:
SELECT * FROM (VALUES 'America', 'Asia', 'Africa', 'Europe', 'Australia', 'Antarctica') AS t (continent)
WHERE continent NOT LIKE 'E%';


If you only have one specific character to match, you can use the _ symbol
for each character. The following query uses two underscores and produces only
Asia as result:
SELECT * FROM (VALUES 'America', 'Asia', 'Africa', 'Europe', 'Australia', 'Antarctica') AS t (continent)
WHERE continent LIKE 'A__A';


The wildcard characters _ and % must be escaped to allow you to match
them as literals. This can be achieved by specifying the ESCAPE character to
use:
SELECT 'South_America' LIKE 'South\_America' ESCAPE '\';


The above query returns true since the escaped underscore symbol matches. If
you need to match the used escape character as well, you can escape it.
If you want to match for the chosen escape character, you simply escape itself.
For example, you can use \\ to match for \.


Row comparison: IN#
The IN operator can be used in a WHERE clause to compare column values with
a list of values. The list of values can be supplied by a subquery or directly
as static values in an array:
... WHERE column [NOT] IN ('value1','value2');
... WHERE column [NOT] IN ( subquery );


Use the optional NOT keyword to negate the condition.
The following example shows a simple usage with a static array:
SELECT * FROM region WHERE name IN ('AMERICA', 'EUROPE');


The values in the clause are used for multiple comparisons that are combined as
a logical OR. The preceding query is equivalent to the following query:
SELECT * FROM region WHERE name = 'AMERICA' OR name = 'EUROPE';


You can negate the comparisons by adding NOT, and get all other regions
except the values in list:
SELECT * FROM region WHERE name NOT IN ('AMERICA', 'EUROPE');


When using a subquery to determine the values to use in the comparison, the
subquery must return a single column and one or more rows. For example, the
following query returns nation name of countries in regions starting with the
letter A, specifically Africa, America, and Asia:
SELECT nation.name
FROM nation
WHERE regionkey IN (
  SELECT regionkey
  FROM region
  WHERE starts_with(name, 'A')
)
ORDER by nation.name;




Examples#
The following example queries showcase aspects of using comparison functions and
operators related to implied ordering of values, implicit casting, and different
types.
Ordering:
SELECT 'M' BETWEEN 'A' AND 'Z'; -- true
SELECT 'A' < 'B'; -- true
SELECT 'A' < 'a'; -- true
SELECT TRUE > FALSE; -- true
SELECT 'M' BETWEEN 'A' AND 'Z'; -- true
SELECT 'm' BETWEEN 'A' AND 'Z'; -- false


The following queries show a subtle difference between char and varchar
types. The length parameter for varchar is an optional maximum length
parameter and comparison is based on the data only, ignoring the length:
SELECT cast('Test' as varchar(20)) = cast('Test' as varchar(25)); --true
SELECT cast('Test' as varchar(20)) = cast('Test   ' as varchar(25)); --false


The length parameter for char defines a fixed length character array.
Comparison with different length automatically includes a cast to the same
larger length. The cast is performed as automatic padding with spaces, and
therefore both queries in the following return true:
SELECT cast('Test' as char(20)) = cast('Test' as char(25)); -- true
SELECT cast('Test' as char(20)) = cast('Test   ' as char(25)); -- true


The following queries show how date types are ordered, and how date is
implicitly cast to timestamp with zero time values:
SELECT DATE '2024-08-22' < DATE '2024-08-31';
SELECT DATE '2024-08-22' < TIMESTAMP '2024-08-22 8:00:00';


















 Previous  Color functions 



  Next  Conditional expressions 











































Date and time functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Date and time functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion



 Date and time 
Date and time

Contents

Date and time operators

Time zone conversion

Date and time functions

current_date

current_time

current_timestamp

current_timezone()

date()

last_day_of_month()

from_iso8601_timestamp()

from_iso8601_timestamp_nanos()

from_iso8601_date()

at_timezone()

with_timezone()

from_unixtime()

from_unixtime_nanos()

localtime

localtimestamp

now()

to_iso8601()

to_milliseconds()

to_unixtime()



Truncation function

date_trunc()



Interval functions

date_add()

date_diff()



Duration function

parse_duration()

human_readable_seconds()



MySQL date functions

date_format()

date_parse()



Java date functions

format_datetime()

parse_datetime()



Extraction function

extract()



Convenience extraction functions

day()

day_of_month()

day_of_week()

day_of_year()

dow()

doy()

hour()

millisecond()

minute()

month()

quarter()

second()

timezone_hour()

timezone_minute()

week()

week_of_year()

year()

year_of_week()

yow()

timezone()







Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Date and time operators

Time zone conversion

Date and time functions

current_date

current_time

current_timestamp

current_timezone()

date()

last_day_of_month()

from_iso8601_timestamp()

from_iso8601_timestamp_nanos()

from_iso8601_date()

at_timezone()

with_timezone()

from_unixtime()

from_unixtime_nanos()

localtime

localtimestamp

now()

to_iso8601()

to_milliseconds()

to_unixtime()



Truncation function

date_trunc()



Interval functions

date_add()

date_diff()



Duration function

parse_duration()

human_readable_seconds()



MySQL date functions

date_format()

date_parse()



Java date functions

format_datetime()

parse_datetime()



Extraction function

extract()



Convenience extraction functions

day()

day_of_month()

day_of_week()

day_of_year()

dow()

doy()

hour()

millisecond()

minute()

month()

quarter()

second()

timezone_hour()

timezone_minute()

week()

week_of_year()

year()

year_of_week()

yow()

timezone()











Date and time functions and operators#
These functions and operators operate on date and time data types.

Date and time operators#


Operator
Example
Result



+
date '2012-08-08' + interval '2' day
2012-08-10

+
time '01:00' + interval '3' hour
04:00:00.000

+
timestamp '2012-08-08 01:00' + interval '29' hour
2012-08-09 06:00:00.000

+
timestamp '2012-10-31 01:00' + interval '1' month
2012-11-30 01:00:00.000

+
interval '2' day + interval '3' hour
2 03:00:00.000

+
interval '3' year + interval '5' month
3-5

-
date '2012-08-08' - interval '2' day
2012-08-06

-
time '01:00' - interval '3' hour
22:00:00.000

-
timestamp '2012-08-08 01:00' - interval '29' hour
2012-08-06 20:00:00.000

-
timestamp '2012-10-31 01:00' - interval '1' month
2012-09-30 01:00:00.000

-
interval '2' day - interval '3' hour
1 21:00:00.000

-
interval '3' year - interval '5' month
2-7





Time zone conversion#
The AT TIME ZONE operator sets the time zone of a timestamp:
SELECT timestamp '2012-10-31 01:00 UTC';
-- 2012-10-31 01:00:00.000 UTC

SELECT timestamp '2012-10-31 01:00 UTC' AT TIME ZONE 'America/Los_Angeles';
-- 2012-10-30 18:00:00.000 America/Los_Angeles




Date and time functions#


current_date#
Returns the current date as of the start of the query.



current_time#
Returns the current time with time zone as of the start of the query.



current_timestamp#
Returns the current timestamp with time zone as of the start of the query,
with 3 digits of subsecond precision,



current_timestamp(p)
Returns the current timestamp with time zone as of the start of the query, with
p digits of subsecond precision:
SELECT current_timestamp(6);
-- 2020-06-24 08:25:31.759993 America/Los_Angeles





current_timezone() → varchar#
Returns the current time zone in the format defined by IANA
(e.g., America/Los_Angeles) or as fixed offset from UTC (e.g., +08:35)



date(x) → date#
This is an alias for CAST(x AS date).



last_day_of_month(x) → date#
Returns the last day of the month.



from_iso8601_timestamp(string) → timestamp(3) with time zone#
Parses the ISO 8601 formatted date string, optionally with time and time
zone, into a timestamp(3) with time zone. The time defaults to
00:00:00.000, and the time zone defaults to the session time zone:
SELECT from_iso8601_timestamp('2020-05-11');
-- 2020-05-11 00:00:00.000 America/Vancouver

SELECT from_iso8601_timestamp('2020-05-11T11:15:05');
-- 2020-05-11 11:15:05.000 America/Vancouver

SELECT from_iso8601_timestamp('2020-05-11T11:15:05.055+01:00');
-- 2020-05-11 11:15:05.055 +01:00





from_iso8601_timestamp_nanos(string) → timestamp(9) with time zone#
Parses the ISO 8601 formatted date and time string. The time zone
defaults to the session time zone:
SELECT from_iso8601_timestamp_nanos('2020-05-11T11:15:05');
-- 2020-05-11 11:15:05.000000000 America/Vancouver

SELECT from_iso8601_timestamp_nanos('2020-05-11T11:15:05.123456789+01:00');
-- 2020-05-11 11:15:05.123456789 +01:00





from_iso8601_date(string) → date#
Parses the ISO 8601 formatted date string into a date. The date can
be a calendar date, a week date using ISO week numbering, or year and day
of year combined:
SELECT from_iso8601_date('2020-05-11');
-- 2020-05-11

SELECT from_iso8601_date('2020-W10');
-- 2020-03-02

SELECT from_iso8601_date('2020-123');
-- 2020-05-02





at_timezone(timestamp(p) with time zone, zone) → timestamp(p) with time zone#
Converts a timestamp(p) with time zone to a time zone specified in zone.
In the following example, the input timezone is GMT, which is seven hours
ahead of America/Los_Angeles in November 2022:
SELECT at_timezone(TIMESTAMP '2022-11-01 09:08:07.321 GMT', 'America/Los_Angeles')
-- 2022-11-01 02:08:07.321 America/Los_Angeles





with_timezone(timestamp(p), zone) → timestamp(p) with time zone#
Returns the timestamp specified in timestamp with the time zone
specified in zone with precision p:
SELECT current_timezone()
-- America/New_York

SELECT with_timezone(TIMESTAMP '2022-11-01 09:08:07.321', 'America/Los_Angeles')
-- 2022-11-01 09:08:07.321 America/Los_Angeles





from_unixtime(unixtime) → timestamp(3) with time zone#
Returns the UNIX timestamp unixtime as a timestamp with time zone. unixtime is the
number of seconds since 1970-01-01 00:00:00 UTC.



from_unixtime(unixtime, zone) → timestamp(3) with time zone
Returns the UNIX timestamp unixtime as a timestamp with time zone
using zone for the time zone. unixtime is the number of seconds
since 1970-01-01 00:00:00 UTC.



from_unixtime(unixtime, hours, minutes) → timestamp(3) with time zone
Returns the UNIX timestamp unixtime as a timestamp with time zone
using hours and minutes for the time zone offset. unixtime is
the number of seconds since 1970-01-01 00:00:00 in double data type.



from_unixtime_nanos(unixtime) → timestamp(9) with time zone#
Returns the UNIX timestamp unixtime as a timestamp with time zone. unixtime is the
number of nanoseconds since 1970-01-01 00:00:00.000000000 UTC:
SELECT from_unixtime_nanos(100);
-- 1970-01-01 00:00:00.000000100 UTC

SELECT from_unixtime_nanos(DECIMAL '1234');
-- 1970-01-01 00:00:00.000001234 UTC

SELECT from_unixtime_nanos(DECIMAL '1234.499');
-- 1970-01-01 00:00:00.000001234 UTC

SELECT from_unixtime_nanos(DECIMAL '-1234');
-- 1969-12-31 23:59:59.999998766 UTC





localtime#
Returns the current time as of the start of the query.



localtimestamp#
Returns the current timestamp as of the start of the query, with 3
digits of subsecond precision.



localtimestamp(p)
Returns the current timestamp as of the start
of the query, with p digits of subsecond precision:
SELECT localtimestamp(6);
-- 2020-06-10 15:55:23.383628





now() → timestamp(3) with time zone#
This is an alias for current_timestamp.



to_iso8601(x) → varchar#
Formats x as an ISO 8601 string. x can be date, timestamp, or
timestamp with time zone.



to_milliseconds(interval) → bigint#
Returns the day-to-second interval as milliseconds.



to_unixtime(timestamp) → double#
Returns timestamp as a UNIX timestamp.


Note
The following SQL-standard functions do not use parenthesis:

current_date
current_time
current_timestamp
localtime
localtimestamp




Truncation function#
The date_trunc function supports the following units:


Unit
Example Truncated Value



millisecond
2001-08-22 03:04:05.321

second
2001-08-22 03:04:05.000

minute
2001-08-22 03:04:00.000

hour
2001-08-22 03:00:00.000

day
2001-08-22 00:00:00.000

week
2001-08-20 00:00:00.000

month
2001-08-01 00:00:00.000

quarter
2001-07-01 00:00:00.000

year
2001-01-01 00:00:00.000



The above examples use the timestamp 2001-08-22 03:04:05.321 as the input.


date_trunc(unit, x) → [same as input]#
Returns x truncated to unit:
SELECT date_trunc('day' , TIMESTAMP '2022-10-20 05:10:00');
-- 2022-10-20 00:00:00.000

SELECT date_trunc('month' , TIMESTAMP '2022-10-20 05:10:00');
-- 2022-10-01 00:00:00.000

SELECT date_trunc('year', TIMESTAMP '2022-10-20 05:10:00');
-- 2022-01-01 00:00:00.000





Interval functions#
The functions in this section support the following interval units:


Unit
Description



millisecond
Milliseconds

second
Seconds

minute
Minutes

hour
Hours

day
Days

week
Weeks

month
Months

quarter
Quarters of a year

year
Years





date_add(unit, value, timestamp) → [same as input]#
Adds an interval value of type unit to timestamp.
Subtraction can be performed by using a negative value:
SELECT date_add('second', 86, TIMESTAMP '2020-03-01 00:00:00');
-- 2020-03-01 00:01:26.000

SELECT date_add('hour', 9, TIMESTAMP '2020-03-01 00:00:00');
-- 2020-03-01 09:00:00.000

SELECT date_add('day', -1, TIMESTAMP '2020-03-01 00:00:00 UTC');
-- 2020-02-29 00:00:00.000 UTC





date_diff(unit, timestamp1, timestamp2) → bigint#
Returns timestamp2 - timestamp1 expressed in terms of unit:
SELECT date_diff('second', TIMESTAMP '2020-03-01 00:00:00', TIMESTAMP '2020-03-02 00:00:00');
-- 86400

SELECT date_diff('hour', TIMESTAMP '2020-03-01 00:00:00 UTC', TIMESTAMP '2020-03-02 00:00:00 UTC');
-- 24

SELECT date_diff('day', DATE '2020-03-01', DATE '2020-03-02');
-- 1

SELECT date_diff('second', TIMESTAMP '2020-06-01 12:30:45.000000000', TIMESTAMP '2020-06-02 12:30:45.123456789');
-- 86400

SELECT date_diff('millisecond', TIMESTAMP '2020-06-01 12:30:45.000000000', TIMESTAMP '2020-06-02 12:30:45.123456789');
-- 86400123





Duration function#
The parse_duration function supports the following units:


Unit
Description



ns
Nanoseconds

us
Microseconds

ms
Milliseconds

s
Seconds

m
Minutes

h
Hours

d
Days





parse_duration(string) → interval#
Parses string of format value unit into an interval, where
value is fractional number of unit values:
SELECT parse_duration('42.8ms');
-- 0 00:00:00.043

SELECT parse_duration('3.81 d');
-- 3 19:26:24.000

SELECT parse_duration('5m');
-- 0 00:05:00.000





human_readable_seconds(double) → varchar#
Formats the double value of seconds into a human readable string containing
weeks, days, hours, minutes, and seconds:
SELECT human_readable_seconds(96);
-- 1 minute, 36 seconds

SELECT human_readable_seconds(3762);
-- 1 hour, 2 minutes, 42 seconds

SELECT human_readable_seconds(56363463);
-- 93 weeks, 1 day, 8 hours, 31 minutes, 3 seconds





MySQL date functions#
The functions in this section use a format string that is compatible with
the MySQL date_parse and str_to_date functions. The following table,
based on the MySQL manual, describes the format specifiers:


Specifier
Description



%a
Abbreviated weekday name (Sun .. Sat)

%b
Abbreviated month name (Jan .. Dec)

%c
Month, numeric (1 .. 12), this specifier does not support 0 as a month.

%D
Day of the month with English suffix (0th, 1st, 2nd, 3rd, …)

%d
Day of the month, numeric (01 .. 31), this specifier does not support 0 as a month or day.

%e
Day of the month, numeric (1 .. 31), this specifier does not support 0 as a day.

%f
Fraction of second (6 digits for printing: 000000 .. 999000; 1 - 9 digits for parsing: 0 .. 999999999), timestamp is truncated to milliseconds.

%H
Hour (00 .. 23)

%h
Hour (01 .. 12)

%I
Hour (01 .. 12)

%i
Minutes, numeric (00 .. 59)

%j
Day of year (001 .. 366)

%k
Hour (0 .. 23)

%l
Hour (1 .. 12)

%M
Month name (January .. December)

%m
Month, numeric (01 .. 12), this specifier does not support 0 as a month.

%p
AM or PM

%r
Time of day, 12-hour (equivalent to %h:%i:%s %p)

%S
Seconds (00 .. 59)

%s
Seconds (00 .. 59)

%T
Time of day, 24-hour (equivalent to %H:%i:%s)

%U
Week (00 .. 53), where Sunday is the first day of the week

%u
Week (00 .. 53), where Monday is the first day of the week

%V
Week (01 .. 53), where Sunday is the first day of the week; used with %X

%v
Week (01 .. 53), where Monday is the first day of the week; used with %x

%W
Weekday name (Sunday .. Saturday)

%w
Day of the week (0 .. 6), where Sunday is the first day of the week, this specifier is not supported,consider using day_of_week() (it uses 1-7 instead of 0-6).

%X
Year for the week where Sunday is the first day of the week, numeric, four digits; used with %V

%x
Year for the week, where Monday is the first day of the week, numeric, four digits; used with %v

%Y
Year, numeric, four digits

%y
Year, numeric (two digits), when parsing, two-digit year format assumes range 1970 .. 2069, so “70” will result in year 1970 but “69” will produce 2069.

%%
A literal % character

%x
x, for any x not listed above




Warning
The following specifiers are not currently supported: %D %U %u %V %w %X



date_format(timestamp, format) → varchar#
Formats timestamp as a string using format:
SELECT date_format(TIMESTAMP '2022-10-20 05:10:00', '%m-%d-%Y %H');
-- 10-20-2022 05





date_parse(string, format) → timestamp(3)#
Parses string into a timestamp using format:
SELECT date_parse('2022/10/20/05', '%Y/%m/%d/%H');
-- 2022-10-20 05:00:00.000





Java date functions#
The functions in this section use a format string that is compatible with
JodaTime’s DateTimeFormat pattern format.


format_datetime(timestamp, format) → varchar#
Formats timestamp as a string using format.



parse_datetime(string, format) → timestamp with time zone#
Parses string into a timestamp with time zone using format.



Extraction function#
The extract function supports the following fields:


Field
Description



YEAR
year()

QUARTER
quarter()

MONTH
month()

WEEK
week()

DAY
day()

DAY_OF_MONTH
day()

DAY_OF_WEEK
day_of_week()

DOW
day_of_week()

DAY_OF_YEAR
day_of_year()

DOY
day_of_year()

YEAR_OF_WEEK
year_of_week()

YOW
year_of_week()

HOUR
hour()

MINUTE
minute()

SECOND
second()

TIMEZONE_HOUR
timezone_hour()

TIMEZONE_MINUTE
timezone_minute()



The types supported by the extract function vary depending on the
field to be extracted. Most fields support all date and time types.


extract(field FROM x) → bigint#
Returns field from x:
SELECT extract(YEAR FROM TIMESTAMP '2022-10-20 05:10:00');
-- 2022



Note
This SQL-standard function uses special syntax for specifying the arguments.




Convenience extraction functions#


day(x) → bigint#
Returns the day of the month from x.



day_of_month(x) → bigint#
This is an alias for day().



day_of_week(x) → bigint#
Returns the ISO day of the week from x.
The value ranges from 1 (Monday) to 7 (Sunday).



day_of_year(x) → bigint#
Returns the day of the year from x.
The value ranges from 1 to 366.



dow(x) → bigint#
This is an alias for day_of_week().



doy(x) → bigint#
This is an alias for day_of_year().



hour(x) → bigint#
Returns the hour of the day from x.
The value ranges from 0 to 23.



millisecond(x) → bigint#
Returns the millisecond of the second from x.



minute(x) → bigint#
Returns the minute of the hour from x.



month(x) → bigint#
Returns the month of the year from x.



quarter(x) → bigint#
Returns the quarter of the year from x.
The value ranges from 1 to 4.



second(x) → bigint#
Returns the second of the minute from x.



timezone_hour(timestamp) → bigint#
Returns the hour of the time zone offset from timestamp.



timezone_minute(timestamp) → bigint#
Returns the minute of the time zone offset from timestamp.



week(x) → bigint#
Returns the ISO week of the year from x.
The value ranges from 1 to 53.



week_of_year(x) → bigint#
This is an alias for week().



year(x) → bigint#
Returns the year from x.



year_of_week(x) → bigint#
Returns the year of the ISO week from x.



yow(x) → bigint#
This is an alias for year_of_week().



timezone(timestamp(p) with time zone) → varchar#
Returns the timezone identifier from timestamp(p) with time zone. The format
of the returned identifier is identical to the format used in the input
timestamp:
SELECT timezone(TIMESTAMP '2024-01-01 12:00:00 Asia/Tokyo'); -- Asia/Tokyo
SELECT timezone(TIMESTAMP '2024-01-01 12:00:00 +01:00'); -- +01:00
SELECT timezone(TIMESTAMP '2024-02-29 12:00:00 UTC'); -- UTC





timezone(time(p) with time zone) → varchar
Returns the timezone identifier from a time(p) with time zone. The format
of the returned identifier is identical to the format used in the input
time:
SELECT timezone(TIME '12:00:00+09:00'); -- +09:00



















 Previous  Conversion functions 



  Next  Decimal functions and operators 











































Decimal functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Decimal functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time



 Decimal 
Decimal

Contents

Decimal literals

Binary arithmetic decimal operators

Comparison operators

Unary decimal operators





Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Decimal literals

Binary arithmetic decimal operators

Comparison operators

Unary decimal operators









Decimal functions and operators#

Decimal literals#
Use the DECIMAL 'xxxxxxx.yyyyyyy' syntax to define a decimal literal.
The precision of a decimal type for a literal will be equal to the number of digits
in the literal (including trailing and leading zeros). The scale will be equal
to the number of digits in the fractional part (including trailing zeros).






Example literal
Data type



DECIMAL '0'
DECIMAL(1)

DECIMAL '12345'
DECIMAL(5)

DECIMAL '0000012345.1234500000'
DECIMAL(20, 10)





Binary arithmetic decimal operators#
Standard mathematical operators are supported. The table below explains
precision and scale calculation rules for result.
Assuming x is of type DECIMAL(xp, xs) and y is of type DECIMAL(yp, ys).







Operation
Result type precision
Result type scale



x + y and x - y
min(38,
    1 +
    max(xs, ys) +
    max(xp - xs, yp - ys)
)



max(xs, ys)

x * y
min(38, xp + yp)



xs + ys

x / y
min(38,
    xp + ys-xs
    + max(0, ys-xs)
    )



max(xs, ys)

x % y
min(xp - xs, yp - ys) +
max(xs, bs)



max(xs, ys)



If the mathematical result of the operation is not exactly representable with
the precision and scale of the result data type,
then an exception condition is raised: Value is out of range.
When operating on decimal types with different scale and precision, the values are
first coerced to a common super type. For types near the largest representable precision (38),
this can result in Value is out of range errors when one of the operands doesn’t fit
in the common super type. For example, the common super type of decimal(38, 0) and
decimal(38, 1) is decimal(38, 1), but certain values that fit in decimal(38, 0)
cannot be represented as a decimal(38, 1).


Comparison operators#
All standard Comparison functions and operators work for the decimal type.


Unary decimal operators#
The - operator performs negation. The type of result is same as type of argument.
















 Previous  Date and time functions and operators 



  Next  Geospatial functions 











































Geospatial functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Geospatial functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal



 Geospatial 
Geospatial

Contents

Constructors

ST_AsBinary()

ST_AsText()

ST_GeometryFromText()

ST_GeomFromBinary()

ST_GeomFromKML()

geometry_from_hadoop_shape()

ST_LineFromText()

ST_LineString()

ST_MultiPoint()

ST_Point()

ST_Polygon()

to_spherical_geography()

to_geometry()



Relationship tests

ST_Contains()

ST_Crosses()

ST_Disjoint()

ST_Equals()

ST_Intersects()

ST_Overlaps()

ST_Relate()

ST_Touches()

ST_Within()



Operations

geometry_nearest_points()

geometry_union()

ST_Boundary()

ST_Buffer()

ST_Difference()

ST_Envelope()

ST_EnvelopeAsPts()

ST_ExteriorRing()

ST_Intersection()

ST_SymDifference()

ST_Union()



Accessors

ST_Area()

ST_Centroid()

ST_ConvexHull()

ST_CoordDim()

ST_Dimension()

ST_Distance()

ST_GeometryN()

ST_InteriorRingN()

ST_GeometryType()

ST_IsClosed()

ST_IsEmpty()

ST_IsSimple()

ST_IsRing()

ST_IsValid()

ST_Length()

ST_PointN()

ST_Points()

ST_XMax()

ST_YMax()

ST_XMin()

ST_YMin()

ST_StartPoint()

simplify_geometry()

ST_EndPoint()

ST_X()

ST_Y()

ST_InteriorRings()

ST_NumGeometries()

ST_Geometries()

ST_NumPoints()

ST_NumInteriorRing()

line_interpolate_point()

line_interpolate_points()

line_locate_point()

geometry_invalid_reason()

great_circle_distance()

to_geojson_geometry()

from_geojson_geometry()



Aggregations

convex_hull_agg()

geometry_union_agg()



Bing tiles

bing_tile()

bing_tile_at()

bing_tiles_around()

bing_tile_coordinates()

bing_tile_polygon()

bing_tile_quadkey()

bing_tile_zoom_level()

geometry_to_bing_tiles()



Encoded polylines

to_encoded_polyline()

from_encoded_polyline()







HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Constructors

ST_AsBinary()

ST_AsText()

ST_GeometryFromText()

ST_GeomFromBinary()

ST_GeomFromKML()

geometry_from_hadoop_shape()

ST_LineFromText()

ST_LineString()

ST_MultiPoint()

ST_Point()

ST_Polygon()

to_spherical_geography()

to_geometry()



Relationship tests

ST_Contains()

ST_Crosses()

ST_Disjoint()

ST_Equals()

ST_Intersects()

ST_Overlaps()

ST_Relate()

ST_Touches()

ST_Within()



Operations

geometry_nearest_points()

geometry_union()

ST_Boundary()

ST_Buffer()

ST_Difference()

ST_Envelope()

ST_EnvelopeAsPts()

ST_ExteriorRing()

ST_Intersection()

ST_SymDifference()

ST_Union()



Accessors

ST_Area()

ST_Centroid()

ST_ConvexHull()

ST_CoordDim()

ST_Dimension()

ST_Distance()

ST_GeometryN()

ST_InteriorRingN()

ST_GeometryType()

ST_IsClosed()

ST_IsEmpty()

ST_IsSimple()

ST_IsRing()

ST_IsValid()

ST_Length()

ST_PointN()

ST_Points()

ST_XMax()

ST_YMax()

ST_XMin()

ST_YMin()

ST_StartPoint()

simplify_geometry()

ST_EndPoint()

ST_X()

ST_Y()

ST_InteriorRings()

ST_NumGeometries()

ST_Geometries()

ST_NumPoints()

ST_NumInteriorRing()

line_interpolate_point()

line_interpolate_points()

line_locate_point()

geometry_invalid_reason()

great_circle_distance()

to_geojson_geometry()

from_geojson_geometry()



Aggregations

convex_hull_agg()

geometry_union_agg()



Bing tiles

bing_tile()

bing_tile_at()

bing_tiles_around()

bing_tile_coordinates()

bing_tile_polygon()

bing_tile_quadkey()

bing_tile_zoom_level()

geometry_to_bing_tiles()



Encoded polylines

to_encoded_polyline()

from_encoded_polyline()











Geospatial functions#
Trino Geospatial functions that begin with the ST_ prefix support the SQL/MM specification
and are compliant with the Open Geospatial Consortium’s (OGC) OpenGIS Specifications.
As such, many Trino Geospatial functions require, or more accurately, assume that
geometries that are operated on are both simple and valid. For example, it does not
make sense to calculate the area of a polygon that has a hole defined outside of the
polygon, or to construct a polygon from a non-simple boundary line.
Trino Geospatial functions support the Well-Known Text (WKT) and Well-Known Binary (WKB) form of spatial objects:

POINT (0 0)
LINESTRING (0 0, 1 1, 1 2)
POLYGON ((0 0, 4 0, 4 4, 0 4, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1))
MULTIPOINT (0 0, 1 2)
MULTILINESTRING ((0 0, 1 1, 1 2), (2 3, 3 2, 5 4))
MULTIPOLYGON (((0 0, 4 0, 4 4, 0 4, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1)), ((-1 -1, -1 -2, -2 -2, -2 -1, -1 -1)))
GEOMETRYCOLLECTION (POINT(2 3), LINESTRING (2 3, 3 4))

Use ST_GeometryFromText() and ST_GeomFromBinary() functions to create geometry
objects from WKT or WKB.
The SphericalGeography type provides native support for spatial features represented on
geographic coordinates (sometimes called geodetic coordinates, or lat/lon, or lon/lat).
Geographic coordinates are spherical coordinates expressed in angular units (degrees).
The basis for the Geometry type is a plane. The shortest path between two points on the plane is a
straight line. That means calculations on geometries (areas, distances, lengths, intersections, etc)
can be calculated using cartesian mathematics and straight line vectors.
The basis for the SphericalGeography type is a sphere. The shortest path between two points on the
sphere is a great circle arc. That means that calculations on geographies (areas, distances,
lengths, intersections, etc) must be calculated on the sphere, using more complicated mathematics.
More accurate measurements that take the actual spheroidal shape of the world into account are not
supported.
Values returned by the measurement functions ST_Distance() and ST_Length() are in the unit of meters;
values returned by ST_Area() are in square meters.
Use to_spherical_geography() function to convert a geometry object to geography object.
For example, ST_Distance(ST_Point(-71.0882, 42.3607), ST_Point(-74.1197, 40.6976)) returns
3.4577 in the unit of the passed-in values on the euclidean plane, while
ST_Distance(to_spherical_geography(ST_Point(-71.0882, 42.3607)), to_spherical_geography(ST_Point(-74.1197, 40.6976)))
returns 312822.179 in meters.

Constructors#


ST_AsBinary(Geometry) → varbinary#
Returns the WKB representation of the geometry.



ST_AsText(Geometry) → varchar#
Returns the WKT representation of the geometry. For empty geometries,
ST_AsText(ST_LineFromText('LINESTRING EMPTY')) will produce 'MULTILINESTRING EMPTY'
and ST_AsText(ST_Polygon('POLYGON EMPTY')) will produce 'MULTIPOLYGON EMPTY'.



ST_GeometryFromText(varchar) → Geometry#
Returns a geometry type object from WKT representation.



ST_GeomFromBinary(varbinary) → Geometry#
Returns a geometry type object from WKB or EWKB representation.



ST_GeomFromKML(varchar) → Geometry#
Returns a geometry type object from KML representation.



geometry_from_hadoop_shape(varbinary) → Geometry#
Returns a geometry type object from Spatial Framework for Hadoop representation.



ST_LineFromText(varchar) → LineString#
Returns a geometry type linestring object from WKT representation.



ST_LineString(array(Point)) → LineString#
Returns a LineString formed from an array of points. If there are fewer than
two non-empty points in the input array, an empty LineString will be returned.
Array elements must not be NULL or the same as the previous element.
The returned geometry may not be simple, e.g. may self-intersect or may contain
duplicate vertexes depending on the input.



ST_MultiPoint(array(Point)) → MultiPoint#
Returns a MultiPoint geometry object formed from the specified points. Returns NULL if input array is empty.
Array elements must not be NULL or empty.
The returned geometry may not be simple and may contain duplicate points if input array has duplicates.



ST_Point(lon: double, lat: double) → Point#
Returns a geometry type point object with the given coordinate values.



ST_Polygon(varchar) → Polygon#
Returns a geometry type polygon object from WKT representation.



to_spherical_geography(Geometry) → SphericalGeography#
Converts a Geometry object to a SphericalGeography object on the sphere of the Earth’s radius. This
function is only applicable to POINT, MULTIPOINT, LINESTRING, MULTILINESTRING,
POLYGON, MULTIPOLYGON geometries defined in 2D space, or GEOMETRYCOLLECTION of such
geometries. For each point of the input geometry, it verifies that point.x is within
[-180.0, 180.0] and point.y is within [-90.0, 90.0], and uses them as (longitude, latitude)
degrees to construct the shape of the SphericalGeography result.



to_geometry(SphericalGeography) → Geometry#
Converts a SphericalGeography object to a Geometry object.



Relationship tests#


ST_Contains(geometryA: Geometry, geometryB: Geometry) → boolean#
Returns true if and only if no points of the second geometry lie in the exterior
of the first geometry, and at least one point of the interior of the first geometry
lies in the interior of the second geometry.



ST_Crosses(first: Geometry, second: Geometry) → boolean#
Returns true if the supplied geometries have some, but not all, interior points in common.



ST_Disjoint(first: Geometry, second: Geometry) → boolean#
Returns true if the give geometries do not spatially intersect –
if they do not share any space together.



ST_Equals(first: Geometry, second: Geometry) → boolean#
Returns true if the given geometries represent the same geometry.



ST_Intersects(first: Geometry, second: Geometry) → boolean#
Returns true if the given geometries spatially intersect in two dimensions
(share any portion of space) and false if they do not (they are disjoint).



ST_Overlaps(first: Geometry, second: Geometry) → boolean#
Returns true if the given geometries share space, are of the same dimension,
but are not completely contained by each other.



ST_Relate(first: Geometry, second: Geometry) → boolean#
Returns true if first geometry is spatially related to second geometry.



ST_Touches(first: Geometry, second: Geometry) → boolean#
Returns true if the given geometries have at least one point in common,
but their interiors do not intersect.



ST_Within(first: Geometry, second: Geometry) → boolean#
Returns true if first geometry is completely inside second geometry.



Operations#


geometry_nearest_points(first: Geometry, second: Geometry)#
Returns the points on each geometry nearest the other.  If either geometry
is empty, return NULL.  Otherwise, return a row of two Points that have
the minimum distance of any two points on the geometries.  The first Point
will be from the first Geometry argument, the second from the second Geometry
argument.  If there are multiple pairs with the minimum distance, one pair
is chosen arbitrarily.



geometry_union(array(Geometry)) → Geometry#
Returns a geometry that represents the point set union of the input geometries. Performance
of this function, in conjunction with array_agg() to first aggregate the input geometries,
may be better than geometry_union_agg(), at the expense of higher memory utilization.



ST_Boundary(Geometry) → Geometry#
Returns the closure of the combinatorial boundary of this geometry.



ST_Buffer(Geometry, distance) → Geometry#
Returns the geometry that represents all points whose distance from the specified geometry
is less than or equal to the specified distance. If the points of the geometry are extremely
close together (delta < 1e-8), this might return an empty geometry.



ST_Difference(first: Geometry, second: Geometry) → Geometry#
Returns the geometry value that represents the point set difference of the given geometries.



ST_Envelope(Geometry) → Geometry#
Returns the bounding rectangular polygon of a geometry.



ST_EnvelopeAsPts(Geometry)#
Returns an array of two points: the lower left and upper right corners of the bounding
rectangular polygon of a geometry. Returns NULL if input geometry is empty.



ST_ExteriorRing(Geometry) → Geometry#
Returns a line string representing the exterior ring of the input polygon.



ST_Intersection(first: Geometry, second: Geometry) → Geometry#
Returns the geometry value that represents the point set intersection of two geometries.



ST_SymDifference(first: Geometry, second: Geometry) → Geometry#
Returns the geometry value that represents the point set symmetric difference of two geometries.



ST_Union(first: Geometry, second: Geometry) → Geometry#
Returns a geometry that represents the point set union of the input geometries.
See also:  geometry_union(), geometry_union_agg()



Accessors#


ST_Area(Geometry) → double#
Returns the 2D Euclidean area of a geometry.
For Point and LineString types, returns 0.0.
For GeometryCollection types, returns the sum of the areas of the individual
geometries.



ST_Area(SphericalGeography) → double
Returns the area of a polygon or multi-polygon in square meters using a spherical model for Earth.



ST_Centroid(Geometry) → Geometry#
Returns the point value that is the mathematical centroid of a geometry.



ST_ConvexHull(Geometry) → Geometry#
Returns the minimum convex geometry that encloses all input geometries.



ST_CoordDim(Geometry) → bigint#
Returns the coordinate dimension of the geometry.



ST_Dimension(Geometry) → bigint#
Returns the inherent dimension of this geometry object, which must be
less than or equal to the coordinate dimension.



ST_Distance(first: Geometry, second: Geometry) → double
Returns the 2-dimensional cartesian minimum distance (based on spatial ref)
between two geometries in projected units.



ST_Distance(first: SphericalGeography, second: SphericalGeography) → double#
Returns the great-circle distance in meters between two SphericalGeography points.



ST_GeometryN(Geometry, index) → Geometry#
Returns the geometry element at a given index (indices start at 1).
If the geometry is a collection of geometries (e.g., GEOMETRYCOLLECTION or MULTI*),
returns the geometry at a given index.
If the given index is less than 1 or greater than the total number of elements in the collection,
returns NULL.
Use ST_NumGeometries() to find out the total number of elements.
Singular geometries (e.g., POINT, LINESTRING, POLYGON), are treated as collections of one element.
Empty geometries are treated as empty collections.



ST_InteriorRingN(Geometry, index) → Geometry#
Returns the interior ring element at the specified index (indices start at 1). If
the given index is less than 1 or greater than the total number of interior rings
in the input geometry, returns NULL. The input geometry must be a polygon.
Use ST_NumInteriorRing() to find out the total number of elements.



ST_GeometryType(Geometry) → varchar#
Returns the type of the geometry.



ST_IsClosed(Geometry) → boolean#
Returns true if the linestring’s start and end points are coincident.



ST_IsEmpty(Geometry) → boolean#
Returns true if this Geometry is an empty geometrycollection, polygon, point etc.



ST_IsSimple(Geometry) → boolean#
Returns true if this Geometry has no anomalous geometric points, such as self intersection or self tangency.



ST_IsRing(Geometry) → boolean#
Returns true if and only if the line is closed and simple.



ST_IsValid(Geometry) → boolean#
Returns true if and only if the input geometry is well formed.
Use geometry_invalid_reason() to determine why the geometry is not well formed.



ST_Length(Geometry) → double#
Returns the length of a linestring or multi-linestring using Euclidean measurement on a
two dimensional plane (based on spatial ref) in projected units.



ST_Length(SphericalGeography) → double
Returns the length of a linestring or multi-linestring on a spherical model of the Earth.
This is equivalent to the sum of great-circle distances between adjacent points on the linestring.



ST_PointN(LineString, index) → Point#
Returns the vertex of a linestring at a given index (indices start at 1).
If the given index is less than 1 or greater than the total number of elements in the collection,
returns NULL.
Use ST_NumPoints() to find out the total number of elements.



ST_Points(Geometry)#
Returns an array of points in a linestring.



ST_XMax(Geometry) → double#
Returns X maxima of a bounding box of a geometry.



ST_YMax(Geometry) → double#
Returns Y maxima of a bounding box of a geometry.



ST_XMin(Geometry) → double#
Returns X minima of a bounding box of a geometry.



ST_YMin(Geometry) → double#
Returns Y minima of a bounding box of a geometry.



ST_StartPoint(Geometry) → point#
Returns the first point of a LineString geometry as a Point.
This is a shortcut for ST_PointN(geometry, 1).



simplify_geometry(Geometry, double) → Geometry#
Returns a “simplified” version of the input geometry using the Douglas-Peucker algorithm.
Will avoid creating derived geometries (polygons in particular) that are invalid.



ST_EndPoint(Geometry) → point#
Returns the last point of a LineString geometry as a Point.
This is a shortcut for ST_PointN(geometry, ST_NumPoints(geometry)).



ST_X(Point) → double#
Returns the X coordinate of the point.



ST_Y(Point) → double#
Returns the Y coordinate of the point.



ST_InteriorRings(Geometry)#
Returns an array of all interior rings found in the input geometry, or an empty
array if the polygon has no interior rings. Returns NULL if the input geometry
is empty. The input geometry must be a polygon.



ST_NumGeometries(Geometry) → bigint#
Returns the number of geometries in the collection.
If the geometry is a collection of geometries (e.g., GEOMETRYCOLLECTION or MULTI*),
returns the number of geometries,
for single geometries returns 1,
for empty geometries returns 0.



ST_Geometries(Geometry)#
Returns an array of geometries in the specified collection. Returns a one-element array
if the input geometry is not a multi-geometry. Returns NULL if input geometry is empty.



ST_NumPoints(Geometry) → bigint#
Returns the number of points in a geometry. This is an extension to the SQL/MM
ST_NumPoints function which only applies to point and linestring.



ST_NumInteriorRing(Geometry) → bigint#
Returns the cardinality of the collection of interior rings of a polygon.



line_interpolate_point(LineString, double) → Geometry#
Returns a Point interpolated along a LineString at the fraction given. The fraction
must be between 0 and 1, inclusive.



line_interpolate_points(LineString, double, repeated)#
Returns an array of Points interpolated along a LineString. The fraction must be
between 0 and 1, inclusive.



line_locate_point(LineString, Point) → double#
Returns a float between 0 and 1 representing the location of the closest point on
the LineString to the given Point, as a fraction of total 2d line length.
Returns NULL if a LineString or a Point is empty or NULL.



geometry_invalid_reason(Geometry) → varchar#
Returns the reason for why the input geometry is not valid.
Returns NULL if the input is valid.



great_circle_distance(latitude1, longitude1, latitude2, longitude2) → double#
Returns the great-circle distance between two points on Earth’s surface in kilometers.



to_geojson_geometry(SphericalGeography) → varchar#
Returns the GeoJSON encoded defined by the input spherical geography.



from_geojson_geometry(varchar) → SphericalGeography#
Returns the spherical geography type object from the GeoJSON representation stripping non geometry key/values.
Feature and FeatureCollection are not supported.



Aggregations#


convex_hull_agg(Geometry) → Geometry#
Returns the minimum convex geometry that encloses all input geometries.



geometry_union_agg(Geometry) → Geometry#
Returns a geometry that represents the point set union of all input geometries.



Bing tiles#
These functions convert between geometries and
Bing tiles.


bing_tile(x, y, zoom_level) → BingTile#
Creates a Bing tile object from XY coordinates and a zoom level.
Zoom levels from 1 to 23 are supported.



bing_tile(quadKey) → BingTile
Creates a Bing tile object from a quadkey.



bing_tile_at(latitude, longitude, zoom_level) → BingTile#
Returns a Bing tile at a given zoom level containing a point at a given latitude
and longitude. Latitude must be within [-85.05112878, 85.05112878] range.
Longitude must be within [-180, 180] range. Zoom levels from 1 to 23 are supported.



bing_tiles_around(latitude, longitude, zoom_level)#
Returns a collection of Bing tiles that surround the point specified
by the latitude and longitude arguments at a given zoom level.



bing_tiles_around(latitude, longitude, zoom_level, radius_in_km)
Returns a minimum set of Bing tiles at specified zoom level that cover a circle of specified
radius in km around a specified (latitude, longitude) point.



bing_tile_coordinates(tile) → row<x, y>#
Returns the XY coordinates of a given Bing tile.



bing_tile_polygon(tile) → Geometry#
Returns the polygon representation of a given Bing tile.



bing_tile_quadkey(tile) → varchar#
Returns the quadkey of a given Bing tile.



bing_tile_zoom_level(tile) → tinyint#
Returns the zoom level of a given Bing tile.



geometry_to_bing_tiles(geometry, zoom_level)#
Returns the minimum set of Bing tiles that fully covers a given geometry at
a given zoom level. Zoom levels from 1 to 23 are supported.



Encoded polylines#
These functions convert between geometries and
encoded polylines.


to_encoded_polyline(Geometry) → varchar#
Encodes a linestring or multipoint to a polyline.



from_encoded_polyline(varchar) → Geometry#
Decodes a polyline to a linestring.

















 Previous  Decimal functions and operators 



  Next  HyperLogLog functions 











































HyperLogLog functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 HyperLogLog functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial



 HyperLogLog 
HyperLogLog

Contents

Data structures

Serialization

Functions

approx_set()

empty_approx_set()

merge()







IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Data structures

Serialization

Functions

approx_set()

empty_approx_set()

merge()











HyperLogLog functions#
Trino implements the approx_distinct() function using the
HyperLogLog data structure.

Data structures#
Trino implements HyperLogLog data sketches as a set of 32-bit buckets which
store a maximum hash. They can be stored sparsely (as a map from bucket ID
to bucket), or densely (as a contiguous memory block). The HyperLogLog data
structure starts as the sparse representation, switching to dense when it is
more efficient. The P4HyperLogLog structure is initialized densely and
remains dense for its lifetime.
HyperLogLog implicitly casts to P4HyperLogLog,
while one can explicitly cast HyperLogLog to P4HyperLogLog:
cast(hll AS P4HyperLogLog)




Serialization#
Data sketches can be serialized to and deserialized from varbinary. This
allows them to be stored for later use.  Combined with the ability to merge
multiple sketches, this allows one to calculate approx_distinct() of the
elements of a partition of a query, then for the entirety of a query with very
little cost.
For example, calculating the HyperLogLog for daily unique users will allow
weekly or monthly unique users to be calculated incrementally by combining the
dailies. This is similar to computing weekly revenue by summing daily revenue.
Uses of approx_distinct() with GROUPING SETS can be converted to use
HyperLogLog.  Examples:
CREATE TABLE visit_summaries (
  visit_date date,
  hll varbinary
);

INSERT INTO visit_summaries
SELECT visit_date, cast(approx_set(user_id) AS varbinary)
FROM user_visits
GROUP BY visit_date;

SELECT cardinality(merge(cast(hll AS HyperLogLog))) AS weekly_unique_users
FROM visit_summaries
WHERE visit_date >= current_date - interval '7' day;




Functions#


approx_set(x) → HyperLogLog#
Returns the HyperLogLog sketch of the input data set of x. This
data sketch underlies approx_distinct() and can be stored and
used later by calling cardinality().



cardinality(hll) → bigint
This will perform approx_distinct() on the data summarized by the
hll HyperLogLog data sketch.



empty_approx_set() → HyperLogLog#
Returns an empty HyperLogLog.



merge(HyperLogLog) → HyperLogLog#
Returns the HyperLogLog of the aggregate union of the individual hll
HyperLogLog structures.

















 Previous  Geospatial functions 



  Next  IP Address Functions 











































IP Address Functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 IP Address Functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog



 IP Address 
IP Address






JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes



















IP Address Functions#


contains(network, address) → boolean
Returns true if the address exists in the CIDR network:
SELECT contains('10.0.0.0/8', IPADDRESS '10.255.255.255'); -- true
SELECT contains('10.0.0.0/8', IPADDRESS '11.255.255.255'); -- false

SELECT contains('2001:0db8:0:0:0:ff00:0042:8329/128', IPADDRESS '2001:0db8:0:0:0:ff00:0042:8329'); -- true
SELECT contains('2001:0db8:0:0:0:ff00:0042:8329/128', IPADDRESS '2001:0db8:0:0:0:ff00:0042:8328'); -- false


















 Previous  HyperLogLog functions 



  Next  JSON functions and operators 











































JSON functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 JSON functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address



 JSON 
JSON

Contents

JSON path language

JSON path syntax and semantics

literals

variables

arithmetic binary expressions

arithmetic unary expressions

member accessor

wildcard member accessor

descendant member accessor

array accessor

wildcard array accessor

filter

Comparison rules

Examples of filter



double()

ceiling(), floor(), and abs()

keyvalue()

type()

size()



Limitations

JSON path modes

Examples of the lax mode behavior





json_exists

Examples



json_query

Examples



json_value

Examples



json_table

Examples



json_array

Argument types

Null handling

Returned type



json_object

Argument passing conventions

Argument types

Null handling

Key uniqueness

Returned type



Cast to JSON

Cast from JSON

Other JSON functions

is_json_scalar()

json_array_contains()

json_array_get()

json_array_length()

json_extract()

json_extract_scalar()

json_format()

json_parse()

json_size()







Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

JSON path language

JSON path syntax and semantics

literals

variables

arithmetic binary expressions

arithmetic unary expressions

member accessor

wildcard member accessor

descendant member accessor

array accessor

wildcard array accessor

filter

Comparison rules

Examples of filter



double()

ceiling(), floor(), and abs()

keyvalue()

type()

size()



Limitations

JSON path modes

Examples of the lax mode behavior





json_exists

Examples



json_query

Examples



json_value

Examples



json_table

Examples



json_array

Argument types

Null handling

Returned type



json_object

Argument passing conventions

Argument types

Null handling

Key uniqueness

Returned type



Cast to JSON

Cast from JSON

Other JSON functions

is_json_scalar()

json_array_contains()

json_array_get()

json_array_length()

json_extract()

json_extract_scalar()

json_format()

json_parse()

json_size()











JSON functions and operators#
The SQL standard describes functions and operators to process JSON data. They
allow you to access JSON data according to its structure, generate JSON data,
and store it persistently in SQL tables.
Importantly, the SQL standard imposes that there is no dedicated data type to
represent JSON data in SQL. Instead, JSON data is represented as character or
binary strings. Although Trino supports JSON type, it is not used or
produced by the following functions.
Trino supports three functions for querying JSON data:
json_exists,
json_query, and json_value. Each of them
is based on the same mechanism of exploring and processing JSON input using
JSON path.
Trino also supports two functions for generating JSON data –
json_array, and json_object.

JSON path language#
The JSON path language is a special language, used exclusively by certain SQL
operators to specify the query to perform on the JSON input. Although JSON path
expressions are embedded in SQL queries, their syntax significantly differs
from SQL. The semantics of predicates, operators, etc. in JSON path expressions
generally follow the semantics of SQL. The JSON path language is case-sensitive
for keywords and identifiers.

JSON path syntax and semantics#
JSON path expressions are recursive structures. Although the name “path”
suggests a linear sequence of operations going step by step deeper into the JSON
structure, a JSON path expression is in fact a tree. It can access the input
JSON item multiple times, in multiple ways, and combine the results. Moreover,
the result of a JSON path expression is not a single item, but an ordered
sequence of items. Each of the sub-expressions takes one or more input
sequences, and returns a sequence as the result.

Note
In the lax mode, most path operations first unnest all JSON arrays in the
input sequence. Any divergence from this rule is mentioned in the following
listing. Path modes are explained in JSON path modes.

The JSON path language features are divided into: literals, variables,
arithmetic binary expressions, arithmetic unary expressions, and a group of
operators collectively known as accessors.

literals#

numeric literals
They include exact and approximate numbers, and are interpreted as if they
were SQL values.


-1, 1.2e3, NaN



string literals
They are enclosed in double quotes.


"Some text"



boolean literals

true, false



null literal
It has the semantics of the JSON null, not of SQL null. See Comparison rules.


null




variables#

context variable
It refers to the currently processed input of the JSON
function.


$



named variable
It refers to a named parameter by its name.


$param



current item variable
It is used inside the filter expression to refer to the currently processed
item from the input sequence.


@



last subscript variable
It refers to the last index of the innermost enclosing array. Array indexes
in JSON path expressions are zero-based.


last




arithmetic binary expressions#
The JSON path language supports five arithmetic binary operators:
<path1> + <path2>
<path1> - <path2>
<path1> * <path2>
<path1> / <path2>
<path1> % <path2>


Both operands, <path1> and <path2>, are evaluated to sequences of
items. For arithmetic binary operators, each input sequence must contain a
single numeric item. The arithmetic operation is performed according to SQL
semantics, and it returns a sequence containing a single element with the
result.
The operators follow the same precedence rules as in SQL arithmetic operations,
and parentheses can be used for grouping.


arithmetic unary expressions#
+ <path>
- <path>


The operand <path> is evaluated to a sequence of items. Every item must be
a numeric value. The unary plus or minus is applied to every item in the
sequence, following SQL semantics, and the results form the returned sequence.


member accessor#
The member accessor returns the value of the member with the specified key for
each JSON object in the input sequence.
<path>.key
<path>."key"


The condition when a JSON object does not have such a member is called a
structural error. In the lax mode, it is suppressed, and the faulty object is
excluded from the result.
Let <path> return a sequence of three JSON objects:
{"customer" : 100, "region" : "AFRICA"},
{"region" : "ASIA"},
{"customer" : 300, "region" : "AFRICA", "comment" : null}


the expression <path>.customer succeeds in the first and the third object,
but the second object lacks the required member. In strict mode, path
evaluation fails. In lax mode, the second object is silently skipped, and the
resulting sequence is 100, 300.
All items in the input sequence must be JSON objects.

Note
Trino does not support JSON objects with duplicate keys.



wildcard member accessor#
Returns values from all key-value pairs for each JSON object in the input
sequence. All the partial results are concatenated into the returned sequence.
<path>.*


Let <path> return a sequence of three JSON objects:
{"customer" : 100, "region" : "AFRICA"},
{"region" : "ASIA"},
{"customer" : 300, "region" : "AFRICA", "comment" : null}


The results is:
100, "AFRICA", "ASIA", 300, "AFRICA", null


All items in the input sequence must be JSON objects.
The order of values returned from a single JSON object is arbitrary. The
sub-sequences from all JSON objects are concatenated in the same order in which
the JSON objects appear in the input sequence.


descendant member accessor#
Returns the values associated with the specified key in all JSON objects on all
levels of nesting in the input sequence.
<path>..key
<path>.."key"


The order of returned values is that of preorder depth first search. First, the
enclosing object is visited, and then all child nodes are visited.
This method does not perform array unwrapping in the lax mode. The results
are the same in the lax and strict modes. The method traverses into JSON
arrays and JSON objects. Non-structural JSON items are skipped.
Let <path> be a sequence containing a JSON object:
{
    "id" : 1,
    "notes" : [{"type" : 1, "comment" : "foo"}, {"type" : 2, "comment" : null}],
    "comment" : ["bar", "baz"]
}


<path>..comment --> ["bar", "baz"], "foo", null




array accessor#
Returns the elements at the specified indexes for each JSON array in the input
sequence. Indexes are zero-based.
<path>[ <subscripts> ]


The <subscripts> list contains one or more subscripts. Each subscript
specifies a single index or a range (ends inclusive):
<path>[<path1>, <path2> to <path3>, <path4>,...]


In lax mode, any non-array items resulting from the evaluation of the input
sequence are wrapped into single-element arrays. Note that this is an exception
to the rule of automatic array wrapping.
Each array in the input sequence is processed in the following way:

The variable last is set to the last index of the array.
All subscript indexes are computed in order of declaration. For a
singleton subscript <path1>, the result must be a singleton numeric item.
For a range subscript <path2> to <path3>, two numeric items are expected.
The specified array elements are added in order to the output sequence.

Let <path> return a sequence of three JSON arrays:
[0, 1, 2], ["a", "b", "c", "d"], [null, null]


The following expression returns a sequence containing the last element from
every array:
<path>[last] --> 2, "d", null


The following expression returns the third and fourth element from every array:
<path>[2 to 3] --> 2, "c", "d"


Note that the first array does not have the fourth element, and the last array
does not have the third or fourth element. Accessing non-existent elements is a
structural error. In strict mode, it causes the path expression to fail. In lax
mode, such errors are suppressed, and only the existing elements are returned.
Another example of a structural error is an improper range specification such
as 5 to 3.
Note that the subscripts may overlap, and they do not need to follow the
element order. The order in the returned sequence follows the subscripts:
<path>[1, 0, 0] --> 1, 0, 0, "b", "a", "a", null, null, null




wildcard array accessor#
Returns all elements of each JSON array in the input sequence.
<path>[*]


In lax mode, any non-array items resulting from the evaluation of the input
sequence are wrapped into single-element arrays. Note that this is an exception
to the rule of automatic array wrapping.
The output order follows the order of the original JSON arrays. Also, the order
of elements within the arrays is preserved.
Let <path> return a sequence of three JSON arrays:
[0, 1, 2], ["a", "b", "c", "d"], [null, null]
<path>[*] --> 0, 1, 2, "a", "b", "c", "d", null, null




filter#
Retrieves the items from the input sequence which satisfy the predicate.
<path>?( <predicate> )


JSON path predicates are syntactically similar to boolean expressions in SQL.
However, the semantics are different in many aspects:

They operate on sequences of items.
They have their own error handling (they never fail).
They behave different depending on the lax or strict mode.

The predicate evaluates to true, false, or unknown. Note that some
predicate expressions involve nested JSON path expression. When evaluating the
nested path, the variable @ refers to the currently examined item from the
input sequence.
The following predicate expressions are supported:

Conjunction

<predicate1> && <predicate2>



Disjunction

<predicate1> || <predicate2>



Negation

! <predicate>



exists predicate

exists( <path> )


Returns true if the nested path evaluates to a non-empty sequence, and
false when the nested path evaluates to an empty sequence. If the path
evaluation throws an error, returns unknown.

starts with predicate

<path> starts with "Some text"
<path> starts with $variable


The nested <path> must evaluate to a sequence of textual items, and the
other operand must evaluate to a single textual item. If evaluating of either
operand throws an error, the result is unknown. All items from the sequence
are checked for starting with the right operand. The result is true if a
match is found, otherwise false. However, if any of the comparisons throws
an error, the result in the strict mode is unknown. The result in the lax
mode depends on whether the match or the error was found first.

is unknown predicate

( <predicate> ) is unknown


Returns true if the nested predicate evaluates to unknown, and
false otherwise.

Comparisons

<path1> == <path2>
<path1> <> <path2>
<path1> != <path2>
<path1> < <path2>
<path1> > <path2>
<path1> <= <path2>
<path1> >= <path2>


Both operands of a comparison evaluate to sequences of items. If either
evaluation throws an error, the result is unknown. Items from the left and
right sequence are then compared pairwise. Similarly to the starts with
predicate, the result is true if any of the comparisons returns true,
otherwise false. However, if any of the comparisons throws an error, for
example because the compared types are not compatible, the result in the strict
mode is unknown. The result in the lax mode depends on whether the true
comparison or the error was found first.

Comparison rules#
Null values in the context of comparison behave different than SQL null:

null == null –> true
null != null, null < null, … –> false
null compared to a scalar value –> false
null compared to a JSON array or a JSON object –> false

When comparing two scalar values, true or false is returned if the
comparison is successfully performed. The semantics of the comparison is the
same as in SQL. In case of an error, e.g. comparing text and number,
unknown is returned.
Comparing a scalar value with a JSON array or a JSON object, and comparing JSON
arrays/objects is an error, so unknown is returned.


Examples of filter#
Let <path> return a sequence of three JSON objects:
{"customer" : 100, "region" : "AFRICA"},
{"region" : "ASIA"},
{"customer" : 300, "region" : "AFRICA", "comment" : null}


<path>?(@.region != "ASIA") --> {"customer" : 100, "region" : "AFRICA"},
                                {"customer" : 300, "region" : "AFRICA", "comment" : null}
<path>?(!exists(@.customer)) --> {"region" : "ASIA"}


The following accessors are collectively referred to as item methods.



double()#
Converts numeric or text values into double values.
<path>.double()


Let <path> return a sequence -1, 23e4, "5.6":
<path>.double() --> -1e0, 23e4, 5.6e0




ceiling(), floor(), and abs()#
Gets the ceiling, the floor or the absolute value for every numeric item in the
sequence. The semantics of the operations is the same as in SQL.
Let <path> return a sequence -1.5, -1, 1.3:
<path>.ceiling() --> -1.0, -1, 2.0
<path>.floor() --> -2.0, -1, 1.0
<path>.abs() --> 1.5, 1, 1.3




keyvalue()#
Returns a collection of JSON objects including one object per every member of
the original object for every JSON object in the sequence.
<path>.keyvalue()


The returned objects have three members:

“name”, which is the original key,
“value”, which is the original bound value,
“id”, which is the unique number, specific to an input object.

Let <path> be a sequence of three JSON objects:
{"customer" : 100, "region" : "AFRICA"},
{"region" : "ASIA"},
{"customer" : 300, "region" : "AFRICA", "comment" : null}


<path>.keyvalue() --> {"name" : "customer", "value" : 100, "id" : 0},
                      {"name" : "region", "value" : "AFRICA", "id" : 0},
                      {"name" : "region", "value" : "ASIA", "id" : 1},
                      {"name" : "customer", "value" : 300, "id" : 2},
                      {"name" : "region", "value" : "AFRICA", "id" : 2},
                      {"name" : "comment", "value" : null, "id" : 2}


It is required that all items in the input sequence are JSON objects.
The order of the returned values follows the order of the original JSON
objects. However, within objects, the order of returned entries is arbitrary.


type()#
Returns a textual value containing the type name for every item in the
sequence.
<path>.type()


This method does not perform array unwrapping in the lax mode.
The returned values are:

"null" for JSON null,
"number" for a numeric item,
"string" for a textual item,
"boolean" for a boolean item,
"date" for an item of type date,
"time without time zone" for an item of type time,
"time with time zone" for an item of type time with time zone,
"timestamp without time zone" for an item of type timestamp,
"timestamp with time zone" for an item of type timestamp with time zone,
"array" for JSON array,
"object" for JSON object,



size()#
Returns a numeric value containing the size for every JSON array in the
sequence.
<path>.size()


This method does not perform array unwrapping in the lax mode. Instead, all
non-array items are wrapped in singleton JSON arrays, so their size is 1.
It is required that all items in the input sequence are JSON arrays.
Let <path> return a sequence of three JSON arrays:
[0, 1, 2], ["a", "b", "c", "d"], [null, null]
<path>.size() --> 3, 4, 2





Limitations#
The SQL standard describes the datetime() JSON path item method and the
like_regex() JSON path predicate. Trino does not support them.


JSON path modes#
The JSON path expression can be evaluated in two modes: strict and lax. In the
strict mode, it is required that the input JSON data strictly fits the schema
required by the path expression. In the lax mode, the input JSON data can
diverge from the expected schema.
The following table shows the differences between the two modes.







Condition
strict mode
lax mode



Performing an operation which requires a non-array on an array, e.g.:
$.key requires a JSON object
$.floor() requires a numeric value

ERROR
The array is automatically unnested, and the operation is performed on
each array element.

Performing an operation which requires an array on an non-array, e.g.:
$[0], $[*], $.size()

ERROR
The non-array item is automatically wrapped in a singleton array, and
the operation is performed on the array.

A structural error: accessing a non-existent element of an array or a
non-existent member of a JSON object, e.g.:
$[-1] (array index out of bounds)
$.key, where the input JSON object does not have a member key

ERROR
The error is suppressed, and the operation results in an empty sequence.




Examples of the lax mode behavior#
Let <path> return a sequence of three items, a JSON array, a JSON object,
and a scalar numeric value:
[1, "a", null], {"key1" : 1.0, "key2" : true}, -2e3


The following example shows the wildcard array accessor in the lax mode. The
JSON array returns all its elements, while the JSON object and the number are
wrapped in singleton arrays and then unnested, so effectively they appear
unchanged in the output sequence:
<path>[*] --> 1, "a", null, {"key1" : 1.0, "key2" : true}, -2e3


When calling the size() method, the JSON object and the number are also
wrapped in singleton arrays:
<path>.size() --> 3, 1, 1


In some cases, the lax mode cannot prevent failure. In the following example,
even though the JSON array is unwrapped prior to calling the floor()
method, the item "a" causes type mismatch.
<path>.floor() --> ERROR






json_exists#
The json_exists function determines whether a JSON value satisfies a JSON
path specification.
JSON_EXISTS(
    json_input [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ],
    json_path
    [ PASSING json_argument [, ...] ]
    [ { TRUE | FALSE | UNKNOWN | ERROR } ON ERROR ]
    )


The json_path is evaluated using the json_input as the context variable
($), and the passed arguments as the named variables ($variable_name).
The returned value is true if the path returns a non-empty sequence, and
false if the path returns an empty sequence. If an error occurs, the
returned value depends on the ON ERROR clause. The default value returned
ON ERROR is FALSE. The ON ERROR clause is applied for the following
kinds of errors:

Input conversion errors, such as malformed JSON
JSON path evaluation errors, e.g. division by zero

json_input is a character string or a binary string. It should contain
a single JSON item. For a binary string, you can specify encoding.
json_path is a string literal, containing the path mode specification, and
the path expression, following the syntax rules described in
JSON path syntax and semantics.
'strict ($.price + $.tax)?(@ > 99.9)'
'lax $[0 to 1].floor()?(@ > 10)'


In the PASSING clause you can pass arbitrary expressions to be used by the
path expression.
PASSING orders.totalprice AS O_PRICE,
        orders.tax % 10 AS O_TAX


The passed parameters can be referenced in the path expression by named
variables, prefixed with $.
'lax $?(@.price > $O_PRICE || @.tax > $O_TAX)'


Additionally to SQL values, you can pass JSON values, specifying the format and
optional encoding:
PASSING orders.json_desc FORMAT JSON AS o_desc,
        orders.binary_record FORMAT JSON ENCODING UTF16 AS o_rec


Note that the JSON path language is case-sensitive, while the unquoted SQL
identifiers are upper-cased. Therefore, it is recommended to use quoted
identifiers in the PASSING clause:
'lax $.keyvalue()?(@.name == $KeyName).value' PASSING nation.name AS KeyName --> ERROR; no passed value found
'lax $.keyvalue()?(@.name == $KeyName).value' PASSING nation.name AS "KeyName" --> correct



Examples#
Let customers be a table containing two columns: id:bigint,
description:varchar.


id
description



101
‘{“comment” : “nice”, “children” : [10, 13, 16]}’

102
‘{“comment” : “problematic”, “children” : [8, 11]}’

103
‘{“comment” : “knows best”, “children” : [2]}’



The following query checks which customers have children above the age of 10:
SELECT
      id,
      json_exists(
                  description,
                  'lax $.children[*]?(@ > 10)'
                 ) AS children_above_ten
FROM customers




id
children_above_ten



101
true

102
true

103
false



In the following query, the path mode is strict. We check the third child for
each customer. This should cause a structural error for the customers who do
not have three or more children. This error is handled according to the ON ERROR clause.
SELECT
      id,
      json_exists(
                  description,
                  'strict $.children[2]?(@ > 10)'
                  UNKNOWN ON ERROR
                 ) AS child_3_above_ten
FROM customers




id
child_3_above_ten



101
true

102
NULL

103
NULL






json_query#
The json_query function extracts a JSON value from a JSON value.
JSON_QUERY(
    json_input [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ],
    json_path
    [ PASSING json_argument [, ...] ]
    [ RETURNING type [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ] ]
    [ WITHOUT [ ARRAY ] WRAPPER |
      WITH [ { CONDITIONAL | UNCONDITIONAL } ] [ ARRAY ] WRAPPER ]
    [ { KEEP | OMIT } QUOTES [ ON SCALAR STRING ] ]
    [ { ERROR | NULL | EMPTY ARRAY | EMPTY OBJECT } ON EMPTY ]
    [ { ERROR | NULL | EMPTY ARRAY | EMPTY OBJECT } ON ERROR ]
    )


The constant string json_path is evaluated using the json_input as the
context variable ($), and the passed arguments as the named variables
($variable_name).
The returned value is a JSON item returned by the path. By default, it is
represented as a character string (varchar). In the RETURNING clause,
you can specify other character string type or varbinary. With
varbinary, you can also specify the desired encoding.
json_input is a character string or a binary string. It should contain
a single JSON item. For a binary string, you can specify encoding.
json_path is a string literal, containing the path mode specification, and
the path expression, following the syntax rules described in
JSON path syntax and semantics.
'strict $.keyvalue()?(@.name == $cust_id)'
'lax $[5 to last]'


In the PASSING clause you can pass arbitrary expressions to be used by the
path expression.
PASSING orders.custkey AS CUST_ID


The passed parameters can be referenced in the path expression by named
variables, prefixed with $.
'strict $.keyvalue()?(@.value == $CUST_ID)'


Additionally to SQL values, you can pass JSON values, specifying the format and
optional encoding:
PASSING orders.json_desc FORMAT JSON AS o_desc,
        orders.binary_record FORMAT JSON ENCODING UTF16 AS o_rec


Note that the JSON path language is case-sensitive, while the unquoted SQL
identifiers are upper-cased. Therefore, it is recommended to use quoted
identifiers in the PASSING clause:
'lax $.keyvalue()?(@.name == $KeyName).value' PASSING nation.name AS KeyName --> ERROR; no passed value found
'lax $.keyvalue()?(@.name == $KeyName).value' PASSING nation.name AS "KeyName" --> correct


The ARRAY WRAPPER clause lets you modify the output by wrapping the results
in a JSON array. WITHOUT ARRAY WRAPPER is the default option. WITH CONDITIONAL ARRAY WRAPPER wraps every result which is not a singleton JSON
array or JSON object. WITH UNCONDITIONAL ARRAY WRAPPER wraps every result.
The QUOTES clause lets you modify the result for a scalar string by
removing the double quotes being part of the JSON string representation.

Examples#
Let customers be a table containing two columns: id:bigint,
description:varchar.


id
description



101
‘{“comment” : “nice”, “children” : [10, 13, 16]}’

102
‘{“comment” : “problematic”, “children” : [8, 11]}’

103
‘{“comment” : “knows best”, “children” : [2]}’



The following query gets the children array for each customer:
SELECT
      id,
      json_query(
                 description,
                 'lax $.children'
                ) AS children
FROM customers




id
children



101
‘[10,13,16]’

102
‘[8,11]’

103
‘[2]’



The following query gets the collection of children for each customer.
Note that the json_query function can only output a single JSON item. If
you don’t use array wrapper, you get an error for every customer with multiple
children. The error is handled according to the ON ERROR clause.
SELECT
      id,
      json_query(
                 description,
                 'lax $.children[*]'
                 WITHOUT ARRAY WRAPPER
                 NULL ON ERROR
                ) AS children
FROM customers




id
children



101
NULL

102
NULL

103
‘2’



The following query gets the last child for each customer, wrapped in a JSON
array:
SELECT
      id,
      json_query(
                 description,
                 'lax $.children[last]'
                 WITH ARRAY WRAPPER
                ) AS last_child
FROM customers




id
last_child



101
‘[16]’

102
‘[11]’

103
‘[2]’



The following query gets all children above the age of 12 for each customer,
wrapped in a JSON array. The second and the third customer don’t have children
of this age. Such case is handled according to the ON EMPTY clause. The
default value returned ON EMPTY is NULL. In the following example,
EMPTY ARRAY ON EMPTY is specified.
SELECT
      id,
      json_query(
                 description,
                 'strict $.children[*]?(@ > 12)'
                 WITH ARRAY WRAPPER
                 EMPTY ARRAY ON EMPTY
                ) AS children
FROM customers




id
children



101
‘[13,16]’

102
‘[]’

103
‘[]’



The following query shows the result of the QUOTES clause. Note that KEEP QUOTES is the default.
SELECT
      id,
      json_query(description, 'strict $.comment' KEEP QUOTES) AS quoted_comment,
      json_query(description, 'strict $.comment' OMIT QUOTES) AS unquoted_comment
FROM customers




id
quoted_comment
unquoted_comment



101
‘“nice”’
‘nice’

102
‘“problematic”’
‘problematic’

103
‘“knows best”’
‘knows best’



If an error occurs, the returned value depends on the ON ERROR clause. The
default value returned ON ERROR is NULL. One example of error is
multiple items returned by the path. Other errors caught and handled according
to the ON ERROR clause are:

Input conversion errors, such as malformed JSON
JSON path evaluation errors, e.g. division by zero
Output conversion errors




json_value#
The json_value function extracts a scalar SQL value from a JSON value.
JSON_VALUE(
    json_input [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ],
    json_path
    [ PASSING json_argument [, ...] ]
    [ RETURNING type ]
    [ { ERROR | NULL | DEFAULT expression } ON EMPTY ]
    [ { ERROR | NULL | DEFAULT expression } ON ERROR ]
    )


The json_path is evaluated using the json_input as the context variable
($), and the passed arguments as the named variables ($variable_name).
The returned value is the SQL scalar returned by the path. By default, it is
converted to string (varchar). In the RETURNING clause, you can specify
other desired type: a character string type, numeric, boolean or datetime type.
json_input is a character string or a binary string. It should contain
a single JSON item. For a binary string, you can specify encoding.
json_path is a string literal, containing the path mode specification, and
the path expression, following the syntax rules described in
JSON path syntax and semantics.
'strict $.price + $tax'
'lax $[last].abs().floor()'


In the PASSING clause you can pass arbitrary expressions to be used by the
path expression.
PASSING orders.tax AS O_TAX


The passed parameters can be referenced in the path expression by named
variables, prefixed with $.
'strict $[last].price + $O_TAX'


Additionally to SQL values, you can pass JSON values, specifying the format and
optional encoding:
PASSING orders.json_desc FORMAT JSON AS o_desc,
        orders.binary_record FORMAT JSON ENCODING UTF16 AS o_rec


Note that the JSON path language is case-sensitive, while the unquoted SQL
identifiers are upper-cased. Therefore, it is recommended to use quoted
identifiers in the PASSING clause:
'lax $.keyvalue()?(@.name == $KeyName).value' PASSING nation.name AS KeyName --> ERROR; no passed value found
'lax $.keyvalue()?(@.name == $KeyName).value' PASSING nation.name AS "KeyName" --> correct


If the path returns an empty sequence, the ON EMPTY clause is applied. The
default value returned ON EMPTY is NULL. You can also specify the
default value:
DEFAULT -1 ON EMPTY


If an error occurs, the returned value depends on the ON ERROR clause. The
default value returned ON ERROR is NULL. One example of error is
multiple items returned by the path. Other errors caught and handled according
to the ON ERROR clause are:

Input conversion errors, such as malformed JSON
JSON path evaluation errors, e.g. division by zero
Returned scalar not convertible to the desired type


Examples#
Let customers be a table containing two columns: id:bigint,
description:varchar.


id
description



101
‘{“comment” : “nice”, “children” : [10, 13, 16]}’

102
‘{“comment” : “problematic”, “children” : [8, 11]}’

103
‘{“comment” : “knows best”, “children” : [2]}’



The following query gets the comment for each customer as char(12):
SELECT id, json_value(
                      description,
                      'lax $.comment'
                      RETURNING char(12)
                     ) AS comment
FROM customers




id
comment



101
‘nice        ‘

102
‘problematic ‘

103
‘knows best  ‘



The following query gets the first child’s age for each customer as
tinyint:
SELECT id, json_value(
                      description,
                      'lax $.children[0]'
                      RETURNING tinyint
                     ) AS child
FROM customers




id
child



101
10

102
8

103
2



The following query gets the third child’s age for each customer. In the strict
mode, this should cause a structural error for the customers who do not have
the third child. This error is handled according to the ON ERROR clause.
SELECT id, json_value(
                      description,
                      'strict $.children[2]'
                      DEFAULT 'err' ON ERROR
                     ) AS child
FROM customers




id
child



101
‘16’

102
‘err’

103
‘err’



After changing the mode to lax, the structural error is suppressed, and the
customers without a third child produce empty sequence. This case is handled
according to the ON EMPTY clause.
SELECT id, json_value(
                      description,
                      'lax $.children[2]'
                      DEFAULT 'missing' ON EMPTY
                     ) AS child
FROM customers




id
child



101
‘16’

102
‘missing’

103
‘missing’






json_table#
The json_table clause extracts a table from a JSON value. Use this clause to
transform JSON data into a relational format, making it easier to query and
analyze. Use json_table in the FROM clause of a
SELECT statement to create a table from JSON data.
JSON_TABLE(
    json_input,
    json_path [ AS path_name ]
    [ PASSING value AS parameter_name [, ...] ]
    COLUMNS (
        column_definition [, ...] )
    [ PLAN ( json_table_specific_plan )
      | PLAN DEFAULT ( json_table_default_plan ) ]
    [ { ERROR | EMPTY } ON ERROR ]
)


The COLUMNS clause supports the following column_definition arguments:
column_name FOR ORDINALITY
| column_name type
    [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ]
    [ PATH json_path ]
    [ { WITHOUT | WITH { CONDITIONAL | UNCONDITIONAL } } [ ARRAY ] WRAPPER ]
    [ { KEEP | OMIT } QUOTES [ ON SCALAR STRING ] ]
    [ { ERROR | NULL | EMPTY { [ARRAY] | OBJECT } | DEFAULT expression } ON EMPTY ]
    [ { ERROR | NULL | DEFAULT expression } ON ERROR ]
| NESTED [ PATH ] json_path [ AS path_name ] COLUMNS ( column_definition [, ...] )


json_input is a character string or a binary string. It must contain a single
JSON item.
json_path is a string literal containing the path mode specification and the
path expression. It follows the syntax rules described in
JSON path syntax and semantics.
'strict ($.price + $.tax)?(@ > 99.9)'
'lax $[0 to 1].floor()?(@ > 10)'


In the PASSING clause, pass values as named parameters that the json_path
expression can reference.
PASSING orders.totalprice AS o_price,
        orders.tax % 10 AS o_tax


Use named parameters to reference the values in the path expression. Prefix
named parameters with $.
'lax $?(@.price > $o_price || @.tax > $o_tax)'


You can also pass JSON values in the PASSING clause. Use FORMAT JSON to
specify the format and ENCODING to specify the encoding:
PASSING orders.json_desc FORMAT JSON AS o_desc,
        orders.binary_record FORMAT JSON ENCODING UTF16 AS o_rec


The json_path value is case-sensitive. The SQL identifiers are uppercase. Use
quoted identifiers in the PASSING clause:
'lax $.keyvalue()?(@.name == $KeyName).value' PASSING nation.name AS KeyName --> ERROR; no passed value found
'lax $.keyvalue()?(@.name == $KeyName).value' PASSING nation.name AS "KeyName" --> correct


The PLAN clause specifies how to join columns from different paths. Use
OUTER or INNER to define how to join parent paths with their child paths.
Use CROSS or UNION to join siblings.
COLUMNS defines the schema of your table. Each column_definition specifies
how to extract and format your json_input value into a relational column.
PLAN is an optional clause to control how to process and join nested JSON
data.
ON ERROR specifies how to handle processing errors. ERROR ON ERROR throws an
error. EMPTY ON ERROR returns an empty result set.
column_name specifies a column name.
FOR ORDINALITY adds a row number column to the output table, starting at 1.
Specify the column name in the column definition:
row_num FOR ORDINALITY


NESTED PATH extracts data from nested levels of a json_input value. Each
NESTED PATH clause can contain column_definition values.
The json_table function returns a result set that you can use like any other
table in your queries. You can join the result set with other tables or
combine multiple arrays from your JSON data.
You can also process nested JSON objects without parsing the data multiple
times.
Use json_table as a lateral join to process JSON data from another table.

Examples#
The following query uses json_table to extract values from a JSON array and
return them as rows in a table with three columns:
SELECT
      *
FROM
      json_table(
                '[
                  {"id":1,"name":"Africa","wikiDataId":"Q15"},
                  {"id":2,"name":"Americas","wikiDataId":"Q828"},
                  {"id":3,"name":"Asia","wikiDataId":"Q48"},
                  {"id":4,"name":"Europe","wikiDataId":"Q51"}
                ]',
                'strict $' COLUMNS (
                  NESTED PATH 'strict $[*]' COLUMNS (
                    id integer PATH 'strict $.id',
                    name varchar PATH 'strict $.name',
                    wiki_data_id varchar PATH 'strict $."wikiDataId"'
                  )
                )
              );




id
child
wiki_data_id



1
Africa
Q1

2
Americas
Q828

3
Asia
Q48

4
Europe
Q51



The following query uses json_table to extract values from an array of nested
JSON objects. It flattens the nested JSON data into a single table. The example
query processes an array of continent names, where each continent contains an
array of countries and their populations.
The NESTED PATH 'lax $[*]' clause iterates through the continent objects,
while the NESTED PATH 'lax $.countries[*]' iterates through each country
within each continent. This creates a flat table structure with four rows
combining each continent with each of its countries. Continent values repeat for
each of their countries.
SELECT
      *
FROM
      json_table(
                '[
                    {"continent": "Asia", "countries": [
                        {"name": "Japan", "population": 125.7},
                        {"name": "Thailand", "population": 71.6}
                    ]},
                    {"continent": "Europe", "countries": [
                        {"name": "France", "population": 67.4},
                        {"name": "Germany", "population": 83.2}
                    ]}
                ]',
                'lax $' COLUMNS (
                    NESTED PATH 'lax $[*]' COLUMNS (
                        continent varchar PATH 'lax $.continent',
                        NESTED PATH 'lax $.countries[*]' COLUMNS (
                            country varchar PATH 'lax $.name',
                            population double PATH 'lax $.population'
                        )
                    )
                ));




continent
country
population



Asia
Japan
125.7

Asia
Thailand
71.6

Europe
France
67.4

Europe
Germany
83.2



The following query uses PLAN to specify an OUTER join between a parent path
and a child path:
SELECT
      *
FROM
      JSON_TABLE(
                '[]',
                'lax $' AS "root_path"
                COLUMNS(
                    a varchar(1) PATH 'lax "A"',
                    NESTED PATH 'lax $[*]' AS "nested_path"
                            COLUMNS (b varchar(1) PATH 'lax "B"'))
                PLAN ("root_path" OUTER "nested_path")
                );




a
b



A
null



The following query uses PLAN to specify an INNER join between a parent path
and a child path:
SELECT
      *
FROM
      JSON_TABLE(
                '[]',
                'lax $' AS "root_path"
                COLUMNS(
                    a varchar(1) PATH 'lax "A"',
                    NESTED PATH 'lax $[*]' AS "nested_path"
                            COLUMNS (b varchar(1) PATH 'lax "B"'))
                PLAN ("root_path" INNER "nested_path")
                );




a
b



null
null






json_array#
The json_array function creates a JSON array containing given elements.
JSON_ARRAY(
    [ array_element [, ...]
      [ { NULL ON NULL | ABSENT ON NULL } ] ],
    [ RETURNING type [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ] ]
    )



Argument types#
The array elements can be arbitrary expressions. Each passed value is converted
into a JSON item according to its type, and optional FORMAT and
ENCODING specification.
You can pass SQL values of types boolean, numeric, and character string. They
are converted to corresponding JSON literals:
SELECT json_array(true, 12e-1, 'text')
--> '[true,1.2,"text"]'


Additionally to SQL values, you can pass JSON values. They are character or
binary strings with a specified format and optional encoding:
SELECT json_array(
                  '[  "text"  ] ' FORMAT JSON,
                  X'5B0035005D00' FORMAT JSON ENCODING UTF16
                 )
--> '[["text"],[5]]'


You can also nest other JSON-returning functions. In that case, the FORMAT
option is implicit:
SELECT json_array(
                  json_query('{"key" : [  "value"  ]}', 'lax $.key')
                 )
--> '[["value"]]'


Other passed values are cast to varchar, and they become JSON text literals:
SELECT json_array(
                  DATE '2001-01-31',
                  UUID '12151fd2-7586-11e9-8f9e-2a86e4085a59'
                 )
--> '["2001-01-31","12151fd2-7586-11e9-8f9e-2a86e4085a59"]'


You can omit the arguments altogether to get an empty array:
SELECT json_array() --> '[]'




Null handling#
If a value passed for an array element is null, it is treated according to
the specified null treatment option. If ABSENT ON NULL is specified, the
null element is omitted in the result. If NULL ON NULL is specified, JSON
null is added to the result. ABSENT ON NULL is the default
configuration:
SELECT json_array(true, null, 1)
--> '[true,1]'

SELECT json_array(true, null, 1 ABSENT ON NULL)
--> '[true,1]'

SELECT json_array(true, null, 1 NULL ON NULL)
--> '[true,null,1]'




Returned type#
The SQL standard imposes that there is no dedicated data type to represent JSON
data in SQL. Instead, JSON data is represented as character or binary strings.
By default, the json_array function returns varchar containing the textual
representation of the JSON array. With the RETURNING clause, you can
specify other character string type:
SELECT json_array(true, 1 RETURNING VARCHAR(100))
--> '[true,1]'


You can also specify to use varbinary and the required encoding as return type.
The default encoding is UTF8:
SELECT json_array(true, 1 RETURNING VARBINARY)
--> X'5b 74 72 75 65 2c 31 5d'

SELECT json_array(true, 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF8)
--> X'5b 74 72 75 65 2c 31 5d'

SELECT json_array(true, 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF16)
--> X'5b 00 74 00 72 00 75 00 65 00 2c 00 31 00 5d 00'

SELECT json_array(true, 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF32)
--> X'5b 00 00 00 74 00 00 00 72 00 00 00 75 00 00 00 65 00 00 00 2c 00 00 00 31 00 00 00 5d 00 00 00'





json_object#
The json_object function creates a JSON object containing given key-value pairs.
JSON_OBJECT(
    [ key_value [, ...]
      [ { NULL ON NULL | ABSENT ON NULL } ] ],
      [ { WITH UNIQUE [ KEYS ] | WITHOUT UNIQUE [ KEYS ] } ]
    [ RETURNING type [ FORMAT JSON [ ENCODING { UTF8 | UTF16 | UTF32 } ] ] ]
    )



Argument passing conventions#
There are two conventions for passing keys and values:
SELECT json_object('key1' : 1, 'key2' : true)
--> '{"key1":1,"key2":true}'

SELECT json_object(KEY 'key1' VALUE 1, KEY 'key2' VALUE true)
--> '{"key1":1,"key2":true}'


In the second convention, you can omit the KEY keyword:
SELECT json_object('key1' VALUE 1, 'key2' VALUE true)
--> '{"key1":1,"key2":true}'




Argument types#
The keys can be arbitrary expressions. They must be of character string type.
Each key is converted into a JSON text item, and it becomes a key in the
created JSON object. Keys must not be null.
The values can be arbitrary expressions. Each passed value is converted
into a JSON item according to its type, and optional FORMAT and
ENCODING specification.
You can pass SQL values of types boolean, numeric, and character string. They
are converted to corresponding JSON literals:
SELECT json_object('x' : true, 'y' : 12e-1, 'z' : 'text')
--> '{"x":true,"y":1.2,"z":"text"}'


Additionally to SQL values, you can pass JSON values. They are character or
binary strings with a specified format and optional encoding:
SELECT json_object(
                   'x' : '[  "text"  ] ' FORMAT JSON,
                   'y' : X'5B0035005D00' FORMAT JSON ENCODING UTF16
                  )
--> '{"x":["text"],"y":[5]}'


You can also nest other JSON-returning functions. In that case, the FORMAT
option is implicit:
SELECT json_object(
                   'x' : json_query('{"key" : [  "value"  ]}', 'lax $.key')
                  )
--> '{"x":["value"]}'


Other passed values are cast to varchar, and they become JSON text literals:
SELECT json_object(
                   'x' : DATE '2001-01-31',
                   'y' : UUID '12151fd2-7586-11e9-8f9e-2a86e4085a59'
                  )
--> '{"x":"2001-01-31","y":"12151fd2-7586-11e9-8f9e-2a86e4085a59"}'


You can omit the arguments altogether to get an empty object:
SELECT json_object() --> '{}'




Null handling#
The values passed for JSON object keys must not be null. It is allowed to pass
null for JSON object values. A null value is treated according to the
specified null treatment option. If NULL ON NULL is specified, a JSON
object entry with null value is added to the result. If ABSENT ON NULL
is specified, the entry is omitted in the result. NULL ON NULL is the
default configuration.:
SELECT json_object('x' : null, 'y' : 1)
--> '{"x":null,"y":1}'

SELECT json_object('x' : null, 'y' : 1 NULL ON NULL)
--> '{"x":null,"y":1}'

SELECT json_object('x' : null, 'y' : 1 ABSENT ON NULL)
--> '{"y":1}'




Key uniqueness#
If a duplicate key is encountered, it is handled according to the specified key
uniqueness constraint.
If WITH UNIQUE KEYS is specified, a duplicate key results in a query
failure:
SELECT json_object('x' : null, 'x' : 1 WITH UNIQUE KEYS)
--> failure: "duplicate key passed to JSON_OBJECT function"


Note that this option is not supported if any of the arguments has a
FORMAT specification.
If WITHOUT UNIQUE KEYS is specified, duplicate keys are not supported due
to implementation limitation. WITHOUT UNIQUE KEYS is the default
configuration.


Returned type#
The SQL standard imposes that there is no dedicated data type to represent JSON
data in SQL. Instead, JSON data is represented as character or binary strings.
By default, the json_object function returns varchar containing the textual
representation of the JSON object. With the RETURNING clause, you can
specify other character string type:
SELECT json_object('x' : 1 RETURNING VARCHAR(100))
--> '{"x":1}'


You can also specify to use varbinary and the required encoding as return type.
The default encoding is UTF8:
SELECT json_object('x' : 1 RETURNING VARBINARY)
--> X'7b 22 78 22 3a 31 7d'

SELECT json_object('x' : 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF8)
--> X'7b 22 78 22 3a 31 7d'

SELECT json_object('x' : 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF16)
--> X'7b 00 22 00 78 00 22 00 3a 00 31 00 7d 00'

SELECT json_object('x' : 1 RETURNING VARBINARY FORMAT JSON ENCODING UTF32)
--> X'7b 00 00 00 22 00 00 00 78 00 00 00 22 00 00 00 3a 00 00 00 31 00 00 00 7d 00 00 00'



Warning
The following functions and operators are not compliant with the SQL
standard, and should be considered deprecated. According to the SQL
standard, there shall be no JSON data type. Instead, JSON values
should be represented as string values. The remaining functionality of the
following functions is covered by the functions described previously.




Cast to JSON#
The following types can be cast to JSON:

BOOLEAN
TINYINT
SMALLINT
INTEGER
BIGINT
REAL
DOUBLE
VARCHAR

Additionally, ARRAY, MAP, and ROW types can be cast to JSON when
the following requirements are met:

ARRAY types can be cast when the element type of the array is one
of the supported types.
MAP types can be cast when the key type of the map is VARCHAR and
the value type of the map is a supported type,
ROW types can be cast when every field type of the row is a supported
type.


Note
Cast operations with supported character string types treat the input as a string, not validated as JSON.
This means that a cast operation with a string-type input of invalid JSON
results in a successful cast to invalid JSON.
Instead, consider using the json_parse() function to
create validated JSON from a string.

The following examples show the behavior of casting to JSON with these types:
SELECT CAST(NULL AS JSON);
-- NULL

SELECT CAST(1 AS JSON);
-- JSON '1'

SELECT CAST(9223372036854775807 AS JSON);
-- JSON '9223372036854775807'

SELECT CAST('abc' AS JSON);
-- JSON '"abc"'

SELECT CAST(true AS JSON);
-- JSON 'true'

SELECT CAST(1.234 AS JSON);
-- JSON '1.234'

SELECT CAST(ARRAY[1, 23, 456] AS JSON);
-- JSON '[1,23,456]'

SELECT CAST(ARRAY[1, NULL, 456] AS JSON);
-- JSON '[1,null,456]'

SELECT CAST(ARRAY[ARRAY[1, 23], ARRAY[456]] AS JSON);
-- JSON '[[1,23],[456]]'

SELECT CAST(MAP(ARRAY['k1', 'k2', 'k3'], ARRAY[1, 23, 456]) AS JSON);
-- JSON '{"k1":1,"k2":23,"k3":456}'

SELECT CAST(CAST(ROW(123, 'abc', true) AS
            ROW(v1 BIGINT, v2 VARCHAR, v3 BOOLEAN)) AS JSON);
-- JSON '{"v1":123,"v2":"abc","v3":true}'


Casting from NULL to JSON is not straightforward. Casting
from a standalone NULL will produce SQL NULL instead of
JSON 'null'. However, when casting from arrays or map containing
NULLs, the produced JSON will have nulls in it.


Cast from JSON#
Casting to BOOLEAN, TINYINT, SMALLINT, INTEGER,
BIGINT, REAL, DOUBLE or VARCHAR is supported.
Casting to ARRAY and MAP is supported when the element type of
the array is one of the supported types, or when the key type of the map
is VARCHAR and value type of the map is one of the supported types.
Behaviors of the casts are shown with the examples below:
SELECT CAST(JSON 'null' AS VARCHAR);
-- NULL

SELECT CAST(JSON '1' AS INTEGER);
-- 1

SELECT CAST(JSON '9223372036854775807' AS BIGINT);
-- 9223372036854775807

SELECT CAST(JSON '"abc"' AS VARCHAR);
-- abc

SELECT CAST(JSON 'true' AS BOOLEAN);
-- true

SELECT CAST(JSON '1.234' AS DOUBLE);
-- 1.234

SELECT CAST(JSON '[1,23,456]' AS ARRAY(INTEGER));
-- [1, 23, 456]

SELECT CAST(JSON '[1,null,456]' AS ARRAY(INTEGER));
-- [1, NULL, 456]

SELECT CAST(JSON '[[1,23],[456]]' AS ARRAY(ARRAY(INTEGER)));
-- [[1, 23], [456]]

SELECT CAST(JSON '{"k1":1,"k2":23,"k3":456}' AS MAP(VARCHAR, INTEGER));
-- {k1=1, k2=23, k3=456}

SELECT CAST(JSON '{"v1":123,"v2":"abc","v3":true}' AS
            ROW(v1 BIGINT, v2 VARCHAR, v3 BOOLEAN));
-- {v1=123, v2=abc, v3=true}

SELECT CAST(JSON '[123,"abc",true]' AS
            ROW(v1 BIGINT, v2 VARCHAR, v3 BOOLEAN));
-- {v1=123, v2=abc, v3=true}


JSON arrays can have mixed element types and JSON maps can have mixed
value types. This makes it impossible to cast them to SQL arrays and maps in
some cases. To address this, Trino supports partial casting of arrays and maps:
SELECT CAST(JSON '[[1, 23], 456]' AS ARRAY(JSON));
-- [JSON '[1,23]', JSON '456']

SELECT CAST(JSON '{"k1": [1, 23], "k2": 456}' AS MAP(VARCHAR, JSON));
-- {k1 = JSON '[1,23]', k2 = JSON '456'}

SELECT CAST(JSON '[null]' AS ARRAY(JSON));
-- [JSON 'null']


When casting from JSON to ROW, both JSON array and JSON object are supported.


Other JSON functions#
In addition to the functions explained in more details in the preceding
sections, the following functions are available:


is_json_scalar(json) → boolean#
Determine if json is a scalar (i.e. a JSON number, a JSON string, true, false or null):
SELECT is_json_scalar('1');         -- true
SELECT is_json_scalar('[1, 2, 3]'); -- false





json_array_contains(json, value) → boolean#
Determine if value exists in json (a string containing a JSON array):
SELECT json_array_contains('[1, 2, 3]', 2); -- true





json_array_get(json_array, index) → json#

Warning
The semantics of this function are broken. If the extracted element
is a string, it will be converted into an invalid JSON value that
is not properly quoted (the value will not be surrounded by quotes
and any interior quotes will not be escaped).
We recommend against using this function. It cannot be fixed without
impacting existing usages and may be removed in a future release.

Returns the element at the specified index into the json_array.
The index is zero-based:
SELECT json_array_get('["a", [3, 9], "c"]', 0); -- JSON 'a' (invalid JSON)
SELECT json_array_get('["a", [3, 9], "c"]', 1); -- JSON '[3,9]'


This function also supports negative indexes for fetching element indexed
from the end of an array:
SELECT json_array_get('["c", [3, 9], "a"]', -1); -- JSON 'a' (invalid JSON)
SELECT json_array_get('["c", [3, 9], "a"]', -2); -- JSON '[3,9]'


If the element at the specified index doesn’t exist, the function returns null:
SELECT json_array_get('[]', 0);                -- NULL
SELECT json_array_get('["a", "b", "c"]', 10);  -- NULL
SELECT json_array_get('["c", "b", "a"]', -10); -- NULL





json_array_length(json) → bigint#
Returns the array length of json (a string containing a JSON array):
SELECT json_array_length('[1, 2, 3]'); -- 3





json_extract(json, json_path) → json#
Evaluates the JSONPath-like expression json_path on json
(a string containing JSON) and returns the result as a JSON string:
SELECT json_extract(json, '$.store.book');
SELECT json_extract(json, '$.store[book]');
SELECT json_extract(json, '$.store["book name"]');


The json_query function provides a more powerful and
feature-rich alternative to parse and extract JSON data.



json_extract_scalar(json, json_path) → varchar#
Like json_extract(), but returns the result value as a string (as opposed
to being encoded as JSON). The value referenced by json_path must be a
scalar (boolean, number or string).
SELECT json_extract_scalar('[1, 2, 3]', '$[2]');
SELECT json_extract_scalar(json, '$.store.book[0].author');





json_format(json) → varchar#
Returns the JSON text serialized from the input JSON value.
This is inverse function to json_parse().
SELECT json_format(JSON '[1, 2, 3]'); -- '[1,2,3]'
SELECT json_format(JSON '"a"');       -- '"a"'



Note
json_format() and CAST(json AS VARCHAR) have completely
different semantics.
json_format() serializes the input JSON value to JSON text conforming to
RFC 7159. The JSON value can be a JSON object, a JSON array, a JSON string,
a JSON number, true, false or null.
SELECT json_format(JSON '{"a": 1, "b": 2}'); -- '{"a":1,"b":2}'
SELECT json_format(JSON '[1, 2, 3]');        -- '[1,2,3]'
SELECT json_format(JSON '"abc"');            -- '"abc"'
SELECT json_format(JSON '42');               -- '42'
SELECT json_format(JSON 'true');             -- 'true'
SELECT json_format(JSON 'null');             -- 'null'


CAST(json AS VARCHAR) casts the JSON value to the corresponding SQL VARCHAR value.
For JSON string, JSON number, true, false or null, the cast
behavior is same as the corresponding SQL type. JSON object and JSON array
cannot be cast to VARCHAR.
SELECT CAST(JSON '{"a": 1, "b": 2}' AS VARCHAR); -- ERROR!
SELECT CAST(JSON '[1, 2, 3]' AS VARCHAR);        -- ERROR!
SELECT CAST(JSON '"abc"' AS VARCHAR);            -- 'abc' (the double quote is gone)
SELECT CAST(JSON '42' AS VARCHAR);               -- '42'
SELECT CAST(JSON 'true' AS VARCHAR);             -- 'true'
SELECT CAST(JSON 'null' AS VARCHAR);             -- NULL






json_parse(string) → json#
Returns the JSON value deserialized from the input JSON text.
This is inverse function to json_format():
SELECT json_parse('[1, 2, 3]');   -- JSON '[1,2,3]'
SELECT json_parse('"abc"');       -- JSON '"abc"'



Note
json_parse() and CAST(string AS JSON) have completely
different semantics.
json_parse() expects a JSON text conforming to RFC 7159, and returns
the JSON value deserialized from the JSON text.
The JSON value can be a JSON object, a JSON array, a JSON string, a JSON number,
true, false or null.
SELECT json_parse('not_json');         -- ERROR!
SELECT json_parse('["a": 1, "b": 2]'); -- JSON '["a": 1, "b": 2]'
SELECT json_parse('[1, 2, 3]');        -- JSON '[1,2,3]'
SELECT json_parse('"abc"');            -- JSON '"abc"'
SELECT json_parse('42');               -- JSON '42'
SELECT json_parse('true');             -- JSON 'true'
SELECT json_parse('null');             -- JSON 'null'


CAST(string AS JSON) takes any VARCHAR value as input, and returns
a JSON string with its value set to input string.
SELECT CAST('not_json' AS JSON);         -- JSON '"not_json"'
SELECT CAST('["a": 1, "b": 2]' AS JSON); -- JSON '"[\"a\": 1, \"b\": 2]"'
SELECT CAST('[1, 2, 3]' AS JSON);        -- JSON '"[1, 2, 3]"'
SELECT CAST('"abc"' AS JSON);            -- JSON '"\"abc\""'
SELECT CAST('42' AS JSON);               -- JSON '"42"'
SELECT CAST('true' AS JSON);             -- JSON '"true"'
SELECT CAST('null' AS JSON);             -- JSON '"null"'






json_size(json, json_path) → bigint#
Like json_extract(), but returns the size of the value.
For objects or arrays, the size is the number of members,
and the size of a scalar value is zero.
SELECT json_size('{"x": {"a": 1, "b": 2}}', '$.x');   -- 2
SELECT json_size('{"x": [1, 2, 3]}', '$.x');          -- 3
SELECT json_size('{"x": {"a": 1, "b": 2}}', '$.x.a'); -- 0



















 Previous  IP Address Functions 



  Next  Lambda expressions 











































Lambda expressions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Lambda expressions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON



 Lambda 
Lambda

Contents

Limitations

Examples





Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Limitations

Examples









Lambda expressions#
Lambda expressions are anonymous functions which are passed as
arguments to higher-order SQL functions.
Lambda expressions are written with ->:
x -> x + 1
(x, y) -> x + y
x -> regexp_like(x, 'a+')
x -> x[1] / x[2]
x -> IF(x > 0, x, -x)
x -> COALESCE(x, 0)
x -> CAST(x AS JSON)
x -> x + TRY(1 / 0)



Limitations#
Most SQL expressions can be used in a lambda body, with a few exceptions:

Subqueries are not supported: x -> 2 + (SELECT 3)
Aggregations are not supported: x -> max(y)



Examples#
Obtain the squared elements of an array column with transform():
SELECT numbers,
       transform(numbers, n -> n * n) as squared_numbers
FROM (
    VALUES
        (ARRAY[1, 2]),
        (ARRAY[3, 4]),
        (ARRAY[5, 6, 7])
) AS t(numbers);


  numbers  | squared_numbers
-----------+-----------------
 [1, 2]    | [1, 4]
 [3, 4]    | [9, 16]
 [5, 6, 7] | [25, 36, 49]
(3 rows)


The function transform() can be also employed to safely cast the elements
of an array to strings:
SELECT transform(prices, n -> TRY_CAST(n AS VARCHAR) || '$') as price_tags
FROM (
    VALUES
        (ARRAY[100, 200]),
        (ARRAY[30, 4])
) AS t(prices);


  price_tags
--------------
 [100$, 200$]
 [30$, 4$]
(2 rows)


Besides the array column being manipulated,
other columns can be captured as well within the lambda expression.
The following statement provides a showcase of this feature
for calculating the value of the linear function f(x) = ax + b
with transform():
SELECT xvalues,
       a,
       b,
       transform(xvalues, x -> a * x + b) as linear_function_values
FROM (
    VALUES
        (ARRAY[1, 2], 10, 5),
        (ARRAY[3, 4], 4, 2)
) AS t(xvalues, a, b);


 xvalues | a  | b | linear_function_values
---------+----+---+------------------------
 [1, 2]  | 10 | 5 | [15, 25]
 [3, 4]  |  4 | 2 | [14, 18]
(2 rows)


Find the array elements containing at least one value greater than 100
with any_match():
SELECT numbers
FROM (
    VALUES
        (ARRAY[1,NULL,3]),
        (ARRAY[10,20,30]),
        (ARRAY[100,200,300])
) AS t(numbers)
WHERE any_match(numbers, n ->  COALESCE(n, 0) > 100);
-- [100, 200, 300]


Capitalize the first word in a string via regexp_replace():
SELECT regexp_replace('once upon a time ...', '^(\w)(\w*)(\s+.*)$',x -> upper(x[1]) || x[2] || x[3]);
-- Once upon a time ...


Lambda expressions can be also applied in aggregation functions.
Following statement is a sample the overly complex calculation of the sum of all elements of a column
by making use of reduce_agg():
SELECT reduce_agg(value, 0, (a, b) -> a + b, (a, b) -> a + b) sum_values
FROM (
    VALUES (1), (2), (3), (4), (5)
) AS t(value);
-- 15


















 Previous  JSON functions and operators 



  Next  Logical operators 











































Logical operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Logical operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda



 Logical 
Logical

Contents

Logical operators

Effect of NULL on logical operators





Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Logical operators

Effect of NULL on logical operators









Logical operators#

Logical operators#


Operator
Description
Example



AND
True if both values are true
a AND b

OR
True if either value is true
a OR b

NOT
True if the value is false
NOT a





Effect of NULL on logical operators#
The result of an AND comparison may be NULL if one or both
sides of the expression are NULL. If at least one side of an
AND operator is FALSE the expression evaluates to FALSE:
SELECT CAST(null AS boolean) AND true; -- null

SELECT CAST(null AS boolean) AND false; -- false

SELECT CAST(null AS boolean) AND CAST(null AS boolean); -- null


The result of an OR comparison may be NULL if one or both
sides of the expression are NULL.  If at least one side of an
OR operator is TRUE the expression evaluates to TRUE:
SELECT CAST(null AS boolean) OR CAST(null AS boolean); -- null

SELECT CAST(null AS boolean) OR false; -- null

SELECT CAST(null AS boolean) OR true; -- true


The following truth table demonstrates the handling of
NULL in AND and OR:


a
b
a AND b
a OR b



TRUE
TRUE
TRUE
TRUE

TRUE
FALSE
FALSE
TRUE

TRUE
NULL
NULL
TRUE

FALSE
TRUE
FALSE
TRUE

FALSE
FALSE
FALSE
FALSE

FALSE
NULL
FALSE
NULL

NULL
TRUE
NULL
TRUE

NULL
FALSE
FALSE
NULL

NULL
NULL
NULL
NULL



The logical complement of NULL is NULL as shown in the following example:
SELECT NOT CAST(null AS boolean); -- null


The following truth table demonstrates the handling of NULL in NOT:


a
NOT a



TRUE
FALSE

FALSE
TRUE

NULL
NULL



















 Previous  Lambda expressions 



  Next  Machine learning functions 











































Machine learning functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Machine learning functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical



 Machine learning 
Machine learning

Contents

Feature vector

Classification

Regression

Machine learning functions

features()

learn_classifier()

learn_libsvm_classifier()

classify()

learn_regressor()

learn_libsvm_regressor()

regress()







Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Feature vector

Classification

Regression

Machine learning functions

features()

learn_classifier()

learn_libsvm_classifier()

classify()

learn_regressor()

learn_libsvm_regressor()

regress()











Machine learning functions#
The machine learning plugin provides machine learning functionality
as an aggregation function. It enables you to train Support Vector Machine (SVM)
based classifiers and regressors for the supervised learning problems.

Note
The machine learning functions are not optimized for distributed processing.
The capability to train large data sets is limited by this execution of the
final training on a single instance.


Feature vector#
To solve a problem with the machine learning technique, especially as a
supervised learning problem, it is necessary to represent the data set
with the sequence of pairs of labels and feature vector. A label is a
target value you want to predict from the unseen feature and a feature is a
A N-dimensional vector whose elements are numerical values. In Trino, a
feature vector is represented as a map-type value, whose key is an index
of each feature, so that it can express a sparse vector.
Since classifiers and regressors can recognize the map-type feature
vector, there is a function to construct the feature from the existing
numerical values, features():
SELECT features(1.0, 2.0, 3.0) AS features;


       features
-----------------------
 {0=1.0, 1=2.0, 2=3.0}


The output from features() can be directly passed to ML functions.


Classification#
Classification is a type of supervised learning problem to predict the distinct
label from the given feature vector. The interface looks similar to the
construction of the SVM model from the sequence of pairs of labels and features
implemented in Teradata Aster or BigQuery ML.
The function to train a classification model looks like as follows:
SELECT
  learn_classifier(
    species,
    features(sepal_length, sepal_width, petal_length, petal_width)
  ) AS model
FROM
  iris


It returns the trained model in a serialized format.
                      model
-------------------------------------------------
 3c 43 6c 61 73 73 69 66 69 65 72 28 76 61 72 63
 68 61 72 29 3e


classify() returns the predicted label by using the trained model.
The trained model can not be saved natively, and needs to be passed in
the format of a nested query:
SELECT
  classify(features(5.9, 3, 5.1, 1.8), model) AS predicted_label
FROM (
  SELECT
    learn_classifier(species, features(sepal_length, sepal_width, petal_length, petal_width)) AS model
  FROM
    iris
) t


 predicted_label
-----------------
 Iris-virginica


As a result you need to run the training process at the same time when predicting values.
Internally, the model is trained by libsvm.
You can use learn_libsvm_classifier() to control the internal parameters of the model.


Regression#
Regression is another type of supervised learning problem, predicting continuous
value, unlike the classification problem. The target must be numerical values that can
be described as double.
The following code shows the creation of the model predicting sepal_length
from the other 3 features:
SELECT
  learn_regressor(sepal_length, features(sepal_width, petal_length, petal_width)) AS model
FROM
  iris


The way to use the model is similar to the classification case:
SELECT
  regress(features(3, 5.1, 1.8), model) AS predicted_target
FROM (
  SELECT
    learn_regressor(sepal_length, features(sepal_width, petal_length, petal_width)) AS model
  FROM iris
) t;


 predicted_target
-------------------
 6.407376822560477


Internally, the model is trained by libsvm.
learn_libsvm_regressor() provides you a way to control the training process.


Machine learning functions#


features(double, ...) -> map(bigint, double)#
Returns the map representing the feature vector.



learn_classifier(label, features) → Classifier#
Returns an SVM-based classifier model, trained with the given label and feature data sets.



learn_libsvm_classifier(label, features, params) → Classifier#
Returns an SVM-based classifier model, trained with the given label and feature data sets.
You can control the training process by libsvm parameters.



classify(features, model) → label#
Returns a label predicted by the given classifier SVM model.



learn_regressor(target, features) → Regressor#
Returns an SVM-based regressor model, trained with the given target and feature data sets.



learn_libsvm_regressor(target, features, params) → Regressor#
Returns an SVM-based regressor model, trained with the given target and feature data sets.
You can control the training process by libsvm parameters.



regress(features, model) → target#
Returns a predicted target value by the given regressor SVM model.

















 Previous  Logical operators 



  Next  Map functions and operators 











































Map functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Map functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning



 Map 
Map

Contents

Subscript operator: []

Map functions

map()

map_from_entries()

multimap_from_entries()

map_entries()

map_concat()

map_filter()

map_keys()

map_values()

map_zip_with()

transform_keys()

transform_values()







Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Subscript operator: []

Map functions

map()

map_from_entries()

multimap_from_entries()

map_entries()

map_concat()

map_filter()

map_keys()

map_values()

map_zip_with()

transform_keys()

transform_values()











Map functions and operators#
Map functions and operators use the MAP type. Create a map with the
data type constructor using an array of keys and another array of
values in the same order. Keys must be character-based and can not be null.
Create an array with integer values
SELECT MAP(ARRAY['key1', 'key2', 'key3' ], ARRAY[2373, 3463, 45837]);
-- {key1=2373, key2=3463, key3=45837}


Create an array of character values:
SELECT MAP(ARRAY['key1', 'key2', 'key3' ], ARRAY['v1', 'v2', 'v3']);
-- {key1=v1, key2=v2, key3=v3}


Values must use the same type or it must be possible to coerce values to a
common type. The following example uses integer and decimal values and the
resulting array contains decimals:
SELECT MAP(ARRAY['key1', 'key2', 'key3' ], ARRAY[23, 34.63, 45.837]);
-- {key1=23.000, key2=34.630, key3=45.837}


Null values are allowed:
SELECT MAP(ARRAY['key1', 'key2', 'key3' ], ARRAY['v1', NULL, 'v3']);
-- {key1=v1, key2=NULL, key3=v3}



Subscript operator: []#
The [] operator is used to retrieve the value corresponding to a given key from a map.
This operator throws an error if the key is not contained in the map.
See also element_at function that returns NULL in such case.
SELECT name_to_age_map['Bob'] AS bob_age;


The following example constructs a map and then accesses the element with the
the key key2:
SELECT MAP(ARRAY['key1', 'key2', 'key3' ], ARRAY['v1', 'v2', 'v3'])['key2'];
-- v2




Map functions#


cardinality(x) → bigint
Returns the cardinality (size) of the map x.



element_at(map(K, V), key) → V
Returns value for given key, or NULL if the key is not contained in the map.



map() → map<unknown, unknown>#
Returns an empty map.
SELECT map();
-- {}





map(array(K), array(V)) -> map(K, V)
Returns a map created using the given key/value arrays.
SELECT map(ARRAY[1,3], ARRAY[2,4]);
-- {1 -> 2, 3 -> 4}


See also map_agg() and multimap_agg() for creating a map as an aggregation.



map_from_entries(array(row(K, V))) -> map(K, V)#
Returns a map created from the given array of entries.
SELECT map_from_entries(ARRAY[(1, 'x'), (2, 'y')]);
-- {1 -> 'x', 2 -> 'y'}





multimap_from_entries(array(row(K, V))) -> map(K, array(V))#
Returns a multimap created from the given array of entries. Each key can be associated with multiple values.
SELECT multimap_from_entries(ARRAY[(1, 'x'), (2, 'y'), (1, 'z')]);
-- {1 -> ['x', 'z'], 2 -> ['y']}





map_entries(map(K, V)) -> array(row(K, V))#
Returns an array of all entries in the given map.
SELECT map_entries(MAP(ARRAY[1, 2], ARRAY['x', 'y']));
-- [ROW(1, 'x'), ROW(2, 'y')]





map_concat(map1(K, V), map2(K, V), ..., mapN(K, V)) -> map(K, V)#
Returns the union of all the given maps. If a key is found in multiple given maps,
that key’s value in the resulting map comes from the last one of those maps.



map_filter(map(K, V), function(K, V, boolean)) -> map(K, V)#
Constructs a map from those entries of map for which function returns true:
SELECT map_filter(MAP(ARRAY[], ARRAY[]), (k, v) -> true);
-- {}

SELECT map_filter(MAP(ARRAY[10, 20, 30], ARRAY['a', NULL, 'c']),
                  (k, v) -> v IS NOT NULL);
-- {10 -> a, 30 -> c}

SELECT map_filter(MAP(ARRAY['k1', 'k2', 'k3'], ARRAY[20, 3, 15]),
                  (k, v) -> v > 10);
-- {k1 -> 20, k3 -> 15}





map_keys(x(K, V)) -> array(K)#
Returns all the keys in the map x.



map_values(x(K, V)) -> array(V)#
Returns all the values in the map x.



map_zip_with(map(K, V1), map(K, V2), function(K, V1, V2, V3)) -> map(K, V3)#
Merges the two given maps into a single map by applying function to the pair of values with the same key.
For keys only presented in one map, NULL will be passed as the value for the missing key.
SELECT map_zip_with(MAP(ARRAY[1, 2, 3], ARRAY['a', 'b', 'c']),
                    MAP(ARRAY[1, 2, 3], ARRAY['d', 'e', 'f']),
                    (k, v1, v2) -> concat(v1, v2));
-- {1 -> ad, 2 -> be, 3 -> cf}

SELECT map_zip_with(MAP(ARRAY['k1', 'k2'], ARRAY[1, 2]),
                    MAP(ARRAY['k2', 'k3'], ARRAY[4, 9]),
                    (k, v1, v2) -> (v1, v2));
-- {k1 -> ROW(1, null), k2 -> ROW(2, 4), k3 -> ROW(null, 9)}

SELECT map_zip_with(MAP(ARRAY['a', 'b', 'c'], ARRAY[1, 8, 27]),
                    MAP(ARRAY['a', 'b', 'c'], ARRAY[1, 2, 3]),
                    (k, v1, v2) -> k || CAST(v1 / v2 AS VARCHAR));
-- {a -> a1, b -> b4, c -> c9}





transform_keys(map(K1, V), function(K1, V, K2)) -> map(K2, V)#
Returns a map that applies function to each entry of map and transforms the keys:
SELECT transform_keys(MAP(ARRAY[], ARRAY[]), (k, v) -> k + 1);
-- {}

SELECT transform_keys(MAP(ARRAY [1, 2, 3], ARRAY ['a', 'b', 'c']),
                      (k, v) -> k + 1);
-- {2 -> a, 3 -> b, 4 -> c}

SELECT transform_keys(MAP(ARRAY ['a', 'b', 'c'], ARRAY [1, 2, 3]),
                      (k, v) -> v * v);
-- {1 -> 1, 4 -> 2, 9 -> 3}

SELECT transform_keys(MAP(ARRAY ['a', 'b'], ARRAY [1, 2]),
                      (k, v) -> k || CAST(v as VARCHAR));
-- {a1 -> 1, b2 -> 2}

SELECT transform_keys(MAP(ARRAY [1, 2], ARRAY [1.0, 1.4]),
                      (k, v) -> MAP(ARRAY[1, 2], ARRAY['one', 'two'])[k]);
-- {one -> 1.0, two -> 1.4}





transform_values(map(K, V1), function(K, V1, V2)) -> map(K, V2)#
Returns a map that applies function to each entry of map and transforms the values:
SELECT transform_values(MAP(ARRAY[], ARRAY[]), (k, v) -> v + 1);
-- {}

SELECT transform_values(MAP(ARRAY [1, 2, 3], ARRAY [10, 20, 30]),
                        (k, v) -> v + k);
-- {1 -> 11, 2 -> 22, 3 -> 33}

SELECT transform_values(MAP(ARRAY [1, 2, 3], ARRAY ['a', 'b', 'c']),
                        (k, v) -> k * k);
-- {1 -> 1, 2 -> 4, 3 -> 9}

SELECT transform_values(MAP(ARRAY ['a', 'b'], ARRAY [1, 2]),
                        (k, v) -> k || CAST(v as VARCHAR));
-- {a -> a1, b -> b2}

SELECT transform_values(MAP(ARRAY [1, 2], ARRAY [1.0, 1.4]),
                        (k, v) -> MAP(ARRAY[1, 2], ARRAY['one', 'two'])[k]
                          || '_' || CAST(v AS VARCHAR));
-- {1 -> one_1.0, 2 -> two_1.4}



















 Previous  Machine learning functions 



  Next  Mathematical functions and operators 











































Mathematical functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Mathematical functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map



 Math 
Math

Contents

Mathematical operators

Mathematical functions

abs()

cbrt()

ceil()

ceiling()

degrees()

e()

exp()

floor()

ln()

log()

log2()

log10()

mod()

pi()

pow()

power()

radians()

round()

sign()

sqrt()

truncate()

width_bucket()



Random functions

rand()

random()



Trigonometric functions

acos()

asin()

atan()

atan2()

cos()

cosh()

sin()

sinh()

tan()

tanh()



Geometric functions

cosine_distance()

cosine_similarity()



Floating point functions

infinity()

is_finite()

is_infinite()

is_nan()

nan()



Base conversion functions

from_base()

to_base()



Statistical functions

t_pdf()

wilson_interval_lower()

wilson_interval_upper()



Cumulative distribution functions

beta_cdf()

inverse_beta_cdf()

inverse_normal_cdf()

normal_cdf()

t_cdf()







Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Mathematical operators

Mathematical functions

abs()

cbrt()

ceil()

ceiling()

degrees()

e()

exp()

floor()

ln()

log()

log2()

log10()

mod()

pi()

pow()

power()

radians()

round()

sign()

sqrt()

truncate()

width_bucket()



Random functions

rand()

random()



Trigonometric functions

acos()

asin()

atan()

atan2()

cos()

cosh()

sin()

sinh()

tan()

tanh()



Geometric functions

cosine_distance()

cosine_similarity()



Floating point functions

infinity()

is_finite()

is_infinite()

is_nan()

nan()



Base conversion functions

from_base()

to_base()



Statistical functions

t_pdf()

wilson_interval_lower()

wilson_interval_upper()



Cumulative distribution functions

beta_cdf()

inverse_beta_cdf()

inverse_normal_cdf()

normal_cdf()

t_cdf()











Mathematical functions and operators#

Mathematical operators#


Operator
Description



+
Addition

-
Subtraction

*
Multiplication

/
Division (integer division performs truncation)

%
Modulus (remainder)





Mathematical functions#


abs(x) → [same as input]#
Returns the absolute value of x.



cbrt(x) → double#
Returns the cube root of x.



ceil(x) → [same as input]#
This is an alias for ceiling().



ceiling(x) → [same as input]#
Returns x rounded up to the nearest integer.



degrees(x) → double#
Converts angle x in radians to degrees.



e() → double#
Returns the constant Euler’s number.



exp(x) → double#
Returns Euler’s number raised to the power of x.



floor(x) → [same as input]#
Returns x rounded down to the nearest integer.



ln(x) → double#
Returns the natural logarithm of x.



log(b, x) → double#
Returns the base b logarithm of x.



log2(x) → double#
Returns the base 2 logarithm of x.



log10(x) → double#
Returns the base 10 logarithm of x.



mod(n, m) → [same as input]#
Returns the modulus (remainder) of n divided by m.



pi() → double#
Returns the constant Pi.



pow(x, p) → double#
This is an alias for power().



power(x, p) → double#
Returns x raised to the power of p.



radians(x) → double#
Converts angle x in degrees to radians.



round(x) → [same as input]#
Returns x rounded to the nearest integer.



round(x, d) → [same as input]
Returns x rounded to d decimal places.



sign(x) → [same as input]#
Returns the signum function of x, that is:

0 if the argument is 0,
1 if the argument is greater than 0,
-1 if the argument is less than 0.

For floating point arguments, the function additionally returns:

-0 if the argument is -0,
NaN if the argument is NaN,
1 if the argument is +Infinity,
-1 if the argument is -Infinity.




sqrt(x) → double#
Returns the square root of x.



truncate(x) → double#
Returns x rounded to integer by dropping digits after decimal point.



width_bucket(x, bound1, bound2, n) → bigint#
Returns the bin number of x in an equi-width histogram with the
specified bound1 and bound2 bounds and n number of buckets.



width_bucket(x, bins) → bigint
Returns the bin number of x according to the bins specified by the
array bins. The bins parameter must be an array of doubles and is
assumed to be in sorted ascending order.



Random functions#


rand() → double#
This is an alias for random().



random() → double#
Returns a pseudo-random value in the range 0.0 <= x < 1.0.



random(n) → [same as input]
Returns a pseudo-random number between 0 and n (exclusive).



random(m, n) → [same as input]
Returns a pseudo-random number between m and n (exclusive).



Trigonometric functions#
All trigonometric function arguments are expressed in radians.
See unit conversion functions degrees() and radians().


acos(x) → double#
Returns the arc cosine of x.



asin(x) → double#
Returns the arc sine of x.



atan(x) → double#
Returns the arc tangent of x.



atan2(y, x) → double#
Returns the arc tangent of y / x.



cos(x) → double#
Returns the cosine of x.



cosh(x) → double#
Returns the hyperbolic cosine of x.



sin(x) → double#
Returns the sine of x.



sinh(x) → double#
Returns the hyperbolic sine of x.



tan(x) → double#
Returns the tangent of x.



tanh(x) → double#
Returns the hyperbolic tangent of x.



Geometric functions#


cosine_distance(array(double), array(double)) → double#
Calculates the cosine distance between two dense vectors:
SELECT cosine_distance(ARRAY[1.0, 2.0], ARRAY[3.0, 4.0]);
-- 0.01613008990009257





cosine_similarity(array(double), array(double)) → double#
Calculates the cosine similarity of two dense vectors:
SELECT cosine_similarity(ARRAY[1.0, 2.0], ARRAY[3.0, 4.0]);
-- 0.9838699100999074





cosine_similarity(x, y) → double
Calculates the cosine similarity of two sparse vectors:
SELECT cosine_similarity(MAP(ARRAY['a'], ARRAY[1.0]), MAP(ARRAY['a'], ARRAY[2.0]));
-- 1.0





Floating point functions#


infinity() → double#
Returns the constant representing positive infinity.



is_finite(x) → boolean#
Determine if x is finite.



is_infinite(x) → boolean#
Determine if x is infinite.



is_nan(x) → boolean#
Determine if x is not-a-number.



nan() → double#
Returns the constant representing not-a-number.



Base conversion functions#


from_base(string, radix) → bigint#
Returns the value of string interpreted as a base-radix number.



to_base(x, radix) → varchar#
Returns the base-radix representation of x.



Statistical functions#


t_pdf(x, df) → double#
Computes the Student’s t-distribution probability density function for given x and
degrees of freedom (df). The x must be a real value and degrees of freedom must be
an integer and positive value.



wilson_interval_lower(successes, trials, z) → double#
Returns the lower bound of the Wilson score interval of a Bernoulli trial process
at a confidence specified by the z-score z.



wilson_interval_upper(successes, trials, z) → double#
Returns the upper bound of the Wilson score interval of a Bernoulli trial process
at a confidence specified by the z-score z.



Cumulative distribution functions#


beta_cdf(a, b, v) → double#
Compute the Beta cdf with given a, b parameters:  P(N < v; a, b).
The a, b parameters must be positive real numbers and value v must be a real value.
The value v must lie on the interval [0, 1].



inverse_beta_cdf(a, b, p) → double#
Compute the inverse of the Beta cdf with given a, b parameters for the cumulative
probability (p): P(N < n). The a, b parameters must be positive real values.
The probability p must lie on the interval [0, 1].



inverse_normal_cdf(mean, sd, p) → double#
Compute the inverse of the Normal cdf with given mean and standard
deviation (sd) for the cumulative probability (p): P(N < n). The mean must be
a real value and the standard deviation must be a real and positive value.
The probability p must lie on the interval (0, 1).



normal_cdf(mean, sd, v) → double#
Compute the Normal cdf with given mean and standard deviation (sd):  P(N < v; mean, sd).
The mean and value v must be real values and the standard deviation must be a real
and positive value.



t_cdf(x, df) → double#
Compute the Student’s t-distribution cumulative density function for given x and degrees of freedom (df).
The x must be a real value and degrees of freedom must be an integer and positive value.

















 Previous  Map functions and operators 



  Next  Quantile digest functions 











































Quantile digest functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Quantile digest functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math



 Quantile digest 
Quantile digest

Contents

Data structures

Functions

value_at_quantile()

quantile_at_value()

values_at_quantiles()

qdigest_agg()







Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Data structures

Functions

value_at_quantile()

quantile_at_value()

values_at_quantiles()

qdigest_agg()











Quantile digest functions#

Data structures#
A quantile digest is a data sketch which stores approximate percentile
information.  The Trino type for this data structure is called qdigest,
and it takes a parameter which must be one of bigint, double or
real which represent the set of numbers that may be ingested by the
qdigest.  They may be merged without losing precision, and for storage
and retrieval they may be cast to/from VARBINARY.


Functions#


merge(qdigest) → qdigest
Merges all input qdigests into a single qdigest.



value_at_quantile(qdigest(T), quantile) → T#
Returns the approximate percentile value from the quantile digest given
the number quantile between 0 and 1.



quantile_at_value(qdigest(T), T) → quantile#
Returns the approximate quantile number between 0 and 1 from the
quantile digest given an input value. Null is returned if the quantile digest
is empty or the input value is outside of the range of the quantile digest.



values_at_quantiles(qdigest(T), quantiles) -> array(T)#
Returns the approximate percentile values as an array given the input
quantile digest and array of values between 0 and 1 which
represent the quantiles to return.



qdigest_agg(x) -> qdigest([same as x])#
Returns the qdigest which is composed of  all input values of x.



qdigest_agg(x, w) -> qdigest([same as x])
Returns the qdigest which is composed of  all input values of x using
the per-item weight w.



qdigest_agg(x, w, accuracy) -> qdigest([same as x])
Returns the qdigest which is composed of  all input values of x using
the per-item weight w and maximum error of accuracy. accuracy
must be a value greater than zero and less than one, and it must be constant
for all input rows.

















 Previous  Mathematical functions and operators 



  Next  Regular expression functions 











































Regular expression functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Regular expression functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest



 Regular expression 
Regular expression

Contents

regexp_count()

regexp_extract_all()

regexp_extract()

regexp_like()

regexp_position()

regexp_replace()

regexp_split()





Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

regexp_count()

regexp_extract_all()

regexp_extract()

regexp_like()

regexp_position()

regexp_replace()

regexp_split()









Regular expression functions#
All of the regular expression functions use the Java pattern syntax,
with a few notable exceptions:

When using multi-line mode (enabled via the (?m) flag),
only \n is recognized as a line terminator. Additionally,
the (?d) flag is not supported and must not be used.
Case-insensitive matching (enabled via the (?i) flag) is always
performed in a Unicode-aware manner. However, context-sensitive and
local-sensitive matching is not supported. Additionally, the
(?u) flag is not supported and must not be used.
Surrogate pairs are not supported. For example, \uD800\uDC00 is
not treated as U+10000 and must be specified as \x{10000}.
Boundaries (\b) are incorrectly handled for a non-spacing mark
without a base character.
\Q and \E are not supported in character classes
(such as [A-Z123]) and are instead treated as literals.
Unicode character classes (\p{prop}) are supported with
the following differences:

All underscores in names must be removed. For example, use
OldItalic instead of Old_Italic.
Scripts must be specified directly, without the
Is, script= or sc= prefixes.
Example: \p{Hiragana}
Blocks must be specified with the In prefix.
The block= and blk= prefixes are not supported.
Example: \p{Mongolian}
Categories must be specified directly, without the Is,
general_category= or gc= prefixes.
Example: \p{L}
Binary properties must be specified directly, without the Is.
Example: \p{NoncharacterCodePoint}





regexp_count(string, pattern) → bigint#
Returns the number of occurrence of pattern in string:
SELECT regexp_count('1a 2b 14m', '\s*[a-z]+\s*'); -- 3





regexp_extract_all(string, pattern)#
Returns the substring(s) matched by the regular expression pattern
in string:
SELECT regexp_extract_all('1a 2b 14m', '\d+'); -- [1, 2, 14]





regexp_extract_all(string, pattern, group)
Finds all occurrences of the regular expression pattern in string
and returns the capturing group number group:
SELECT regexp_extract_all('1a 2b 14m', '(\d+)([a-z]+)', 2); -- ['a', 'b', 'm']





regexp_extract(string, pattern) → varchar#
Returns the first substring matched by the regular expression pattern
in string:
SELECT regexp_extract('1a 2b 14m', '\d+'); -- 1





regexp_extract(string, pattern, group) → varchar
Finds the first occurrence of the regular expression pattern in
string and returns the capturing group number group:
SELECT regexp_extract('1a 2b 14m', '(\d+)([a-z]+)', 2); -- 'a'





regexp_like(string, pattern) → boolean#
Evaluates the regular expression pattern and determines if it is
contained within string.
The pattern only needs to be contained within
string, rather than needing to match all of string. In other words,
this performs a contains operation rather than a match operation. You can
match the entire string by anchoring the pattern using ^ and $:
SELECT regexp_like('1a 2b 14m', '\d+b'); -- true





regexp_position(string, pattern) → integer#
Returns the index of the first occurrence (counting from 1) of pattern in string.
Returns -1 if not found:
SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\b\d+\b'); -- 8





regexp_position(string, pattern, start) → integer
Returns the index of the first occurrence of pattern in string,
starting from start (include start). Returns -1 if not found:
SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\b\d+\b', 5); -- 8
SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\b\d+\b', 12); -- 19





regexp_position(string, pattern, start, occurrence) → integer
Returns the index of the nth occurrence of pattern in string,
starting from start (include start). Returns -1 if not found:
SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\b\d+\b', 12, 1); -- 19
SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\b\d+\b', 12, 2); -- 31
SELECT regexp_position('I have 23 apples, 5 pears and 13 oranges', '\b\d+\b', 12, 3); -- -1





regexp_replace(string, pattern) → varchar#
Removes every instance of the substring matched by the regular expression
pattern from string:
SELECT regexp_replace('1a 2b 14m', '\d+[ab] '); -- '14m'





regexp_replace(string, pattern, replacement) → varchar
Replaces every instance of the substring matched by the regular expression
pattern in string with replacement. Capturing groups can be
referenced in replacement using $g for a numbered group or
${name} for a named group. A dollar sign ($) may be included in the
replacement by escaping it with a backslash (\$):
SELECT regexp_replace('1a 2b 14m', '(\d+)([ab]) ', '3c$2 '); -- '3ca 3cb 14m'





regexp_replace(string, pattern, function) → varchar
Replaces every instance of the substring matched by the regular expression
pattern in string using function. The lambda expression
function is invoked for each match with the capturing groups passed as an
array. Capturing group numbers start at one; there is no group for the entire match
(if you need this, surround the entire expression with parenthesis).
SELECT regexp_replace('new york', '(\w)(\w*)', x -> upper(x[1]) || lower(x[2])); --'New York'





regexp_split(string, pattern)#
Splits string using the regular expression pattern and returns an
array. Trailing empty strings are preserved:
SELECT regexp_split('1a 2b 14m', '\s*[a-z]+\s*'); -- [1, 2, 14, ]


















 Previous  Quantile digest functions 



  Next  Session information 











































Session information — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Session information 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression



 Session 
Session

Contents

current_user

current_groups()

current_catalog

current_schema





Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

current_user

current_groups()

current_catalog

current_schema









Session information#
Functions providing information about the query execution environment.


current_user#
Returns the current user running the query.



current_groups()#
Returns the list of groups for the current user running the query.



current_catalog#
Returns a character string that represents the current catalog name.



current_schema#
Returns a character string that represents the current unqualified schema name.

Note
This is part of the SQL standard and does not use parenthesis.

















 Previous  Regular expression functions 



  Next  Set Digest functions 











































Set Digest functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Set Digest functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session



 Set Digest 
Set Digest

Contents

Data structures

Serialization

Functions

make_set_digest()

merge_set_digest()

intersection_cardinality()

jaccard_index()

hash_counts()







String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Data structures

Serialization

Functions

make_set_digest()

merge_set_digest()

intersection_cardinality()

jaccard_index()

hash_counts()











Set Digest functions#
Trino offers several functions that deal with the
MinHash technique.
MinHash is used to quickly estimate the
Jaccard similarity coefficient
between two sets.
It is commonly used in data mining to detect near-duplicate web pages at scale.
By using this information, the search engines efficiently avoid showing
within the search results two pages that are nearly identical.
The following example showcases how the Set Digest functions can be
used to naively estimate the similarity between texts. The input texts
are split by using the function ngrams() to
4-shingles which are
used as input for creating a set digest of each initial text.
The set digests are compared to each other to get an
approximation of the similarity of their corresponding
initial texts:
WITH text_input(id, text) AS (
         VALUES
             (1, 'The quick brown fox jumps over the lazy dog'),
             (2, 'The quick and the lazy'),
             (3, 'The quick brown fox jumps over the dog')
     ),
     text_ngrams(id, ngrams) AS (
         SELECT id,
                transform(
                  ngrams(
                    split(text, ' '),
                    4
                  ),
                  token -> array_join(token, ' ')
                )
         FROM text_input
     ),
     minhash_digest(id, digest) AS (
         SELECT id,
                (SELECT make_set_digest(v) FROM unnest(ngrams) u(v))
         FROM text_ngrams
     ),
     setdigest_side_by_side(id1, digest1, id2, digest2) AS (
         SELECT m1.id as id1,
                m1.digest as digest1,
                m2.id as id2,
                m2.digest as digest2
         FROM (SELECT id, digest FROM minhash_digest) m1
         JOIN (SELECT id, digest FROM minhash_digest) m2
           ON m1.id != m2.id AND m1.id < m2.id
     )
SELECT id1,
       id2,
       intersection_cardinality(digest1, digest2) AS intersection_cardinality,
       jaccard_index(digest1, digest2)            AS jaccard_index
FROM setdigest_side_by_side
ORDER BY id1, id2;


 id1 | id2 | intersection_cardinality | jaccard_index
-----+-----+--------------------------+---------------
   1 |   2 |                        0 |           0.0
   1 |   3 |                        4 |           0.6
   2 |   3 |                        0 |           0.0


The above result listing points out, as expected, that the texts
with the id 1 and 3 are quite similar.
One may argue that the text with the id 2 is somewhat similar to
the texts with the id 1 and 3. Due to the fact in the example above
4-shingles are taken into account for measuring the similarity of the texts,
there are no intersections found for the text pairs 1 and 2, respectively
3 and 2 and therefore there the similarity index for these text pairs
is 0.

Data structures#
Trino implements Set Digest data sketches by encapsulating the following components:

HyperLogLog
MinHash with a single hash function

The HyperLogLog structure is used for the approximation of the distinct elements
in the original set.
The MinHash structure is used to store a low memory footprint signature of the original set.
The similarity of any two sets is estimated by comparing their signatures.
The Trino type for this data structure is called setdigest.
Trino offers the ability to merge multiple Set Digest data sketches.


Serialization#
Data sketches can be serialized to and deserialized from varbinary. This
allows them to be stored for later use.


Functions#


make_set_digest(x) → setdigest#
Composes all input values of x into a setdigest.
Create a setdigest corresponding to a bigint array:
SELECT make_set_digest(value)
FROM (VALUES 1, 2, 3) T(value);


Create a setdigest corresponding to a varchar array:
SELECT make_set_digest(value)
FROM (VALUES 'Trino', 'SQL', 'on', 'everything') T(value);





merge_set_digest(setdigest) → setdigest#
Returns the setdigest of the aggregate union of the individual setdigest
Set Digest structures.



cardinality(setdigest) → long
Returns the cardinality of the set digest from its internal
HyperLogLog component.
Examples:
SELECT cardinality(make_set_digest(value))
FROM (VALUES 1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5) T(value);
-- 5





intersection_cardinality(x, y) → long#
Returns the estimation for the cardinality of the intersection of the two set digests.
x and y must be of type  setdigest
Examples:
SELECT intersection_cardinality(make_set_digest(v1), make_set_digest(v2))
FROM (VALUES (1, 1), (NULL, 2), (2, 3), (3, 4)) T(v1, v2);
-- 3





jaccard_index(x, y) → double#
Returns the estimation of Jaccard index for
the two set digests.
x and y must be of type  setdigest.
Examples:
SELECT jaccard_index(make_set_digest(v1), make_set_digest(v2))
FROM (VALUES (1, 1), (NULL,2), (2, 3), (NULL, 4)) T(v1, v2);
-- 0.5





hash_counts(x)#
Returns a map containing the Murmur3Hash128
hashed values and the count of their occurences within
the internal MinHash structure belonging to x.
x must be of type  setdigest.
Examples:
SELECT hash_counts(make_set_digest(value))
FROM (VALUES 1, 1, 1, 2, 2) T(value);
-- {19144387141682250=3, -2447670524089286488=2}



















 Previous  Session information 



  Next  String functions and operators 











































String functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 String functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest



 String 
String

Contents

String operators

String functions

chr()

codepoint()

concat()

concat_ws()

hamming_distance()

length()

levenshtein_distance()

lower()

lpad()

ltrim()

luhn_check()

position()

replace()

reverse()

rpad()

rtrim()

soundex()

split()

split_part()

split_to_map()

split_to_multimap()

strpos()

starts_with()

substr()

substring()

translate()

trim()

upper()

word_stem()



Unicode functions

normalize()

to_utf8()

from_utf8()







System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

String operators

String functions

chr()

codepoint()

concat()

concat_ws()

hamming_distance()

length()

levenshtein_distance()

lower()

lpad()

ltrim()

luhn_check()

position()

replace()

reverse()

rpad()

rtrim()

soundex()

split()

split_part()

split_to_map()

split_to_multimap()

strpos()

starts_with()

substr()

substring()

translate()

trim()

upper()

word_stem()



Unicode functions

normalize()

to_utf8()

from_utf8()











String functions and operators#

String operators#
The || operator performs concatenation.
The LIKE statement can be used for pattern matching and is documented in
Pattern comparison: LIKE.


String functions#

Note
These functions assume that the input strings contain valid UTF-8 encoded
Unicode code points.  There are no explicit checks for valid UTF-8 and
the functions may return incorrect results on invalid UTF-8.
Invalid UTF-8 data can be corrected with from_utf8().
Additionally, the functions operate on Unicode code points and not user
visible characters (or grapheme clusters).  Some languages combine
multiple code points into a single user-perceived character, the basic
unit of a writing system for a language, but the functions will treat each
code point as a separate unit.
The lower() and upper() functions do not perform
locale-sensitive, context-sensitive, or one-to-many mappings required for
some languages. Specifically, this will return incorrect results for
Lithuanian, Turkish and Azeri.



chr(n) → varchar#
Returns the Unicode code point n as a single character string.



codepoint(string) → integer#
Returns the Unicode code point of the only character of string.



concat(string1, ..., stringN) → varchar#
Returns the concatenation of string1, string2, ..., stringN.
This function provides the same functionality as the
SQL-standard concatenation operator (||).



concat_ws(string0, string1, ..., stringN) → varchar#
Returns the concatenation of string1, string2, ..., stringN
using string0 as a separator. If string0 is null, then the return
value is null. Any null values provided in the arguments after the
separator are skipped.



concat_ws(string0, array(varchar)) → varchar
Returns the concatenation of elements in the array using string0 as a
separator. If string0 is null, then the return value is null. Any
null values in the array are skipped.



format(format, args...) → varchar
See format().



hamming_distance(string1, string2) → bigint#
Returns the Hamming distance of string1 and string2,
i.e. the number of positions at which the corresponding characters are different.
Note that the two strings must have the same length.



length(string) → bigint#
Returns the length of string in characters.



levenshtein_distance(string1, string2) → bigint#
Returns the Levenshtein edit distance of string1 and string2,
i.e. the minimum number of single-character edits (insertions,
deletions or substitutions) needed to change string1 into string2.



lower(string) → varchar#
Converts string to lowercase.



lpad(string, size, padstring) → varchar#
Left pads string to size characters with padstring.
If size is less than the length of string, the result is
truncated to size characters. size must not be negative
and padstring must be non-empty.



ltrim(string) → varchar#
Removes leading whitespace from string.



luhn_check(string) → boolean#
Tests whether a string of digits is valid according to the
Luhn algorithm.
This checksum function, also known as modulo 10 or mod 10, is
widely applied on credit card numbers and government identification numbers
to distinguish valid numbers from mistyped, incorrect numbers.
Valid identification number:
select luhn_check('79927398713');
-- true


Invalid identification number:
select luhn_check('79927398714');
-- false





position(substring IN string) → bigint#
Returns the starting position of the first instance of substring in
string. Positions start with 1. If not found, 0 is returned.

Note
This SQL-standard function has special syntax and uses the
IN keyword for the arguments. See also strpos().




replace(string, search) → varchar#
Removes all instances of search from string.



replace(string, search, replace) → varchar
Replaces all instances of search with replace in string.



reverse(string) → varchar#
Returns string with the characters in reverse order.



rpad(string, size, padstring) → varchar#
Right pads string to size characters with padstring.
If size is less than the length of string, the result is
truncated to size characters. size must not be negative
and padstring must be non-empty.



rtrim(string) → varchar#
Removes trailing whitespace from string.



soundex(char) → string#

soundex returns a character string containing the phonetic representation of char.It is typically used to evaluate the similarity of two expressions phonetically, that is
how the string sounds when spoken:
SELECT name
FROM nation
WHERE SOUNDEX(name)  = SOUNDEX('CHYNA');

 name  |
-------+----
 CHINA |
(1 row)







split(string, delimiter)#
Splits string on delimiter and returns an array.



split(string, delimiter, limit)
Splits string on delimiter and returns an array of size at most
limit. The last element in the array always contain everything
left in the string. limit must be a positive number.



split_part(string, delimiter, index) → varchar#
Splits string on delimiter and returns the field index.
Field indexes start with 1. If the index is larger than
the number of fields, then null is returned.



split_to_map(string, entryDelimiter, keyValueDelimiter) → map<varchar, varchar>#
Splits string by entryDelimiter and keyValueDelimiter and returns a map.
entryDelimiter splits string into key-value pairs. keyValueDelimiter splits
each pair into key and value.



split_to_multimap(string, entryDelimiter, keyValueDelimiter)#
Splits string by entryDelimiter and keyValueDelimiter and returns a map
containing an array of values for each unique key. entryDelimiter splits string
into key-value pairs. keyValueDelimiter splits each pair into key and value. The
values for each key will be in the same order as they appeared in string.



strpos(string, substring) → bigint#
Returns the starting position of the first instance of substring in
string. Positions start with 1. If not found, 0 is returned.



strpos(string, substring, instance) → bigint
Returns the position of the N-th instance of substring in string.
When instance is a negative number the search will start from the end of string.
Positions start with 1. If not found, 0 is returned.



starts_with(string, substring) → boolean#
Tests whether substring is a prefix of string.



substr(string, start) → varchar#
This is an alias for substring().



substring(string, start) → varchar#
Returns the rest of string from the starting position start.
Positions start with 1. A negative starting position is interpreted
as being relative to the end of the string.



substr(string, start, length) → varchar
This is an alias for substring().



substring(string, start, length) → varchar
Returns a substring from string of length length from the starting
position start. Positions start with 1. A negative starting
position is interpreted as being relative to the end of the string.



translate(source, from, to) → varchar#
Returns the source string translated by replacing characters found in the
from string with the corresponding characters in the to string.  If the from
string contains duplicates, only the first is used.  If the source character
does not exist in the from string, the source character will be copied
without translation.  If the index of the matching character in the from
string is beyond the length of the to string, the source character will
be omitted from the resulting string.
Here are some examples illustrating the translate function:
SELECT translate('abcd', '', ''); -- 'abcd'
SELECT translate('abcd', 'a', 'z'); -- 'zbcd'
SELECT translate('abcda', 'a', 'z'); -- 'zbcdz'
SELECT translate('Palhoça', 'ç','c'); -- 'Palhoca'
SELECT translate('abcd', 'b', U&'\+01F600'); -- a😀cd
SELECT translate('abcd', 'a', ''); -- 'bcd'
SELECT translate('abcd', 'a', 'zy'); -- 'zbcd'
SELECT translate('abcd', 'ac', 'z'); -- 'zbd'
SELECT translate('abcd', 'aac', 'zq'); -- 'zbd'





trim(string) → varchar
Removes leading and trailing whitespace from string.



trim([ [ specification ] [ string ] FROM ] source ) → varchar#
Removes any leading and/or trailing characters as specified up to and
including string from source:
SELECT trim('!' FROM '!foo!'); -- 'foo'
SELECT trim(LEADING FROM '  abcd');  -- 'abcd'
SELECT trim(BOTH '$' FROM '$var$'); -- 'var'
SELECT trim(TRAILING 'ER' FROM upper('worker')); -- 'WORK'





upper(string) → varchar#
Converts string to uppercase.



word_stem(word) → varchar#
Returns the stem of word in the English language.



word_stem(word, lang) → varchar
Returns the stem of word in the lang language.



Unicode functions#


normalize(string) → varchar#
Transforms string with NFC normalization form.



normalize(string, form) → varchar
Transforms string with the specified normalization form.
form must be one of the following keywords:


Form
Description



NFD
Canonical Decomposition

NFC
Canonical Decomposition, followed by Canonical Composition

NFKD
Compatibility Decomposition

NFKC
Compatibility Decomposition, followed by Canonical Composition




Note
This SQL-standard function has special syntax and requires
specifying form as a keyword, not as a string.




to_utf8(string) → varbinary#
Encodes string into a UTF-8 varbinary representation.



from_utf8(binary) → varchar#
Decodes a UTF-8 encoded string from binary. Invalid UTF-8 sequences
are replaced with the Unicode replacement character U+FFFD.



from_utf8(binary, replace) → varchar
Decodes a UTF-8 encoded string from binary. Invalid UTF-8 sequences
are replaced with replace. The replacement string replace must either
be a single character or empty (in which case invalid characters are
removed).

















 Previous  Set Digest functions 



  Next  System information 











































System information — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 System information 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String



 System 
System

Contents

version()





Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

version()









System information#
Functions providing information about the Trino cluster system environment. More
information is available by querying the various schemas and tables exposed by
the System connector.


version() → varchar#
Returns the Trino version used on the cluster. Equivalent to the value of
the node_version column in the system.runtime.nodes table.
















 Previous  String functions and operators 



  Next  Table functions 











































Table functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Table functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System



 Table 
Table

Contents

Built-in table functions

exclude_columns table function

sequence table function



Table function invocation

Function resolution

Arguments

Argument passing conventions







Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Built-in table functions

exclude_columns table function

sequence table function



Table function invocation

Function resolution

Arguments

Argument passing conventions











Table functions#
A table function is a function returning a table. It can be invoked inside the
FROM clause of a query:
SELECT * FROM TABLE(my_function(1, 100))


The row type of the returned table can depend on the arguments passed with
invocation of the function. If different row types can be returned, the
function is a polymorphic table function.
Polymorphic table functions allow you to dynamically invoke custom logic from
within the SQL query. They can be used for working with external systems as
well as for enhancing Trino with capabilities going beyond the SQL standard.
For the list of built-in table functions available in Trino, see built in
table functions.
Trino supports adding custom table functions. They are declared by connectors
through implementing dedicated interfaces. For guidance on adding new table
functions, see the developer guide.
Connectors offer support for different functions on a per-connector basis. For
more information about supported table functions, refer to the connector
documentation.

Built-in table functions#

exclude_columns table function#
Use the exclude_columns table function to return a new table based on an input
table table, with the exclusion of all columns specified in descriptor:


exclude_columns(input => table, columns => descriptor) → table
The argument input is a table or a query.
The argument columns is a descriptor without types.

Example query using the orders table from the TPC-H dataset, provided by the
TPC-H connector:
SELECT *
FROM TABLE(exclude_columns(
                        input => TABLE(orders),
                        columns => DESCRIPTOR(clerk, comment)));


The table function is useful for queries where you want to return nearly all
columns from tables with many columns. You can avoid enumerating all columns,
and only need to specify the columns to exclude.


sequence table function#
Use the sequence table function to return a table with a single column
sequential_number containing a sequence of bigint:


sequence(start => bigint, stop => bigint, step => bigint) -> table(sequential_number bigint)
start is the first element in the sequence. The default value is 0.
stop is the end of the range, inclusive. The last element in the
sequence is equal to stop, or it is the last value within range,
reachable by steps.
step is the difference between subsequent values. The default value is
1.

Example query:
SELECT *
FROM TABLE(sequence(
                start => 1000000,
                stop => -2000000,
                step => -3));


The result of the sequence table function might not be ordered. If required,
enforce ordering in the enclosing query:
SELECT *
FROM TABLE(sequence(
                start => 0,
                stop => 100,
                step => 5))
ORDER BY sequential_number;





Table function invocation#
You invoke a table function in the FROM clause of a query. Table function
invocation syntax is similar to a scalar function call.

Function resolution#
Every table function is provided by a catalog, and it belongs to a schema in
the catalog. You can qualify the function name with a schema name, or with
catalog and schema names:
SELECT * FROM TABLE(schema_name.my_function(1, 100))
SELECT * FROM TABLE(catalog_name.schema_name.my_function(1, 100))


Otherwise, the standard Trino name resolution is applied. The connection
between the function and the catalog must be identified, because the function
is executed by the corresponding connector. If the function is not registered
by the specified catalog, the query fails.
The table function name is resolved case-insensitive, analogically to scalar
function and table resolution in Trino.


Arguments#
There are three types of arguments.

Scalar arguments

They must be constant expressions, and they can be of any SQL type, which is
compatible with the declared argument type:
factor => 42



Descriptor arguments

Descriptors consist of fields with names and optional data types:
schema => DESCRIPTOR(id BIGINT, name VARCHAR)
columns => DESCRIPTOR(date, status, comment)


To pass null for a descriptor, use:
schema => CAST(null AS DESCRIPTOR)



Table arguments

You can pass a table name, or a query. Use the keyword TABLE:
input => TABLE(orders)
data => TABLE(SELECT * FROM region, nation WHERE region.regionkey = nation.regionkey)


If the table argument is declared as set semantics,
you can specify partitioning and ordering. Each partition is processed
independently by the table function. If you do not specify partitioning, the
argument is processed as a single partition. You can also specify
PRUNE WHEN EMPTY or KEEP WHEN EMPTY. With PRUNE WHEN EMPTY you
declare that you are not interested in the function result if the argument is
empty. This information is used by the Trino engine to optimize the query. The
KEEP WHEN EMPTY option indicates that the function should be executed even
if the table argument is empty. By specifying KEEP WHEN EMPTY or
PRUNE WHEN EMPTY, you override the property set for the argument by the
function author.
The following example shows how the table argument properties should be ordered:
input => TABLE(orders)
                    PARTITION BY orderstatus
                    KEEP WHEN EMPTY
                    ORDER BY orderdate




Argument passing conventions#
There are two conventions of passing arguments to a table function:

Arguments passed by name:
SELECT * FROM TABLE(my_function(row_count => 100, column_count => 1))




In this convention, you can pass the arguments in arbitrary order. Arguments
declared with default values can be skipped. Argument names are resolved
case-sensitive, and with automatic uppercasing of unquoted names.

Arguments passed positionally:
SELECT * FROM TABLE(my_function(1, 100))




In this convention, you must follow the order in which the arguments are
declared. You can skip a suffix of the argument list, provided that all the
skipped arguments are declared with default values.
You cannot mix the argument conventions in one invocation.
You can also use parameters in arguments:
PREPARE stmt FROM
SELECT * FROM TABLE(my_function(row_count => ? + 1, column_count => ?));

EXECUTE stmt USING 100, 1;



















 Previous  System information 



  Next  Teradata functions 











































Teradata functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Teradata functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table



 Teradata 
Teradata

Contents

String functions

char2hexint()

index()



Date functions

to_char()

to_timestamp()

to_date()







T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

String functions

char2hexint()

index()



Date functions

to_char()

to_timestamp()

to_date()











Teradata functions#
These functions provide compatibility with Teradata SQL.

String functions#


char2hexint(string) → varchar#
Returns the hexadecimal representation of the UTF-16BE encoding of the string.



index(string, substring) → bigint#
Alias for strpos() function.



Date functions#
The functions in this section use a format string that is compatible with
the Teradata datetime functions. The following table, based on the
Teradata reference manual, describes the supported format specifiers:


Specifier
Description



- / , . ; :
Punctuation characters are ignored

dd
Day of month (1-31)

hh
Hour of day (1-12)

hh24
Hour of the day (0-23)

mi
Minute (0-59)

mm
Month (01-12)

ss
Second (0-59)

yyyy
4-digit year

yy
2-digit year




Warning
Case insensitivity is not currently supported. All specifiers must be lowercase.



to_char(timestamp, format) → varchar#
Formats timestamp as a string using format.



to_timestamp(string, format) → timestamp#
Parses string into a TIMESTAMP using format.



to_date(string, format) → date#
Parses string into a DATE using format.

















 Previous  Table functions 



  Next  T-Digest functions 











































T-Digest functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 T-Digest functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata



 T-Digest 
T-Digest

Contents

Data structures

Functions

tdigest_agg()







URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Data structures

Functions

tdigest_agg()











T-Digest functions#

Data structures#
A T-digest is a data sketch which stores approximate percentile
information.  The Trino type for this data structure is called tdigest.
T-digests can be merged, and for storage and retrieval they can be cast
to and from VARBINARY.


Functions#


merge(tdigest) → tdigest
Aggregates all inputs into a single tdigest.



value_at_quantile(tdigest, quantile) → double
Returns the approximate percentile value from the T-digest, given
the number quantile between 0 and 1.



values_at_quantiles(tdigest, quantiles)
Returns the approximate percentile values as an array, given the input
T-digest and an array of values between 0 and 1, which
represent the quantiles to return.



tdigest_agg(x) → tdigest#
Composes all input values of x into a tdigest. x can be
of any numeric type.



tdigest_agg(x, w) → tdigest
Composes all input values of x into a tdigest using
the per-item weight w. w must be greater or equal than 1.
x and w can be of any numeric type.

















 Previous  Teradata functions 



  Next  URL functions 











































URL functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 URL functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest



 URL 
URL

Contents

Extraction functions

url_extract_fragment()

url_extract_host()

url_extract_parameter()

url_extract_path()

url_extract_port()

url_extract_protocol()

url_extract_query()



Encoding functions

url_encode()

url_decode()







UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Extraction functions

url_extract_fragment()

url_extract_host()

url_extract_parameter()

url_extract_path()

url_extract_port()

url_extract_protocol()

url_extract_query()



Encoding functions

url_encode()

url_decode()











URL functions#

Extraction functions#
The URL extraction functions extract components from HTTP URLs
(or any valid URIs conforming to RFC 2396).
The following syntax is supported:
[protocol:][//host[:port]][path][?query][#fragment]


The extracted components do not contain URI syntax separators
such as : or ?.


url_extract_fragment(url) → varchar#
Returns the fragment identifier from url.



url_extract_host(url) → varchar#
Returns the host from url.



url_extract_parameter(url, name) → varchar#
Returns the value of the first query string parameter named name
from url. Parameter extraction is handled in the typical manner
as specified by RFC 1866#section-8.2.1.



url_extract_path(url) → varchar#
Returns the path from url.



url_extract_port(url) → bigint#
Returns the port number from url.



url_extract_protocol(url) → varchar#
Returns the protocol from url:
SELECT url_extract_protocol('http://localhost:8080/req_path');
-- http

SELECT url_extract_protocol('https://127.0.0.1:8080/req_path');
-- https

SELECT url_extract_protocol('ftp://path/file');
-- ftp





url_extract_query(url) → varchar#
Returns the query string from url.



Encoding functions#


url_encode(value) → varchar#
Escapes value by encoding it so that it can be safely included in
URL query parameter names and values:

Alphanumeric characters are not encoded.
The characters ., -, * and _ are not encoded.
The ASCII space character is encoded as +.
All other characters are converted to UTF-8 and the bytes are encoded
as the string %XX where XX is the uppercase hexadecimal
value of the UTF-8 byte.




url_decode(value) → varchar#
Unescapes the URL encoded value.
This function is the inverse of url_encode().

















 Previous  T-Digest functions 



  Next  UUID functions 











































UUID functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 UUID functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL



 UUID 
UUID

Contents

uuid()





Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

uuid()









UUID functions#


uuid() → uuid#
Returns a pseudo randomly generated UUID (type 4).
















 Previous  URL functions 



  Next  Window functions 











































Window functions — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Window functions 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID



 Window 
Window

Contents

Aggregate functions

Ranking functions

cume_dist()

dense_rank()

ntile()

percent_rank()

rank()

row_number()



Value functions

first_value()

last_value()

nth_value()

lead()

lag()








User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Aggregate functions

Ranking functions

cume_dist()

dense_rank()

ntile()

percent_rank()

rank()

row_number()



Value functions

first_value()

last_value()

nth_value()

lead()

lag()











Window functions#
Window functions perform calculations across rows of the query result.
They run after the HAVING clause but before the ORDER BY clause.
Invoking a window function requires special syntax using the OVER
clause to specify the window.
For example, the following query ranks orders for each clerk by price:
SELECT orderkey, clerk, totalprice,
       rank() OVER (PARTITION BY clerk
                    ORDER BY totalprice DESC) AS rnk
FROM orders
ORDER BY clerk, rnk


The window can be specified in two ways (see WINDOW clause):

By a reference to a named window specification defined in the WINDOW clause,
By an in-line window specification which allows to define window components
as well as refer to the window components pre-defined in the WINDOW clause.


Aggregate functions#
All Aggregate functions can be used as window functions by adding the OVER
clause. The aggregate function is computed for each row over the rows within the
current row’s window frame. Note that ordering during
aggregation is not supported.
For example, the following query produces a rolling sum of order prices
by day for each clerk:
SELECT clerk, orderdate, orderkey, totalprice,
       sum(totalprice) OVER (PARTITION BY clerk
                             ORDER BY orderdate) AS rolling_sum
FROM orders
ORDER BY clerk, orderdate, orderkey




Ranking functions#


cume_dist() → bigint#
Returns the cumulative distribution of a value in a group of values.
The result is the number of rows preceding or peer with the row in the
window ordering of the window partition divided by the total number of
rows in the window partition. Thus, any tie values in the ordering will
evaluate to the same distribution value. The window frame must not be
specified.



dense_rank() → bigint#
Returns the rank of a value in a group of values. This is similar to
rank(), except that tie values do not produce gaps in the sequence.
The window frame must not be specified.



ntile(n) → bigint#
Divides the rows for each window partition into n buckets ranging
from 1 to at most n. Bucket values will differ by at most 1.
If the number of rows in the partition does not divide evenly into the
number of buckets, then the remainder values are distributed one per
bucket, starting with the first bucket.
For example, with 6 rows and 4 buckets, the bucket values would
be as follows: 1 1 2 2 3 4
For the ntile() function, the window frame must not be specified.



percent_rank() → double#
Returns the percentage ranking of a value in group of values. The result
is (r - 1) / (n - 1) where r is the rank() of the row and
n is the total number of rows in the window partition. The window frame
must not be specified.



rank() → bigint#
Returns the rank of a value in a group of values. The rank is one plus
the number of rows preceding the row that are not peer with the row.
Thus, tie values in the ordering will produce gaps in the sequence.
The ranking is performed for each window partition. The window frame must
not be specified.



row_number() → bigint#
Returns a unique, sequential number for each row, starting with one,
according to the ordering of rows within the window partition.
The window frame must not be specified.



Value functions#
By default, null values are respected. If IGNORE NULLS is specified, all rows where
x is null are excluded from the calculation. If IGNORE NULLS is specified and x
is null for all rows, the default_value is returned, or if it is not specified,
null is returned.


first_value(x) → [same as input]#
Returns the first value of the window.



last_value(x) → [same as input]#
Returns the last value of the window.



nth_value(x, offset) → [same as input]#
Returns the value at the specified offset from the beginning of the window.
Offsets start at 1. The offset can be any scalar
expression.  If the offset is null or greater than the number of values in
the window, null is returned.  It is an error for the offset to be zero or
negative.



lead(x[, offset[, default_value]]) → [same as input]#
Returns the value at offset rows after the current row in the window partition.
Offsets start at 0, which is the current row. The
offset can be any scalar expression.  The default offset is 1. If the
offset is null, an error is raised. If the offset refers to a row that is not
within the partition, the default_value is returned, or if it is not specified
null is returned.
The lead() function requires that the window ordering be specified.
Window frame must not be specified.



lag(x[, offset[, default_value]]) → [same as input]#
Returns the value at offset rows before the current row in the window partition.
Offsets start at 0, which is the current row. The
offset can be any scalar expression.  The default offset is 1. If the
offset is null, an error is raised. If the offset refers to a row that is not
within the partition, the default_value is returned, or if it is not specified
null is returned.
The lag() function requires that the window ordering be specified.
Window frame must not be specified.

















 Previous  UUID functions 



  Next  User-defined functions 











































Functions and operators — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Functions and operators 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage



 Functions and operators 
Functions and operators

Contents

Functions by name

Functions per topic





List of functions and operators


List of functions by topic


Aggregate


AI


Array


Binary


Bitwise


Color


Comparison


Conditional


Conversion


Date and time


Decimal


Geospatial


HyperLogLog


IP Address


JSON


Lambda


Logical


Machine learning


Map


Math


Quantile digest


Regular expression


Session


Set Digest


String


System


Table


Teradata


T-Digest


URL


UUID


Window



User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Functions by name

Functions per topic









Functions and operators#
This section describes the built-in SQL functions and operators supported by
Trino. They allow you to implement complex capabilities and behavior of the
queries executed by Trino operating on the underlying data sources.
Refer to the following sections for further details:

SQL data types and other general aspects
SQL statement and syntax reference

In addition, Trino supports implementation of custom
functions or custom table
functions provided by a plugin, and creation of
User-defined functions.

Functions by name#
If you are looking for a specific function or operator by name use
SHOW FUNCTIONS, or refer to the following resources:


List of functions and operators
List of functions by topic




Functions per topic#


Aggregate
AI
Array
Binary
Bitwise
Color
Comparison
Conditional
Conversion
Date and time
Decimal
Geospatial
HyperLogLog
IP Address
JSON
Lambda
Logical
Machine learning
Map
Math
Quantile digest
Regular expression
Session
Set Digest
String
System
Table
Teradata
T-Digest
URL
UUID
Window


















 Previous  Object storage file formats 



  Next  List of functions and operators 











































ALTER MATERIALIZED VIEW — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 ALTER MATERIALIZED VIEW 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax



 ALTER MATERIALIZED VIEW 
ALTER MATERIALIZED VIEW

Contents

Synopsis

Description

SET PROPERTIES



Examples

See also





ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

SET PROPERTIES



Examples

See also









ALTER MATERIALIZED VIEW#

Synopsis#
ALTER MATERIALIZED VIEW [ IF EXISTS ] name RENAME TO new_name
ALTER MATERIALIZED VIEW name SET PROPERTIES property_name = expression [, ...]




Description#
Change the name of an existing materialized view.
The optional IF EXISTS clause causes the error to be suppressed if the
materialized view does not exist. The error is not suppressed if the
materialized view does not exist, but a table or view with the given name
exists.

SET PROPERTIES#
The ALTER MATERIALIZED VIEW SET PROPERTIES  statement followed by some number
of property_name and expression pairs applies the specified properties
and values to a materialized view. Ommitting an already-set property from this
statement leaves that property unchanged in the materialized view.
A property in a SET PROPERTIES statement can be set to DEFAULT, which
reverts its value back to the default in that materialized view.
Support for ALTER MATERIALIZED VIEW SET PROPERTIES varies between
connectors. Refer to the connector documentation for more details.



Examples#
Rename materialized view people to users in the current schema:
ALTER MATERIALIZED VIEW people RENAME TO users;


Rename materialized view people to users, if materialized view
people exists in the current catalog and schema:
ALTER MATERIALIZED VIEW IF EXISTS people RENAME TO users;


Set view properties (x = y) in materialized view people:
ALTER MATERIALIZED VIEW people SET PROPERTIES x = 'y';


Set multiple view properties (foo = 123 and foo bar = 456) in
materialized view people:
ALTER MATERIALIZED VIEW people SET PROPERTIES foo = 123, "foo bar" = 456;


Set view property x to its default value in materialized view people:
ALTER MATERIALIZED VIEW people SET PROPERTIES x = DEFAULT;




See also#

CREATE MATERIALIZED VIEW
REFRESH MATERIALIZED VIEW
DROP MATERIALIZED VIEW

















 Previous  SQL statement syntax 



  Next  ALTER SCHEMA 











































ALTER SCHEMA — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 ALTER SCHEMA 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW



 ALTER SCHEMA 
ALTER SCHEMA

Contents

Synopsis

Description

Examples

See Also





ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See Also









ALTER SCHEMA#

Synopsis#
ALTER SCHEMA name RENAME TO new_name
ALTER SCHEMA name SET AUTHORIZATION ( user | USER user | ROLE role )




Description#
Change the definition of an existing schema.


Examples#
Rename schema web to traffic:
ALTER SCHEMA web RENAME TO traffic


Change owner of schema web to user alice:
ALTER SCHEMA web SET AUTHORIZATION alice


Allow everyone to drop schema and create tables in schema web:
ALTER SCHEMA web SET AUTHORIZATION ROLE PUBLIC




See Also#
CREATE SCHEMA
















 Previous  ALTER MATERIALIZED VIEW 



  Next  ALTER TABLE 











































ALTER TABLE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 ALTER TABLE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA



 ALTER TABLE 
ALTER TABLE

Contents

Synopsis

Description

SET PROPERTIES

EXECUTE



Examples

See also





ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

SET PROPERTIES

EXECUTE



Examples

See also









ALTER TABLE#

Synopsis#
ALTER TABLE [ IF EXISTS ] name RENAME TO new_name
ALTER TABLE [ IF EXISTS ] name ADD COLUMN [ IF NOT EXISTS ] column_name data_type
  [ NOT NULL ] [ COMMENT comment ]
  [ WITH ( property_name = expression [, ...] ) ]
  [ FIRST | LAST | AFTER after_column_name ]
ALTER TABLE [ IF EXISTS ] name DROP COLUMN [ IF EXISTS ] column_name
ALTER TABLE [ IF EXISTS ] name RENAME COLUMN [ IF EXISTS ] old_name TO new_name
ALTER TABLE [ IF EXISTS ] name ALTER COLUMN column_name SET DATA TYPE new_type
ALTER TABLE [ IF EXISTS ] name ALTER COLUMN column_name DROP NOT NULL
ALTER TABLE name SET AUTHORIZATION ( user | USER user | ROLE role )
ALTER TABLE name SET PROPERTIES property_name = expression [, ...]
ALTER TABLE name EXECUTE command [ ( parameter => expression [, ... ] ) ]
    [ WHERE expression ]




Description#
Change the definition of an existing table.
The optional IF EXISTS clause, when used before the table name, causes the
error to be suppressed if the table does not exist.
The optional IF EXISTS clause, when used before the column name, causes the
error to be suppressed if the column does not exist.
The optional IF NOT EXISTS clause causes the error to be suppressed if the
column already exists.

SET PROPERTIES#
The ALTER TABLE SET PROPERTIES  statement followed by a number of
property_name and expression pairs applies the specified properties and
values to a table. Ommitting an already-set property from this statement leaves
that property unchanged in the table.
A property in a SET PROPERTIES statement can be set to DEFAULT, which
reverts its value back to the default in that table.
Support for ALTER TABLE SET PROPERTIES varies between
connectors, as not all connectors support modifying table properties.


EXECUTE#
The ALTER TABLE EXECUTE statement followed by a command and
parameters modifies the table according to the specified command and
parameters. ALTER TABLE EXECUTE supports different commands on a
per-connector basis.
You can use the => operator for passing named parameter values. The left side
is the name of the parameter, the right side is the value being passed.
Executable commands are contributed by connectors, such as the optimize
command provided by the Hive, Delta
Lake, and
Iceberg connectors. For example, a user observing
many small files in the storage of a table called test_table in the test
schema of the example catalog, can use the optimize command to merge all
files below the file_size_threshold value. The result is fewer, but larger
files, which typically results in higher query performance on the data in the
files:
ALTER TABLE example.test.test_table EXECUTE optimize(file_size_threshold => '16MB')





Examples#
Rename table users to people:
ALTER TABLE users RENAME TO people;


Rename table users to people if table users exists:
ALTER TABLE IF EXISTS users RENAME TO people;


Add column zip to the users table:
ALTER TABLE users ADD COLUMN zip varchar;


Add column zip to the users table if table users exists and column zip
not already exists:
ALTER TABLE IF EXISTS users ADD COLUMN IF NOT EXISTS zip varchar;


Add column id as the first column to the users table:
ALTER TABLE users ADD COLUMN id varchar FIRST;


Add column zip after column country to the users table:
ALTER TABLE users ADD COLUMN zip varchar AFTER country;


Drop column zip from the users table:
ALTER TABLE users DROP COLUMN zip;


Drop column zip from the users table if table users and column zip
exists:
ALTER TABLE IF EXISTS users DROP COLUMN IF EXISTS zip;


Rename column id to user_id in the users table:
ALTER TABLE users RENAME COLUMN id TO user_id;


Rename column id to user_id in the users table if table users and column
id exists:
ALTER TABLE IF EXISTS users RENAME column IF EXISTS id to user_id;


Change type of column id to bigint in the users table:
ALTER TABLE users ALTER COLUMN id SET DATA TYPE bigint;


Drop a not null constraint on id column in the users table:
ALTER TABLE users ALTER COLUMN id DROP NOT NULL;


Change owner of table people to user alice:
ALTER TABLE people SET AUTHORIZATION alice


Allow everyone with role public to drop and alter table people:
ALTER TABLE people SET AUTHORIZATION ROLE PUBLIC


Set table properties (x = y) in table people:
ALTER TABLE people SET PROPERTIES x = 'y';


Set multiple table properties (foo = 123 and foo bar = 456) in
table people:
ALTER TABLE people SET PROPERTIES foo = 123, "foo bar" = 456;


Set table property x to its default value in table``people``:
ALTER TABLE people SET PROPERTIES x = DEFAULT;




See also#
CREATE TABLE
















 Previous  ALTER SCHEMA 



  Next  ALTER VIEW 











































ALTER VIEW — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 ALTER VIEW 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE



 ALTER VIEW 
ALTER VIEW

Contents

Synopsis

Description

Examples

See also





ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









ALTER VIEW#

Synopsis#
ALTER VIEW name RENAME TO new_name
ALTER VIEW name SET AUTHORIZATION ( user | USER user | ROLE role )




Description#
Change the definition of an existing view.


Examples#
Rename view people to users:
ALTER VIEW people RENAME TO users


Change owner of VIEW people to user alice:
ALTER VIEW people SET AUTHORIZATION alice




See also#
CREATE VIEW
















 Previous  ALTER TABLE 



  Next  ANALYZE 











































ANALYZE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 ANALYZE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW



 ANALYZE 
ANALYZE

Contents

Synopsis

Description

Examples





CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples









ANALYZE#

Synopsis#
ANALYZE table_name [ WITH ( property_name = expression [, ...] ) ]




Description#
Collects table and column statistics for a given table.
The optional WITH clause can be used to provide connector-specific properties.
To list all available properties, run the following query:
SELECT * FROM system.metadata.analyze_properties




Examples#
Analyze table web to collect table and column statistics:
ANALYZE web;


Analyze table stores in catalog hive and schema default:
ANALYZE hive.default.stores;


Analyze partitions '1992-01-01', '1992-01-02' from a Hive partitioned table sales:
ANALYZE hive.default.sales WITH (partitions = ARRAY[ARRAY['1992-01-01'], ARRAY['1992-01-02']]);


Analyze partitions with complex partition key (state and city columns) from a Hive partitioned table customers:
ANALYZE hive.default.customers WITH (partitions = ARRAY[ARRAY['CA', 'San Francisco'], ARRAY['NY', 'NY']]);


Analyze only columns department and product_id for partitions '1992-01-01', '1992-01-02' from a Hive partitioned
table sales:
ANALYZE hive.default.sales WITH (
    partitions = ARRAY[ARRAY['1992-01-01'], ARRAY['1992-01-02']],
    columns = ARRAY['department', 'product_id']);


















 Previous  ALTER VIEW 



  Next  CALL 











































CALL — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 CALL 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE



 CALL 
CALL

Contents

Synopsis

Description

Examples





COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples









CALL#

Synopsis#
CALL procedure_name ( [ name => ] expression [, ...] )




Description#
Call a procedure.
Procedures can be provided by connectors to perform data manipulation or
administrative tasks. For example, the System connector defines a
procedure for killing a running query.
Some connectors, such as the PostgreSQL connector, are for systems
that have their own stored procedures. These stored procedures are separate
from the connector-defined procedures discussed here and thus are not
directly callable via CALL.
See connector documentation for details on available procedures.


Examples#
Call a procedure using positional arguments:
CALL test(123, 'apple');


Call a procedure using named arguments:
CALL test(name => 'apple', id => 123);


Call a procedure using a fully qualified name:
CALL catalog.schema.test();


















 Previous  ANALYZE 



  Next  COMMENT 











































COMMENT — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 COMMENT 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL



 COMMENT 
COMMENT

Contents

Synopsis

Description

Examples

See also





COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









COMMENT#

Synopsis#
COMMENT ON ( TABLE | VIEW | COLUMN ) name IS 'comments'




Description#
Set the comment for a object. The comment can be removed by setting the comment to NULL.


Examples#
Change the comment for the users table to be master table:
COMMENT ON TABLE users IS 'master table';


Change the comment for the users view to be master view:
COMMENT ON VIEW users IS 'master view';


Change the comment for the users.name column to be full name:
COMMENT ON COLUMN users.name IS 'full name';




See also#
Comments
















 Previous  CALL 



  Next  COMMIT 











































COMMIT — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 COMMIT 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT



 COMMIT 
COMMIT

Contents

Synopsis

Description

Examples

See also





CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









COMMIT#

Synopsis#
COMMIT [ WORK ]




Description#
Commit the current transaction.


Examples#
COMMIT;
COMMIT WORK;




See also#
ROLLBACK, START TRANSACTION
















 Previous  COMMENT 



  Next  CREATE CATALOG 











































CREATE CATALOG — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 CREATE CATALOG 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT



 CREATE CATALOG 
CREATE CATALOG

Contents

Synopsis

Description

Examples

See also





CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









CREATE CATALOG#

Synopsis#
CREATE CATALOG
catalog_name
USING connector_name
[ WITH ( property_name = expression [, ...] ) ]




Description#
Create a new catalog using the specified connector.
The optional WITH clause is used to set properties on the newly created
catalog. Property names can be double quoted, which is required if they contain
special characters, like -. Refer to the connectors
documentation to learn about all available properties. All
property values must be varchars (single quoted), including numbers and boolean
values.
The query fails in the following circumstances:

A required property is missing.
An invalid property is set, for example there is a typo in the property name,
or a property name from a different connector was used.
The value of the property is invalid, for example a numeric value is out of
range, or a string value doesn’t match the required pattern.
The value references an environmental variable that is not set on the
coordinator node.


Warning
The complete CREATE CATALOG query is logged, and visible in the Web
UI. This includes any sensitive properties, like
passwords and other credentials. See Secrets.


Note
This command requires the catalog management type
to be set to dynamic.



Examples#
Create a new catalog called tpch using the TPC-H connector:
CREATE CATALOG tpch USING tpch;


Create a new catalog called brain using the Memory connector:
CREATE CATALOG brain USING memory
WITH ("memory.max-data-per-node" = '128MB');


Notice that the connector property contains dashes (-) and needs to quoted
using a double quote ("). The value 128MB is quoted using single quotes,
because it is a string literal.
Create a new catalog called example using the PostgreSQL connector:
CREATE CATALOG example USING postgresql
WITH (
  "connection-url" = 'jdbc:pg:localhost:5432',
  "connection-user" = '${ENV:POSTGRES_USER}',
  "connection-password" = '${ENV:POSTGRES_PASSWORD}',
  "case-insensitive-name-matching" = 'true'
);


This example assumes that the POSTGRES_USER and POSTGRES_PASSWORD
environmental variables are set as secrets on all nodes of
the cluster.


See also#

DROP CATALOG
Catalog management properties

















 Previous  COMMIT 



  Next  CREATE FUNCTION 











































CREATE FUNCTION — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 CREATE FUNCTION 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG



 CREATE FUNCTION 
CREATE FUNCTION

Contents

Synopsis

Description

Examples

See also





CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









CREATE FUNCTION#

Synopsis#
CREATE [OR REPLACE] FUNCTION
  udf_definition




Description#
Create or replace a Catalog user-defined functions. The udf_definition is composed of the
usage of FUNCTION and nested statements. The name of the UDF must be
fully qualified with catalog and schema location, unless the default UDF
storage catalog and schema are configured.
The connector used in the catalog must support UDF storage.
The optional OR REPLACE clause causes the UDF to be replaced if it already
exists rather than raising an error.


Examples#
The following example creates the meaning_of_life UDF in the default
schema of the example catalog:
CREATE FUNCTION example.default.meaning_of_life()
  RETURNS bigint
  BEGIN
    RETURN 42;
  END;


If the default catalog and schema for UDF
storage is configured, you can use the
following more compact syntax:
CREATE FUNCTION meaning_of_life() RETURNS bigint RETURN 42;


Further examples of varying complexity that cover usage of the FUNCTION
statement in combination with other statements are available in the SQL
UDF examples documentation.


See also#

DROP FUNCTION
SHOW CREATE FUNCTION
SHOW FUNCTIONS
User-defined functions
SQL environment properties

















 Previous  CREATE CATALOG 



  Next  CREATE MATERIALIZED VIEW 











































CREATE MATERIALIZED VIEW — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 CREATE MATERIALIZED VIEW 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION



 CREATE MATERIALIZED VIEW 
CREATE MATERIALIZED VIEW

Contents

Synopsis

Description

Examples

See also





CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









CREATE MATERIALIZED VIEW#

Synopsis#
CREATE [ OR REPLACE ] MATERIALIZED VIEW
[ IF NOT EXISTS ] view_name
[ GRACE PERIOD interval ]
[ COMMENT string ]
[ WITH properties ]
AS query




Description#
Create and validate the definition of a new materialized view view_name of a
SELECT query. You need to run the REFRESH MATERIALIZED VIEW
statement after the creation to populate the materialized view with data. This
materialized view is a physical manifestation of the query results at time of
refresh. The data is stored, and can be referenced by future queries.
Queries accessing materialized views are typically faster than retrieving data
from a view created with the same query. Any computation, aggregation, and other
operation to create the data is performed once during refresh of the
materialized views, as compared to each time of accessing the view. Multiple
reads of view data over time, or by multiple users, all trigger repeated
processing. This is avoided for materialized views.
The optional OR REPLACE clause causes the materialized view to be replaced
if it already exists rather than raising an error.
The optional IF NOT EXISTS clause causes the materialized view only to be
created if it does not exist yet.
Note that OR REPLACE and IF NOT EXISTS are mutually exclusive clauses.
The optional GRACE PERIOD clause specifies how long the query materialization
is used for querying:

Within the grace period since last refresh, data retrieval is highly
performant because the query materialization is used. However, the data may
not be up to date with the base tables.
After the grace period has elapsed, the data of the materialized view is
computed on-the-fly using the query. Retrieval is therefore slower, but the
data is up to date with the base tables.
If not specified, the grace period defaults to infinity, and therefore all
queries are within the grace period.
Every REFRESH MATERIALIZED VIEW operation resets the start time for the
grace period.

The optional COMMENT clause causes a string comment to be stored with
the metadata about the materialized view. The comment is displayed with the
SHOW CREATE MATERIALIZED VIEW statement and is available in the table
system.metadata.materialized_view_properties.
The optional WITH clause is used to define properties for the materialized
view creation. Separate multiple property/value pairs by commas. The connector
uses the properties as input parameters for the materialized view refresh
operation. The supported properties are different for each connector and
detailed in the SQL support section of the specific connector’s documentation.
After successful creation, all metadata about the materialized view is available
in a system table.


Examples#
Create a simple materialized view cancelled_orders over the orders table
that only includes cancelled orders. Note that orderstatus is a numeric
value that is potentially meaningless to a consumer, yet the name of the view
clarifies the content:
CREATE MATERIALIZED VIEW cancelled_orders
AS
    SELECT orderkey, totalprice
    FROM orders
    WHERE orderstatus = 3;


Create or replace a materialized view order_totals_by_date that summarizes
orders across all orders from all customers:
CREATE OR REPLACE MATERIALIZED VIEW order_totals_by_date
AS
    SELECT orderdate, sum(totalprice) AS price
    FROM orders
    GROUP BY orderdate;


Create a materialized view for a catalog using the Iceberg connector, with a
comment and partitioning on two fields in the storage:
CREATE MATERIALIZED VIEW orders_nation_mkgsegment
COMMENT 'Orders with nation and market segment data'
WITH ( partitioning = ARRAY['mktsegment', 'nationkey'] )
AS
    SELECT o.*, c.nationkey, c.mktsegment
    FROM orders AS o
    JOIN customer AS c
    ON o.custkey = c.custkey;


Set multiple properties:
WITH ( format = 'ORC', partitioning = ARRAY['_date'] )


Show defined materialized view properties for all catalogs:
SELECT * FROM system.metadata.materialized_view_properties;


Show metadata about the materialized views in all catalogs:
SELECT * FROM system.metadata.materialized_views;




See also#

DROP MATERIALIZED VIEW
SHOW CREATE MATERIALIZED VIEW
REFRESH MATERIALIZED VIEW

















 Previous  CREATE FUNCTION 



  Next  CREATE ROLE 











































CREATE ROLE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 CREATE ROLE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW



 CREATE ROLE 
CREATE ROLE

Contents

Synopsis

Description

Examples

Limitations

See also





CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations

See also









CREATE ROLE#

Synopsis#
CREATE ROLE role_name
[ WITH ADMIN ( user | USER user | ROLE role | CURRENT_USER | CURRENT_ROLE ) ]
[ IN catalog ]




Description#
CREATE ROLE creates the specified role.
The optional WITH ADMIN clause causes the role to be created with
the specified user as a role admin. A role admin has permission to drop
or grant a role. If the optional WITH ADMIN clause is not
specified, the role is created with current user as admin.
The optional IN catalog clause creates the role in a catalog as opposed
to a system role.


Examples#
Create role admin
CREATE ROLE admin;


Create role moderator with admin bob:
CREATE ROLE moderator WITH ADMIN USER bob;




Limitations#
Some connectors do not support role management.
See connector documentation for more details.


See also#
DROP ROLE, SET ROLE, GRANT role, REVOKE role
















 Previous  CREATE MATERIALIZED VIEW 



  Next  CREATE SCHEMA 











































CREATE SCHEMA — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 CREATE SCHEMA 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE



 CREATE SCHEMA 
CREATE SCHEMA

Contents

Synopsis

Description

Examples

See also





CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









CREATE SCHEMA#

Synopsis#
CREATE SCHEMA [ IF NOT EXISTS ] schema_name
[ AUTHORIZATION ( user | USER user | ROLE role ) ]
[ WITH ( property_name = expression [, ...] ) ]




Description#
Create a new, empty schema. A schema is a container that
holds tables, views and other database objects.
The optional IF NOT EXISTS clause causes the error to be
suppressed if the schema already exists.
The optional AUTHORIZATION clause can be used to set the
owner of the newly created schema to a user or role.
The optional WITH clause can be used to set properties
on the newly created schema.  To list all available schema
properties, run the following query:
SELECT * FROM system.metadata.schema_properties




Examples#
Create a new schema web in the current catalog:
CREATE SCHEMA web


Create a new schema sales in the hive catalog:
CREATE SCHEMA hive.sales


Create the schema traffic if it does not already exist:
CREATE SCHEMA IF NOT EXISTS traffic


Create a new schema web and set the owner to user alice:
CREATE SCHEMA web AUTHORIZATION alice


Create a new schema web, set the LOCATION property to /hive/data/web
and set the owner to user alice:
CREATE SCHEMA web AUTHORIZATION alice WITH ( LOCATION = '/hive/data/web' )


Create a new schema web and allow everyone to drop schema and create tables
in schema web:
CREATE SCHEMA web AUTHORIZATION ROLE PUBLIC


Create a new schema web, set the LOCATION property to /hive/data/web
and allow everyone to drop schema and create tables in schema web:
CREATE SCHEMA web AUTHORIZATION ROLE PUBLIC WITH ( LOCATION = '/hive/data/web' )




See also#
ALTER SCHEMA, DROP SCHEMA
















 Previous  CREATE ROLE 



  Next  CREATE TABLE 











































CREATE TABLE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 CREATE TABLE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA



 CREATE TABLE 
CREATE TABLE

Contents

Synopsis

Description

Examples

See also





CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









CREATE TABLE#

Synopsis#
CREATE [ OR REPLACE ] TABLE [ IF NOT EXISTS ]
table_name (
  { column_name data_type [ NOT NULL ]
      [ COMMENT comment ]
      [ WITH ( property_name = expression [, ...] ) ]
  | LIKE existing_table_name
      [ { INCLUDING | EXCLUDING } PROPERTIES ]
  }
  [, ...]
)
[ COMMENT table_comment ]
[ WITH ( property_name = expression [, ...] ) ]




Description#
Create a new, empty table with the specified columns.
Use CREATE TABLE AS to create a table with data.
The optional OR REPLACE clause causes an existing table with the
specified name to be replaced with the new table definition. Support
for table replacement varies across connectors. Refer to the
connector documentation for details.
The optional IF NOT EXISTS clause causes the error to be
suppressed if the table already exists.
OR REPLACE and IF NOT EXISTS cannot be used together.
The optional WITH clause can be used to set properties
on the newly created table or on single columns.  To list all available table
properties, run the following query:
SELECT * FROM system.metadata.table_properties


To list all available column properties, run the following query:
SELECT * FROM system.metadata.column_properties


The LIKE clause can be used to include all the column definitions from
an existing table in the new table. Multiple LIKE clauses may be
specified, which allows copying the columns from multiple tables.
If INCLUDING PROPERTIES is specified, all of the table properties are
copied to the new table. If the WITH clause specifies the same property
name as one of the copied properties, the value from the WITH clause
will be used. The default behavior is EXCLUDING PROPERTIES. The
INCLUDING PROPERTIES option maybe specified for at most one table.


Examples#
Create a new table orders:
CREATE TABLE orders (
  orderkey bigint,
  orderstatus varchar,
  totalprice double,
  orderdate date
)
WITH (format = 'ORC')


Create the table orders if it does not already exist, adding a table comment
and a column comment:
CREATE TABLE IF NOT EXISTS orders (
  orderkey bigint,
  orderstatus varchar,
  totalprice double COMMENT 'Price in cents.',
  orderdate date
)
COMMENT 'A table to keep track of orders.'


Create the table bigger_orders using the columns from orders
plus additional columns at the start and end:
CREATE TABLE bigger_orders (
  another_orderkey bigint,
  LIKE orders,
  another_orderdate date
)




See also#
ALTER TABLE, DROP TABLE, CREATE TABLE AS, SHOW CREATE TABLE
















 Previous  CREATE SCHEMA 



  Next  CREATE TABLE AS 











































CREATE TABLE AS — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 CREATE TABLE AS 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE



 CREATE TABLE AS 
CREATE TABLE AS

Contents

Synopsis

Description

Examples

See also





CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









CREATE TABLE AS#

Synopsis#
CREATE [ OR REPLACE ] TABLE [ IF NOT EXISTS ] table_name [ ( column_alias, ... ) ]
[ COMMENT table_comment ]
[ WITH ( property_name = expression [, ...] ) ]
AS query
[ WITH [ NO ] DATA ]




Description#
Create a new table containing the result of a SELECT query.
Use CREATE TABLE to create an empty table.
The optional OR REPLACE clause causes an existing table with the
specified name to be replaced with the new table definition. Support
for table replacement varies across connectors. Refer to the
connector documentation for details.
The optional IF NOT EXISTS clause causes the error to be
suppressed if the table already exists.
OR REPLACE and IF NOT EXISTS cannot be used together.
The optional WITH clause can be used to set properties
on the newly created table.  To list all available table
properties, run the following query:
SELECT * FROM system.metadata.table_properties




Examples#
Create a new table orders_column_aliased with the results of a query and the given column names:
CREATE TABLE orders_column_aliased (order_date, total_price)
AS
SELECT orderdate, totalprice
FROM orders


Create a new table orders_by_date that summarizes orders:
CREATE TABLE orders_by_date
COMMENT 'Summary of orders by date'
WITH (format = 'ORC')
AS
SELECT orderdate, sum(totalprice) AS price
FROM orders
GROUP BY orderdate


Create the table orders_by_date if it does not already exist:
CREATE TABLE IF NOT EXISTS orders_by_date AS
SELECT orderdate, sum(totalprice) AS price
FROM orders
GROUP BY orderdate


Create a new empty_nation table with the same schema as nation and no data:
CREATE TABLE empty_nation AS
SELECT *
FROM nation
WITH NO DATA




See also#
CREATE TABLE, SELECT
















 Previous  CREATE TABLE 



  Next  CREATE VIEW 











































CREATE VIEW — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 CREATE VIEW 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS



 CREATE VIEW 
CREATE VIEW

Contents

Synopsis

Description

Security

Examples

See also





DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Security

Examples

See also









CREATE VIEW#

Synopsis#
CREATE [ OR REPLACE ] VIEW view_name
[ COMMENT view_comment ]
[ SECURITY { DEFINER | INVOKER } ]
AS query




Description#
Create a new view of a SELECT query. The view is a logical table
that can be referenced by future queries. Views do not contain any data.
Instead, the query stored by the view is executed every time the view is
referenced by another query.
The optional OR REPLACE clause causes the view to be replaced if it
already exists rather than raising an error.


Security#
In the default DEFINER security mode, tables referenced in the view
are accessed using the permissions of the view owner (the creator or
definer of the view) rather than the user executing the query. This
allows providing restricted access to the underlying tables, for which
the user may not be allowed to access directly.
In the INVOKER security mode, tables referenced in the view are accessed
using the permissions of the user executing the query (the invoker of the view).
A view created in this mode is simply a stored query.
Regardless of the security mode, the current_user function will
always return the user executing the query and thus may be used
within views to filter out rows or otherwise restrict access.


Examples#
Create a simple view test over the orders table:
CREATE VIEW test AS
SELECT orderkey, orderstatus, totalprice / 2 AS half
FROM orders


Create a view test_with_comment with a view comment:
CREATE VIEW test_with_comment
COMMENT 'A view to keep track of orders.'
AS
SELECT orderkey, orderstatus, totalprice
FROM orders


Create a view orders_by_date that summarizes orders:
CREATE VIEW orders_by_date AS
SELECT orderdate, sum(totalprice) AS price
FROM orders
GROUP BY orderdate


Create a view that replaces an existing view:
CREATE OR REPLACE VIEW test AS
SELECT orderkey, orderstatus, totalprice / 4 AS quarter
FROM orders




See also#

ALTER VIEW
DROP VIEW
SHOW CREATE VIEW
SHOW TABLES

















 Previous  CREATE TABLE AS 



  Next  DEALLOCATE PREPARE 











































DEALLOCATE PREPARE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DEALLOCATE PREPARE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW



 DEALLOCATE PREPARE 
DEALLOCATE PREPARE

Contents

Synopsis

Description

Examples

See also





DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









DEALLOCATE PREPARE#

Synopsis#
DEALLOCATE PREPARE statement_name




Description#
Removes a statement with the name statement_name from the list of prepared
statements in a session.


Examples#
Deallocate a statement with the name my_query:
DEALLOCATE PREPARE my_query;




See also#
PREPARE, EXECUTE, EXECUTE IMMEDIATE
















 Previous  CREATE VIEW 



  Next  DELETE 











































DELETE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DELETE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE



 DELETE 
DELETE

Contents

Synopsis

Description

Examples

Limitations





DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations









DELETE#

Synopsis#
DELETE FROM table_name [ WHERE condition ]




Description#
Delete rows from a table. If the WHERE clause is specified, only the
matching rows are deleted. Otherwise, all rows from the table are deleted.


Examples#
Delete all line items shipped by air:
DELETE FROM lineitem WHERE shipmode = 'AIR';


Delete all line items for low priority orders:
DELETE FROM lineitem
WHERE orderkey IN (SELECT orderkey FROM orders WHERE priority = 'LOW');


Delete all orders:
DELETE FROM orders;




Limitations#
Some connectors have limited or no support for DELETE.
See connector documentation for more details.
















 Previous  DEALLOCATE PREPARE 



  Next  DENY 











































DENY — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DENY 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE



 DENY 
DENY

Contents

Synopsis

Description

Examples

Limitations

See also





DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations

See also









DENY#

Synopsis#
DENY ( privilege [, ...] | ( ALL PRIVILEGES ) )
ON ( table_name | TABLE table_name | SCHEMA schema_name)
TO ( user | USER user | ROLE role )




Description#
Denies the specified privileges to the specified grantee.
Deny on a table rejects the specified privilege on all current and future
columns of the table.
Deny on a schema rejects the specified privilege on all current and future
columns of all current and future tables of the schema.


Examples#
Deny INSERT and SELECT privileges on the table orders
to user alice:
DENY INSERT, SELECT ON orders TO alice;


Deny DELETE privilege on the schema finance to user bob:
DENY DELETE ON SCHEMA finance TO bob;


Deny SELECT privilege on the table orders to everyone:
DENY SELECT ON orders TO ROLE PUBLIC;




Limitations#
The system access controls as well as the connectors provided by default
in Trino have no support for DENY.


See also#
GRANT privilege, REVOKE privilege, SHOW GRANTS
















 Previous  DELETE 



  Next  DESCRIBE 











































DESCRIBE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DESCRIBE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY



 DESCRIBE 
DESCRIBE

Contents

Synopsis

Description





DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description









DESCRIBE#

Synopsis#
DESCRIBE table_name




Description#
DESCRIBE is an alias for SHOW COLUMNS.
















 Previous  DENY 



  Next  DESCRIBE INPUT 











































DESCRIBE INPUT — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DESCRIBE INPUT 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE



 DESCRIBE INPUT 
DESCRIBE INPUT

Contents

Synopsis

Description

Examples

See also





DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









DESCRIBE INPUT#

Synopsis#
DESCRIBE INPUT statement_name




Description#
Lists the input parameters of a prepared statement along with the
position and type of each parameter. Parameter types that cannot be
determined will appear as unknown.


Examples#
Prepare and describe a query with three parameters:
PREPARE my_select1 FROM
SELECT ? FROM nation WHERE regionkey = ? AND name < ?;


DESCRIBE INPUT my_select1;


 Position | Type
--------------------
        0 | unknown
        1 | bigint
        2 | varchar
(3 rows)


Prepare and describe a query with no parameters:
PREPARE my_select2 FROM
SELECT * FROM nation;


DESCRIBE INPUT my_select2;


 Position | Type
-----------------
(0 rows)




See also#
PREPARE
















 Previous  DESCRIBE 



  Next  DESCRIBE OUTPUT 











































DESCRIBE OUTPUT — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DESCRIBE OUTPUT 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT



 DESCRIBE OUTPUT 
DESCRIBE OUTPUT

Contents

Synopsis

Description

Examples

See also





DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









DESCRIBE OUTPUT#

Synopsis#
DESCRIBE OUTPUT statement_name




Description#
List the output columns of a prepared statement, including the
column name (or alias), catalog, schema, table, type, type size in
bytes, and a boolean indicating if the column is aliased.


Examples#
Prepare and describe a query with four output columns:
PREPARE my_select1 FROM
SELECT * FROM nation;


DESCRIBE OUTPUT my_select1;


 Column Name | Catalog | Schema | Table  |  Type   | Type Size | Aliased
-------------+---------+--------+--------+---------+-----------+---------
 nationkey   | tpch    | sf1    | nation | bigint  |         8 | false
 name        | tpch    | sf1    | nation | varchar |         0 | false
 regionkey   | tpch    | sf1    | nation | bigint  |         8 | false
 comment     | tpch    | sf1    | nation | varchar |         0 | false
(4 rows)


Prepare and describe a query whose output columns are expressions:
PREPARE my_select2 FROM
SELECT count(*) as my_count, 1+2 FROM nation;


DESCRIBE OUTPUT my_select2;


 Column Name | Catalog | Schema | Table |  Type  | Type Size | Aliased
-------------+---------+--------+-------+--------+-----------+---------
 my_count    |         |        |       | bigint |         8 | true
 _col1       |         |        |       | bigint |         8 | false
(2 rows)


Prepare and describe a row count query:
PREPARE my_create FROM
CREATE TABLE foo AS SELECT * FROM nation;


DESCRIBE OUTPUT my_create;


 Column Name | Catalog | Schema | Table |  Type  | Type Size | Aliased
-------------+---------+--------+-------+--------+-----------+---------
 rows        |         |        |       | bigint |         8 | false
(1 row)




See also#
PREPARE
















 Previous  DESCRIBE INPUT 



  Next  DROP CATALOG 











































DROP CATALOG — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DROP CATALOG 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT



 DROP CATALOG 
DROP CATALOG

Contents

Synopsis

Description

Examples

See also





DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









DROP CATALOG#

Synopsis#
DROP CATALOG catalog_name




Description#
Drops an existing catalog. Dropping a catalog does not interrupt any running
queries that use it, but makes it unavailable to any new queries.

Warning
Some connectors are known not to release all resources when dropping a catalog
that uses such connector. This includes all connectors that can read data from
HDFS, S3, GCS, or Azure, which are Hive connector,
Iceberg connector, Delta Lake connector, and
Hudi connector.


Note
This command requires the catalog management type
to be set to dynamic.



Examples#
Drop the catalog example:
DROP CATALOG example;




See also#

CREATE CATALOG
Catalog management properties

















 Previous  DESCRIBE OUTPUT 



  Next  DROP FUNCTION 











































DROP FUNCTION — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DROP FUNCTION 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG



 DROP FUNCTION 
DROP FUNCTION

Contents

Synopsis

Description

Examples

See also





DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









DROP FUNCTION#

Synopsis#
DROP FUNCTION [ IF EXISTS ] udf_name ( [ [ parameter_name ] data_type [, ...] ] )




Description#
Removes a catalog UDF. The value of udf_name must be fully
qualified with catalog and schema location of the UDF, unless the default UDF storage catalog and schema are
configured.
The data_types must be included for UDFs that use parameters to ensure the UDF
with the correct name and parameter signature is removed.
The optional IF EXISTS clause causes the error to be suppressed if
the function does not exist.


Examples#
The following example removes the meaning_of_life UDF in the default schema
of the example catalog:
DROP FUNCTION example.default.meaning_of_life();


If the UDF uses a input parameter, the type must be added:
DROP FUNCTION multiply_by_two(bigint);


If the default catalog and schema for UDF
storage is configured, you can use the
following more compact syntax:
DROP FUNCTION meaning_of_life();




See also#

CREATE FUNCTION
SHOW CREATE FUNCTION
SHOW FUNCTIONS
User-defined functions
SQL environment properties

















 Previous  DROP CATALOG 



  Next  DROP MATERIALIZED VIEW 











































DROP MATERIALIZED VIEW — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DROP MATERIALIZED VIEW 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION



 DROP MATERIALIZED VIEW 
DROP MATERIALIZED VIEW

Contents

Synopsis

Description

Examples

See also





DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









DROP MATERIALIZED VIEW#

Synopsis#
DROP MATERIALIZED VIEW [ IF EXISTS ] view_name




Description#
Drop an existing materialized view view_name.
The optional IF EXISTS clause causes the error to be suppressed if
the materialized view does not exist.


Examples#
Drop the materialized view orders_by_date:
DROP MATERIALIZED VIEW orders_by_date;


Drop the materialized view orders_by_date if it exists:
DROP MATERIALIZED VIEW IF EXISTS orders_by_date;




See also#

CREATE MATERIALIZED VIEW
SHOW CREATE MATERIALIZED VIEW
REFRESH MATERIALIZED VIEW

















 Previous  DROP FUNCTION 



  Next  DROP ROLE 











































DROP ROLE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DROP ROLE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW



 DROP ROLE 
DROP ROLE

Contents

Synopsis

Description

Examples

Limitations

See also





DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations

See also









DROP ROLE#

Synopsis#
DROP ROLE [ IF EXISTS ] role_name
[ IN catalog ]




Description#
DROP ROLE drops the specified role.
For DROP ROLE statement to succeed, the user executing it should possess
admin privileges for the given role.
The optional IF EXISTS prevents the statement from failing if the role
isn’t found.
The optional IN catalog clause drops the role in a catalog as opposed
to a system role.


Examples#
Drop role admin
DROP ROLE admin;




Limitations#
Some connectors do not support role management.
See connector documentation for more details.


See also#
CREATE ROLE, SET ROLE, GRANT role, REVOKE role
















 Previous  DROP MATERIALIZED VIEW 



  Next  DROP SCHEMA 











































DROP SCHEMA — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DROP SCHEMA 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE



 DROP SCHEMA 
DROP SCHEMA

Contents

Synopsis

Description

Examples

See also





DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









DROP SCHEMA#

Synopsis#
DROP SCHEMA [ IF EXISTS ] schema_name [ CASCADE | RESTRICT ]




Description#
Drop an existing schema. The schema must be empty.
The optional IF EXISTS clause causes the error to be suppressed if
the schema does not exist.


Examples#
Drop the schema web:
DROP SCHEMA web


Drop the schema sales if it exists:
DROP SCHEMA IF EXISTS sales


Drop the schema archive, along with everything it contains:
DROP SCHEMA archive CASCADE


Drop the schema archive, only if there are no objects contained in the schema:
DROP SCHEMA archive RESTRICT




See also#
ALTER SCHEMA, CREATE SCHEMA
















 Previous  DROP ROLE 



  Next  DROP TABLE 











































DROP TABLE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DROP TABLE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA



 DROP TABLE 
DROP TABLE

Contents

Synopsis

Description

Examples

See also





DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









DROP TABLE#

Synopsis#
DROP TABLE  [ IF EXISTS ] table_name




Description#
Drops an existing table.
The optional IF EXISTS clause causes the error to be suppressed if the table
does not exist. The error is not suppressed if a Trino view with the same name
exists.


Examples#
Drop the table orders_by_date:
DROP TABLE orders_by_date


Drop the table orders_by_date if it exists:
DROP TABLE IF EXISTS orders_by_date




See also#
ALTER TABLE, CREATE TABLE
















 Previous  DROP SCHEMA 



  Next  DROP VIEW 











































DROP VIEW — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 DROP VIEW 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE



 DROP VIEW 
DROP VIEW

Contents

Synopsis

Description

Examples

See also





EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









DROP VIEW#

Synopsis#
DROP VIEW [ IF EXISTS ] view_name




Description#
Drop an existing view.
The optional IF EXISTS clause causes the error to be suppressed if
the view does not exist.


Examples#
Drop the view orders_by_date:
DROP VIEW orders_by_date


Drop the view orders_by_date if it exists:
DROP VIEW IF EXISTS orders_by_date




See also#
CREATE VIEW
















 Previous  DROP TABLE 



  Next  EXECUTE 











































EXECUTE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 EXECUTE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW



 EXECUTE 
EXECUTE

Contents

Synopsis

Description

Examples

See also





EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









EXECUTE#

Synopsis#
EXECUTE statement_name [ USING parameter1 [ , parameter2, ... ] ]




Description#
Executes a prepared statement with the name statement_name. Parameter values
are defined in the USING clause.


Examples#
Prepare and execute a query with no parameters:
PREPARE my_select1 FROM
SELECT name FROM nation;


EXECUTE my_select1;


Prepare and execute a query with two parameters:
PREPARE my_select2 FROM
SELECT name FROM nation WHERE regionkey = ? and nationkey < ?;


EXECUTE my_select2 USING 1, 3;


This is equivalent to:
SELECT name FROM nation WHERE regionkey = 1 AND nationkey < 3;




See also#
PREPARE, DEALLOCATE PREPARE, EXECUTE IMMEDIATE
















 Previous  DROP VIEW 



  Next  EXECUTE IMMEDIATE 











































EXECUTE IMMEDIATE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 EXECUTE IMMEDIATE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE



 EXECUTE IMMEDIATE 
EXECUTE IMMEDIATE

Contents

Synopsis

Description

Examples

See also





EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









EXECUTE IMMEDIATE#

Synopsis#
EXECUTE IMMEDIATE `statement` [ USING parameter1 [ , parameter2, ... ] ]




Description#
Executes a statement without the need to prepare or deallocate the statement.
Parameter values are defined in the USING clause.


Examples#
Execute a query with no parameters:
EXECUTE IMMEDIATE
'SELECT name FROM nation';


Execute a query with two parameters:
EXECUTE IMMEDIATE
'SELECT name FROM nation WHERE regionkey = ? and nationkey < ?'
USING 1, 3;


This is equivalent to:
PREPARE statement_name FROM SELECT name FROM nation WHERE regionkey = ? and nationkey < ?
EXECUTE statement_name USING 1, 3
DEALLOCATE PREPARE statement_name




See also#
EXECUTE, PREPARE, DEALLOCATE PREPARE
















 Previous  EXECUTE 



  Next  EXPLAIN 











































EXPLAIN — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 EXPLAIN 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE



 EXPLAIN 
EXPLAIN

Contents

Synopsis

Description

Examples

EXPLAIN (TYPE LOGICAL)

EXPLAIN (TYPE LOGICAL, FORMAT JSON)

EXPLAIN (TYPE DISTRIBUTED)

EXPLAIN (TYPE DISTRIBUTED, FORMAT JSON)

EXPLAIN (TYPE VALIDATE)

EXPLAIN (TYPE IO)



See also





EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

EXPLAIN (TYPE LOGICAL)

EXPLAIN (TYPE LOGICAL, FORMAT JSON)

EXPLAIN (TYPE DISTRIBUTED)

EXPLAIN (TYPE DISTRIBUTED, FORMAT JSON)

EXPLAIN (TYPE VALIDATE)

EXPLAIN (TYPE IO)



See also









EXPLAIN#

Synopsis#
EXPLAIN [ ( option [, ...] ) ] statement


where option can be one of:
FORMAT { TEXT | GRAPHVIZ | JSON }
TYPE { LOGICAL | DISTRIBUTED | VALIDATE | IO }




Description#
Show the logical or distributed execution plan of a statement, or validate the statement.
The distributed plan is shown by default. Each plan fragment of the distributed plan is executed by
a single or multiple Trino nodes. Fragments separation represent the data exchange between Trino nodes.
Fragment type specifies how the fragment is executed by Trino nodes and how the data is
distributed between fragments:

SINGLEFragment is executed on a single node.

HASHFragment is executed on a fixed number of nodes with the input data
distributed using a hash function.

ROUND_ROBINFragment is executed on a fixed number of nodes with the input data
distributed in a round-robin fashion.

BROADCASTFragment is executed on a fixed number of nodes with the input data
broadcasted to all nodes.

SOURCEFragment is executed on nodes where input splits are accessed.




Examples#

EXPLAIN (TYPE LOGICAL)#
Process the supplied query statement and create a logical plan in text format:
EXPLAIN (TYPE LOGICAL) SELECT regionkey, count(*) FROM nation GROUP BY 1;


                                                   Query Plan
-----------------------------------------------------------------------------------------------------------------
 Trino version: version
 Output[regionkey, _col1]
 │   Layout: [regionkey:bigint, count:bigint]
 │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
 │   _col1 := count
 └─ RemoteExchange[GATHER]
    │   Layout: [regionkey:bigint, count:bigint]
    │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
    └─ Aggregate(FINAL)[regionkey]
       │   Layout: [regionkey:bigint, count:bigint]
       │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
       │   count := count("count_8")
       └─ LocalExchange[HASH][$hashvalue] ("regionkey")
          │   Layout: [regionkey:bigint, count_8:bigint, $hashvalue:bigint]
          │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
          └─ RemoteExchange[REPARTITION][$hashvalue_9]
             │   Layout: [regionkey:bigint, count_8:bigint, $hashvalue_9:bigint]
             │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
             └─ Project[]
                │   Layout: [regionkey:bigint, count_8:bigint, $hashvalue_10:bigint]
                │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
                │   $hashvalue_10 := "combine_hash"(bigint '0', COALESCE("$operator$hash_code"("regionkey"), 0))
                └─ Aggregate(PARTIAL)[regionkey]
                   │   Layout: [regionkey:bigint, count_8:bigint]
                   │   count_8 := count(*)
                   └─ TableScan[tpch:nation:sf0.01]
                          Layout: [regionkey:bigint]
                          Estimates: {rows: 25 (225B), cpu: 225, memory: 0B, network: 0B}
                          regionkey := tpch:regionkey




EXPLAIN (TYPE LOGICAL, FORMAT JSON)#

Warning
The output format is not guaranteed to be backward compatible across Trino versions.

Process the supplied query statement and create a logical plan in JSON format:
EXPLAIN (TYPE LOGICAL, FORMAT JSON) SELECT regionkey, count(*) FROM nation GROUP BY 1;


{
   "id": "9",
   "name": "Output",
   "descriptor": {
      "columnNames": "[regionkey, _col1]"
   },
   "outputs": [
      {
         "symbol": "regionkey",
         "type": "bigint"
      },
      {
         "symbol": "count",
         "type": "bigint"
      }
   ],
   "details": [
      "_col1 := count"
   ],
   "estimates": [
      {
         "outputRowCount": "NaN",
         "outputSizeInBytes": "NaN",
         "cpuCost": "NaN",
         "memoryCost": "NaN",
         "networkCost": "NaN"
      }
   ],
   "children": [
      {
         "id": "145",
         "name": "RemoteExchange",
         "descriptor": {
            "type": "GATHER",
            "isReplicateNullsAndAny": "",
            "hashColumn": ""
         },
         "outputs": [
            {
               "symbol": "regionkey",
               "type": "bigint"
            },
            {
               "symbol": "count",
               "type": "bigint"
            }
         ],
         "details": [

         ],
         "estimates": [
            {
               "outputRowCount": "NaN",
               "outputSizeInBytes": "NaN",
               "cpuCost": "NaN",
               "memoryCost": "NaN",
               "networkCost": "NaN"
            }
         ],
         "children": [
            {
               "id": "4",
               "name": "Aggregate",
               "descriptor": {
                  "type": "FINAL",
                  "keys": "[regionkey]",
                  "hash": ""
               },
               "outputs": [
                  {
                     "symbol": "regionkey",
                     "type": "bigint"
                  },
                  {
                     "symbol": "count",
                     "type": "bigint"
                  }
               ],
               "details": [
                  "count := count(\"count_0\")"
               ],
               "estimates": [
                  {
                     "outputRowCount": "NaN",
                     "outputSizeInBytes": "NaN",
                     "cpuCost": "NaN",
                     "memoryCost": "NaN",
                     "networkCost": "NaN"
                  }
               ],
               "children": [
                  {
                     "id": "194",
                     "name": "LocalExchange",
                     "descriptor": {
                        "partitioning": "HASH",
                        "isReplicateNullsAndAny": "",
                        "hashColumn": "[$hashvalue]",
                        "arguments": "[\"regionkey\"]"
                     },
                     "outputs": [
                        {
                           "symbol": "regionkey",
                           "type": "bigint"
                        },
                        {
                           "symbol": "count_0",
                           "type": "bigint"
                        },
                        {
                           "symbol": "$hashvalue",
                           "type": "bigint"
                        }
                     ],
                     "details":[],
                     "estimates": [
                        {
                           "outputRowCount": "NaN",
                           "outputSizeInBytes": "NaN",
                           "cpuCost": "NaN",
                           "memoryCost": "NaN",
                           "networkCost": "NaN"
                        }
                     ],
                     "children": [
                        {
                           "id": "200",
                           "name": "RemoteExchange",
                           "descriptor": {
                              "type": "REPARTITION",
                              "isReplicateNullsAndAny": "",
                              "hashColumn": "[$hashvalue_1]"
                           },
                           "outputs": [
                              {
                                 "symbol": "regionkey",
                                 "type": "bigint"
                              },
                              {
                                 "symbol": "count_0",
                                 "type": "bigint"
                              },
                              {
                                 "symbol": "$hashvalue_1",
                                 "type": "bigint"
                              }
                           ],
                           "details":[],
                           "estimates": [
                              {
                                 "outputRowCount": "NaN",
                                 "outputSizeInBytes": "NaN",
                                 "cpuCost": "NaN",
                                 "memoryCost": "NaN",
                                 "networkCost": "NaN"
                              }
                           ],
                           "children": [
                              {
                                 "id": "226",
                                 "name": "Project",
                                 "descriptor": {}
                                 "outputs": [
                                    {
                                       "symbol": "regionkey",
                                       "type": "bigint"
                                    },
                                    {
                                       "symbol": "count_0",
                                       "type": "bigint"
                                    },
                                    {
                                       "symbol": "$hashvalue_2",
                                       "type": "bigint"
                                    }
                                 ],
                                 "details": [
                                    "$hashvalue_2 := combine_hash(bigint '0', COALESCE(\"$operator$hash_code\"(\"regionkey\"), 0))"
                                 ],
                                 "estimates": [
                                    {
                                       "outputRowCount": "NaN",
                                       "outputSizeInBytes": "NaN",
                                       "cpuCost": "NaN",
                                       "memoryCost": "NaN",
                                       "networkCost": "NaN"
                                    }
                                 ],
                                 "children": [
                                    {
                                       "id": "198",
                                       "name": "Aggregate",
                                       "descriptor": {
                                          "type": "PARTIAL",
                                          "keys": "[regionkey]",
                                          "hash": ""
                                       },
                                       "outputs": [
                                          {
                                             "symbol": "regionkey",
                                             "type": "bigint"
                                          },
                                          {
                                             "symbol": "count_0",
                                             "type": "bigint"
                                          }
                                       ],
                                       "details": [
                                          "count_0 := count(*)"
                                       ],
                                       "estimates":[],
                                       "children": [
                                          {
                                             "id": "0",
                                             "name": "TableScan",
                                             "descriptor": {
                                                "table": "hive:tpch_sf1_orc_part:nation"
                                             },
                                             "outputs": [
                                                {
                                                   "symbol": "regionkey",
                                                   "type": "bigint"
                                                }
                                             ],
                                             "details": [
                                                "regionkey := regionkey:bigint:REGULAR"
                                             ],
                                             "estimates": [
                                                {
                                                   "outputRowCount": 25,
                                                   "outputSizeInBytes": 225,
                                                   "cpuCost": 225,
                                                   "memoryCost": 0,
                                                   "networkCost": 0
                                                }
                                             ],
                                             "children": []
                                          }
                                       ]
                                    }
                                 ]
                              }
                           ]
                        }
                     ]
                  }
               ]
            }
         ]
      }
   ]
}




EXPLAIN (TYPE DISTRIBUTED)#
Process the supplied query statement and create a distributed plan in text
format. The distributed plan splits the logical plan into stages, and therefore
explicitly shows the data exchange between workers:
EXPLAIN (TYPE DISTRIBUTED) SELECT regionkey, count(*) FROM nation GROUP BY 1;


                                              Query Plan
------------------------------------------------------------------------------------------------------
 Trino version: version
 Fragment 0 [SINGLE]
     Output layout: [regionkey, count]
     Output partitioning: SINGLE []
     Output[regionkey, _col1]
     │   Layout: [regionkey:bigint, count:bigint]
     │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
     │   _col1 := count
     └─ RemoteSource[1]
            Layout: [regionkey:bigint, count:bigint]

 Fragment 1 [HASH]
     Output layout: [regionkey, count]
     Output partitioning: SINGLE []
     Aggregate(FINAL)[regionkey]
     │   Layout: [regionkey:bigint, count:bigint]
     │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
     │   count := count("count_8")
     └─ LocalExchange[HASH][$hashvalue] ("regionkey")
        │   Layout: [regionkey:bigint, count_8:bigint, $hashvalue:bigint]
        │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
        └─ RemoteSource[2]
               Layout: [regionkey:bigint, count_8:bigint, $hashvalue_9:bigint]

 Fragment 2 [SOURCE]
     Output layout: [regionkey, count_8, $hashvalue_10]
     Output partitioning: HASH [regionkey][$hashvalue_10]
     Project[]
     │   Layout: [regionkey:bigint, count_8:bigint, $hashvalue_10:bigint]
     │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
     │   $hashvalue_10 := "combine_hash"(bigint '0', COALESCE("$operator$hash_code"("regionkey"), 0))
     └─ Aggregate(PARTIAL)[regionkey]
        │   Layout: [regionkey:bigint, count_8:bigint]
        │   count_8 := count(*)
        └─ TableScan[tpch:nation:sf0.01, grouped = false]
               Layout: [regionkey:bigint]
               Estimates: {rows: 25 (225B), cpu: 225, memory: 0B, network: 0B}
               regionkey := tpch:regionkey




EXPLAIN (TYPE DISTRIBUTED, FORMAT JSON)#

Warning
The output format is not guaranteed to be backward compatible across Trino versions.

Process the supplied query statement and create a distributed plan in JSON
format. The distributed plan splits the logical plan into stages, and therefore
explicitly shows the data exchange between workers:
EXPLAIN (TYPE DISTRIBUTED, FORMAT JSON) SELECT regionkey, count(*) FROM nation GROUP BY 1;


{
   "0" : {
      "id" : "9",
      "name" : "Output",
      "descriptor" : {
         "columnNames" : "[regionkey, _col1]"
      },
      "outputs" : [ {
         "symbol" : "regionkey",
         "type" : "bigint"
      }, {
         "symbol" : "count",
         "type" : "bigint"
      } ],
      "details" : [ "_col1 := count" ],
      "estimates" : [ {
         "outputRowCount" : "NaN",
         "outputSizeInBytes" : "NaN",
         "cpuCost" : "NaN",
         "memoryCost" : "NaN",
         "networkCost" : "NaN"
      } ],
      "children" : [ {
         "id" : "145",
         "name" : "RemoteSource",
         "descriptor" : {
            "sourceFragmentIds" : "[1]"
         },
         "outputs" : [ {
            "symbol" : "regionkey",
            "type" : "bigint"
         }, {
            "symbol" : "count",
            "type" : "bigint"
         } ],
         "details" : [ ],
         "estimates" : [ ],
         "children" : [ ]
      } ]
   },
   "1" : {
      "id" : "4",
      "name" : "Aggregate",
      "descriptor" : {
         "type" : "FINAL",
         "keys" : "[regionkey]",
         "hash" : "[]"
      },
      "outputs" : [ {
         "symbol" : "regionkey",
         "type" : "bigint"
      }, {
         "symbol" : "count",
         "type" : "bigint"
      } ],
      "details" : [ "count := count(\"count_0\")" ],
      "estimates" : [ {
         "outputRowCount" : "NaN",
         "outputSizeInBytes" : "NaN",
         "cpuCost" : "NaN",
         "memoryCost" : "NaN",
         "networkCost" : "NaN"
      } ],
      "children" : [ {
         "id" : "194",
         "name" : "LocalExchange",
         "descriptor" : {
            "partitioning" : "SINGLE",
            "isReplicateNullsAndAny" : "",
            "hashColumn" : "[]",
            "arguments" : "[]"
         },
         "outputs" : [ {
            "symbol" : "regionkey",
            "type" : "bigint"
         }, {
            "symbol" : "count_0",
            "type" : "bigint"
         } ],
         "details" : [ ],
         "estimates" : [ {
            "outputRowCount" : "NaN",
            "outputSizeInBytes" : "NaN",
            "cpuCost" : "NaN",
            "memoryCost" : "NaN",
            "networkCost" : "NaN"
         } ],
         "children" : [ {
            "id" : "227",
            "name" : "Project",
            "descriptor" : { },
            "outputs" : [ {
               "symbol" : "regionkey",
               "type" : "bigint"
            }, {
               "symbol" : "count_0",
               "type" : "bigint"
            } ],
            "details" : [ ],
            "estimates" : [ {
               "outputRowCount" : "NaN",
               "outputSizeInBytes" : "NaN",
               "cpuCost" : "NaN",
               "memoryCost" : "NaN",
               "networkCost" : "NaN"
            } ],
            "children" : [ {
               "id" : "200",
               "name" : "RemoteSource",
               "descriptor" : {
                  "sourceFragmentIds" : "[2]"
               },
               "outputs" : [ {
                  "symbol" : "regionkey",
                  "type" : "bigint"
               }, {
                  "symbol" : "count_0",
                  "type" : "bigint"
               }, {
                  "symbol" : "$hashvalue",
                  "type" : "bigint"
               } ],
               "details" : [ ],
               "estimates" : [ ],
               "children" : [ ]
            } ]
         } ]
      } ]
   },
   "2" : {
      "id" : "226",
      "name" : "Project",
      "descriptor" : { },
      "outputs" : [ {
         "symbol" : "regionkey",
         "type" : "bigint"
      }, {
         "symbol" : "count_0",
         "type" : "bigint"
      }, {
         "symbol" : "$hashvalue_1",
         "type" : "bigint"
      } ],
      "details" : [ "$hashvalue_1 := combine_hash(bigint '0', COALESCE(\"$operator$hash_code\"(\"regionkey\"), 0))" ],
      "estimates" : [ {
         "outputRowCount" : "NaN",
         "outputSizeInBytes" : "NaN",
         "cpuCost" : "NaN",
         "memoryCost" : "NaN",
         "networkCost" : "NaN"
      } ],
      "children" : [ {
         "id" : "198",
         "name" : "Aggregate",
         "descriptor" : {
            "type" : "PARTIAL",
            "keys" : "[regionkey]",
            "hash" : "[]"
         },
         "outputs" : [ {
            "symbol" : "regionkey",
            "type" : "bigint"
         }, {
            "symbol" : "count_0",
            "type" : "bigint"
         } ],
         "details" : [ "count_0 := count(*)" ],
         "estimates" : [ ],
         "children" : [ {
            "id" : "0",
            "name" : "TableScan",
            "descriptor" : {
               "table" : "tpch:tiny:nation"
            },
            "outputs" : [ {
               "symbol" : "regionkey",
               "type" : "bigint"
            } ],
            "details" : [ "regionkey := tpch:regionkey" ],
            "estimates" : [ {
               "outputRowCount" : 25.0,
               "outputSizeInBytes" : 225.0,
               "cpuCost" : 225.0,
               "memoryCost" : 0.0,
               "networkCost" : 0.0
            } ],
            "children" : [ ]
         } ]
      } ]
   }
}




EXPLAIN (TYPE VALIDATE)#
Validate the supplied query statement for syntactical and semantic correctness.
Returns true if the statement is valid:
EXPLAIN (TYPE VALIDATE) SELECT regionkey, count(*) FROM nation GROUP BY 1;


 Valid
-------
 true


If the statement is not correct because a syntax error, such as an unknown
keyword, is found the error message details the problem:
EXPLAIN (TYPE VALIDATE) SELET 1=0;


Query 20220929_234840_00001_vjwxj failed: line 1:25: mismatched input 'SELET'.
Expecting: 'ALTER', 'ANALYZE', 'CALL', 'COMMENT', 'COMMIT', 'CREATE',
'DEALLOCATE', 'DELETE', 'DENY', 'DESC', 'DESCRIBE', 'DROP', 'EXECUTE',
'EXPLAIN', 'GRANT', 'INSERT', 'MERGE', 'PREPARE', 'REFRESH', 'RESET',
'REVOKE', 'ROLLBACK', 'SET', 'SHOW', 'START', 'TRUNCATE', 'UPDATE', 'USE',
<query>


Similarly if semantic issues are detected, such as an invalid object name
nations instead of nation, the error message returns useful
information:
EXPLAIN(TYPE VALIDATE) SELECT * FROM tpch.tiny.nations;


Query 20220929_235059_00003_vjwxj failed: line 1:15: Table 'tpch.tiny.nations' does not exist
SELECT * FROM tpch.tiny.nations




EXPLAIN (TYPE IO)#
Process the supplied query statement and create a plan with input and output
details about the accessed objects in JSON format:
EXPLAIN (TYPE IO, FORMAT JSON) INSERT INTO test_lineitem
SELECT * FROM lineitem WHERE shipdate = '2020-02-01' AND quantity > 10;


            Query Plan
-----------------------------------
{
   inputTableColumnInfos: [
      {
         table: {
            catalog: "hive",
            schemaTable: {
               schema: "tpch",
               table: "test_orders"
            }
         },
         columnConstraints: [
            {
               columnName: "orderkey",
               type: "bigint",
               domain: {
                  nullsAllowed: false,
                  ranges: [
                     {
                        low: {
                           value: "1",
                           bound: "EXACTLY"
                        },
                        high: {
                           value: "1",
                           bound: "EXACTLY"
                        }
                     },
                     {
                        low: {
                           value: "2",
                           bound: "EXACTLY"
                        },
                        high: {
                           value: "2",
                           bound: "EXACTLY"
                        }
                     }
                  ]
               }
            },
            {
               columnName: "processing",
               type: "boolean",
               domain: {
                  nullsAllowed: false,
                  ranges: [
                     {
                        low: {
                           value: "false",
                           bound: "EXACTLY"
                        },
                        high: {
                           value: "false",
                           bound: "EXACTLY"
                        }
                     }
                  ]
               }
            },
            {
               columnName: "custkey",
               type: "bigint",
               domain: {
                  nullsAllowed: false,
                  ranges: [
                     {
                        low: {
                           bound: "ABOVE"
                        },
                        high: {
                           value: "10",
                           bound: "EXACTLY"
                        }
                     }
                  ]
               }
            }
         ],
         estimate: {
            outputRowCount: 2,
            outputSizeInBytes: 40,
            cpuCost: 40,
            maxMemory: 0,
            networkCost: 0
         }
      }
   ],
   outputTable: {
      catalog: "hive",
      schemaTable: {
         schema: "tpch",
         table: "test_orders"
      }
   },
   estimate: {
      outputRowCount: "NaN",
      outputSizeInBytes: "NaN",
      cpuCost: "NaN",
      maxMemory: "NaN",
      networkCost: "NaN"
   }
}





See also#
EXPLAIN ANALYZE
















 Previous  EXECUTE IMMEDIATE 



  Next  EXPLAIN ANALYZE 











































EXPLAIN ANALYZE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 EXPLAIN ANALYZE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN



 EXPLAIN ANALYZE 
EXPLAIN ANALYZE

Contents

Synopsis

Description

Examples

See also





GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









EXPLAIN ANALYZE#

Synopsis#
EXPLAIN ANALYZE [VERBOSE] statement




Description#
Execute the statement and show the distributed execution plan of the statement
along with the cost of each operation.
The VERBOSE option will give more detailed information and low-level statistics;
understanding these may require knowledge of Trino internals and implementation details.

Note
The stats may not be entirely accurate, especially for queries that complete quickly.



Examples#
In the example below, you can see the CPU time spent in each stage, as well as the relative
cost of each plan node in the stage. Note that the relative cost of the plan nodes is based on
wall time, which may or may not be correlated to CPU time. For each plan node you can see
some additional statistics (e.g: average input per node instance). Such statistics are useful
when one wants to detect data anomalies for a query (e.g: skewness).
EXPLAIN ANALYZE SELECT count(*), clerk FROM orders
WHERE orderdate > date '1995-01-01' GROUP BY clerk;


                                          Query Plan
-----------------------------------------------------------------------------------------------
Trino version: version
Queued: 374.17us, Analysis: 190.96ms, Planning: 179.03ms, Execution: 3.06s
Fragment 1 [HASH]
    CPU: 22.58ms, Scheduled: 96.72ms, Blocked 46.21s (Input: 23.06s, Output: 0.00ns), Input: 1000 rows (37.11kB); per task: avg.: 1000.00 std.dev.: 0.00, Output: 1000 rows (28.32kB)
    Output layout: [clerk, count]
    Output partitioning: SINGLE []
    Project[]
    │   Layout: [clerk:varchar(15), count:bigint]
    │   Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: 0B}
    │   CPU: 8.00ms (3.51%), Scheduled: 63.00ms (15.11%), Blocked: 0.00ns (0.00%), Output: 1000 rows (28.32kB)
    │   Input avg.: 15.63 rows, Input std.dev.: 24.36%
    └─ Aggregate[type = FINAL, keys = [clerk], hash = [$hashvalue]]
       │   Layout: [clerk:varchar(15), $hashvalue:bigint, count:bigint]
       │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: 0B}
       │   CPU: 8.00ms (3.51%), Scheduled: 22.00ms (5.28%), Blocked: 0.00ns (0.00%), Output: 1000 rows (37.11kB)
       │   Input avg.: 15.63 rows, Input std.dev.: 24.36%
       │   count := count("count_0")
       └─ LocalExchange[partitioning = HASH, hashColumn = [$hashvalue], arguments = ["clerk"]]
          │   Layout: [clerk:varchar(15), count_0:bigint, $hashvalue:bigint]
          │   Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: 0B}
          │   CPU: 2.00ms (0.88%), Scheduled: 4.00ms (0.96%), Blocked: 23.15s (50.10%), Output: 1000 rows (37.11kB)
          │   Input avg.: 15.63 rows, Input std.dev.: 793.73%
          └─ RemoteSource[sourceFragmentIds = [2]]
                 Layout: [clerk:varchar(15), count_0:bigint, $hashvalue_1:bigint]
                 CPU: 0.00ns (0.00%), Scheduled: 0.00ns (0.00%), Blocked: 23.06s (49.90%), Output: 1000 rows (37.11kB)
                 Input avg.: 15.63 rows, Input std.dev.: 793.73%

Fragment 2 [SOURCE]
    CPU: 210.60ms, Scheduled: 327.92ms, Blocked 0.00ns (Input: 0.00ns, Output: 0.00ns), Input: 1500000 rows (18.17MB); per task: avg.: 1500000.00 std.dev.: 0.00, Output: 1000 rows (37.11kB)
    Output layout: [clerk, count_0, $hashvalue_2]
    Output partitioning: HASH [clerk][$hashvalue_2]
    Aggregate[type = PARTIAL, keys = [clerk], hash = [$hashvalue_2]]
    │   Layout: [clerk:varchar(15), $hashvalue_2:bigint, count_0:bigint]
    │   CPU: 30.00ms (13.16%), Scheduled: 30.00ms (7.19%), Blocked: 0.00ns (0.00%), Output: 1000 rows (37.11kB)
    │   Input avg.: 818058.00 rows, Input std.dev.: 0.00%
    │   count_0 := count(*)
    └─ ScanFilterProject[table = hive:sf1:orders, filterPredicate = ("orderdate" > DATE '1995-01-01')]
           Layout: [clerk:varchar(15), $hashvalue_2:bigint]
           Estimates: {rows: 1500000 (41.48MB), cpu: 35.76M, memory: 0B, network: 0B}/{rows: 816424 (22.58MB), cpu: 35.76M, memory: 0B, network: 0B}/{rows: 816424 (22.58MB), cpu: 22.58M, memory: 0B, network: 0B}
           CPU: 180.00ms (78.95%), Scheduled: 298.00ms (71.46%), Blocked: 0.00ns (0.00%), Output: 818058 rows (12.98MB)
           Input avg.: 1500000.00 rows, Input std.dev.: 0.00%
           $hashvalue_2 := combine_hash(bigint '0', COALESCE("$operator$hash_code"("clerk"), 0))
           clerk := clerk:varchar(15):REGULAR
           orderdate := orderdate:date:REGULAR
           Input: 1500000 rows (18.17MB), Filtered: 45.46%, Physical Input: 4.51MB


When the VERBOSE option is used, some operators may report additional information.
For example, the window function operator will output the following:
EXPLAIN ANALYZE VERBOSE SELECT count(clerk) OVER() FROM orders
WHERE orderdate > date '1995-01-01';


                                          Query Plan
-----------------------------------------------------------------------------------------------
  ...
         ─ Window[]
           │   Layout: [clerk:varchar(15), count:bigint]
           │   CPU: 157.00ms (53.40%), Scheduled: 158.00ms (37.71%), Blocked: 0.00ns (0.00%), Output: 818058 rows (22.62MB)
           │   metrics:
           │     'CPU time distribution (s)' = {count=1.00, p01=0.16, p05=0.16, p10=0.16, p25=0.16, p50=0.16, p75=0.16, p90=0.16, p95=0.16, p99=0.16, min=0.16, max=0.16}
           │     'Input rows distribution' = {count=1.00, p01=818058.00, p05=818058.00, p10=818058.00, p25=818058.00, p50=818058.00, p75=818058.00, p90=818058.00, p95=818058.00, p99=818058.00, min=818058.00, max=818058.00}
           │     'Scheduled time distribution (s)' = {count=1.00, p01=0.16, p05=0.16, p10=0.16, p25=0.16, p50=0.16, p75=0.16, p90=0.16, p95=0.16, p99=0.16, min=0.16, max=0.16}
           │   Input avg.: 818058.00 rows, Input std.dev.: 0.00%
           │   Active Drivers: [ 1 / 1 ]
           │   Index size: std.dev.: 0.00 bytes, 0.00 rows
           │   Index count per driver: std.dev.: 0.00
           │   Rows per driver: std.dev.: 0.00
           │   Size of partition: std.dev.: 0.00
           │   count := count("clerk") RANGE UNBOUNDED_PRECEDING CURRENT_ROW
 ...




See also#
EXPLAIN
















 Previous  EXPLAIN 



  Next  GRANT privilege 











































GRANT privilege — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 GRANT privilege 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE



 GRANT privilege 
GRANT privilege

Contents

Synopsis

Description

Examples

Limitations

See also





GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations

See also









GRANT privilege#

Synopsis#
GRANT ( privilege [, ...] | ( ALL PRIVILEGES ) )
ON ( table_name | TABLE table_name | SCHEMA schema_name)
TO ( user | USER user | ROLE role )
[ WITH GRANT OPTION ]




Description#
Grants the specified privileges to the specified grantee.
Specifying ALL PRIVILEGES grants DELETE, INSERT, UPDATE and SELECT privileges.
Specifying ROLE PUBLIC grants privileges to the PUBLIC role and hence to all users.
The optional WITH GRANT OPTION clause allows the grantee to grant these same privileges to others.
For GRANT statement to succeed, the user executing it should possess the specified privileges as well as the GRANT OPTION for those privileges.
Grant on a table grants the specified privilege on all current and future columns of the table.
Grant on a schema grants the specified privilege on all current and future columns of all current and future tables of the schema.


Examples#
Grant INSERT and SELECT privileges on the table orders to user alice:
GRANT INSERT, SELECT ON orders TO alice;


Grant DELETE privilege on the schema finance to user bob:
GRANT DELETE ON SCHEMA finance TO bob;


Grant SELECT privilege on the table nation to user alice, additionally allowing alice to grant SELECT privilege to others:
GRANT SELECT ON nation TO alice WITH GRANT OPTION;


Grant SELECT privilege on the table orders to everyone:
GRANT SELECT ON orders TO ROLE PUBLIC;




Limitations#
Some connectors have no support for GRANT.
See connector documentation for more details.


See also#
DENY, REVOKE privilege, SHOW GRANTS
















 Previous  EXPLAIN ANALYZE 



  Next  GRANT role 











































GRANT role — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 GRANT role 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege



 GRANT role 
GRANT role

Contents

Synopsis

Description

Examples

Limitations

See also





INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations

See also









GRANT role#

Synopsis#
GRANT role_name [, ...]
TO ( user | USER user_name | ROLE role_name) [, ...]
[ GRANTED BY ( user | USER user | ROLE role | CURRENT_USER | CURRENT_ROLE ) ]
[ WITH ADMIN OPTION ]
[ IN catalog ]




Description#
Grants the specified role(s) to the specified principal(s).
If the WITH ADMIN OPTION clause is specified, the role(s) are granted
to the users with GRANT option.
For the GRANT statement for roles to succeed, the user executing it either should
be the role admin or should possess the GRANT option for the given role.
The optional GRANTED BY clause causes the role(s) to be granted with
the specified principal as a grantor. If the GRANTED BY clause is not
specified, the roles are granted with the current user as a grantor.
The optional IN catalog clause grants the roles in a catalog as opposed
to a system roles.


Examples#
Grant role bar to user foo
GRANT bar TO USER foo;


Grant roles bar and foo to user baz and role qux with admin option
GRANT bar, foo TO USER baz, ROLE qux WITH ADMIN OPTION;




Limitations#
Some connectors do not support role management.
See connector documentation for more details.


See also#
CREATE ROLE, DROP ROLE, SET ROLE, REVOKE role
















 Previous  GRANT privilege 



  Next  INSERT 











































INSERT — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 INSERT 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role



 INSERT 
INSERT

Contents

Synopsis

Description

Examples

See also





MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









INSERT#

Synopsis#
INSERT INTO table_name [ ( column [, ... ] ) ] query




Description#
Insert new rows into a table.
If the list of column names is specified, they must exactly match the list
of columns produced by the query. Each column in the table not present in the
column list will be filled with a null value. Otherwise, if the list of
columns is not specified, the columns produced by the query must exactly match
the columns in the table being inserted into.


Examples#
Load additional rows into the orders table from the new_orders table:
INSERT INTO orders
SELECT * FROM new_orders;


Insert a single row into the cities table:
INSERT INTO cities VALUES (1, 'San Francisco');


Insert multiple rows into the cities table:
INSERT INTO cities VALUES (2, 'San Jose'), (3, 'Oakland');


Insert a single row into the nation table with the specified column list:
INSERT INTO nation (nationkey, name, regionkey, comment)
VALUES (26, 'POLAND', 3, 'no comment');


Insert a row without specifying the comment column.
That column will be null:
INSERT INTO nation (nationkey, name, regionkey)
VALUES (26, 'POLAND', 3);




See also#
VALUES
















 Previous  GRANT role 



  Next  MATCH_RECOGNIZE 











































MATCH_RECOGNIZE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 MATCH_RECOGNIZE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT



 MATCH_RECOGNIZE 
MATCH_RECOGNIZE

Contents

Synopsis

Description

Example

Partitioning and ordering

Row pattern measures

Rows per match

After match skip

Row pattern syntax

concatenation

alternation

permutation

grouping

partition start anchor

partition end anchor

empty pattern

exclusion syntax

quantifiers



Row pattern union variables

Row pattern variable definitions

Row pattern recognition expressions

pattern variable references

classifier function

match_number function

logical navigation functions

physical navigation functions

nesting of navigation functions

Aggregate functions

Aggregation arguments

Nesting of aggregate functions

Usage of the classifier and match_number functions

Row pattern count aggregation



RUNNING and FINAL semantics



Evaluating expressions in empty matches and unmatched rows





MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Example

Partitioning and ordering

Row pattern measures

Rows per match

After match skip

Row pattern syntax

concatenation

alternation

permutation

grouping

partition start anchor

partition end anchor

empty pattern

exclusion syntax

quantifiers



Row pattern union variables

Row pattern variable definitions

Row pattern recognition expressions

pattern variable references

classifier function

match_number function

logical navigation functions

physical navigation functions

nesting of navigation functions

Aggregate functions

Aggregation arguments

Nesting of aggregate functions

Usage of the classifier and match_number functions

Row pattern count aggregation



RUNNING and FINAL semantics



Evaluating expressions in empty matches and unmatched rows









MATCH_RECOGNIZE#

Synopsis#
MATCH_RECOGNIZE (
  [ PARTITION BY column [, ...] ]
  [ ORDER BY column [, ...] ]
  [ MEASURES measure_definition [, ...] ]
  [ rows_per_match ]
  [ AFTER MATCH skip_to ]
  PATTERN ( row_pattern )
  [ SUBSET subset_definition [, ...] ]
  DEFINE variable_definition [, ...]
  )




Description#
The MATCH_RECOGNIZE clause is an optional subclause of the FROM clause.
It is used to detect patterns in a set of rows. Patterns of interest are
specified using row pattern syntax based on regular expressions. The input to
pattern matching is a table, a view or a subquery. For each detected match, one
or more rows are returned. They contain requested information about the match.
Row pattern matching is a powerful tool when analyzing complex sequences of
events. The following examples show some of the typical use cases:

in trade applications, tracking trends or identifying customers with specific
behavioral patterns
in shipping applications, tracking packages through all possible valid paths,
in financial applications, detecting unusual incidents, which might signal
fraud



Example#
In the following example, the pattern describes a V-shape over the
totalprice column. A match is found whenever orders made by a customer
first decrease in price, and then increase past the starting point:
SELECT * FROM orders MATCH_RECOGNIZE(
     PARTITION BY custkey
     ORDER BY orderdate
     MEASURES
              A.totalprice AS starting_price,
              LAST(B.totalprice) AS bottom_price,
              LAST(U.totalprice) AS top_price
     ONE ROW PER MATCH
     AFTER MATCH SKIP PAST LAST ROW
     PATTERN (A B+ C+ D+)
     SUBSET U = (C, D)
     DEFINE
              B AS totalprice < PREV(totalprice),
              C AS totalprice > PREV(totalprice) AND totalprice <= A.totalprice,
              D AS totalprice > PREV(totalprice)
     )


In the following sections, all subclauses of the MATCH_RECOGNIZE clause are
explained with this example query.


Partitioning and ordering#
PARTITION BY custkey


The PARTITION BY clause allows you to break up the input table into
separate sections, that are independently processed for pattern matching.
Without a partition declaration, the whole input table is used. This behavior
is analogous to the semantics of PARTITION BY clause in window specification. In the example, the orders table is
partitioned by the custkey value, so that pattern matching is performed for
all orders of a specific customer independently from orders of other
customers.
ORDER BY orderdate


The optional ORDER BY clause is generally useful to allow matching on an
ordered data set. For example, sorting the input by orderdate allows for
matching on a trend of changes over time.


Row pattern measures#
The MEASURES clause allows to specify what information is retrieved from a
matched sequence of rows.
MEASURES measure_expression AS measure_name [, ...]


A measure expression is a scalar expression whose value is computed based on a
match. In the example, three row pattern measures are specified:
A.totalprice AS starting_price returns the price in the first row of the
match, which is the only row associated with A according to the pattern.
LAST(B.totalprice) AS bottom_price returns the lowest price (corresponding
to the bottom of the “V” in the pattern). It is the price in the last row
associated with B, which is the last row of the descending section.
LAST(U.totalprice) AS top_price returns the highest price in the match. It
is the price in the last row associated with C or D, which is also the
final row of the match.
Measure expressions can refer to the columns of the input table. They also
allow special syntax to combine the input information with the details of the
match (see Row pattern recognition expressions).
Each measure defines an output column of the pattern recognition. The column
can be referenced with the measure_name.
The MEASURES clause is optional. When no measures are specified, certain
input columns (depending on ROWS PER MATCH clause) are
the output of the pattern recognition.


Rows per match#
This clause can be used to specify the quantity of output rows. There are two
main options:
ONE ROW PER MATCH


and
ALL ROWS PER MATCH


ONE ROW PER MATCH is the default option. For every match, a single row of
output is produced. Output consists of PARTITION BY columns and measures.
The output is also produced for empty matches, based on their starting rows.
Rows that are unmatched (that is, neither included in some non-empty match, nor
being the starting row of an empty match), are not included in the output.
For ALL ROWS PER MATCH, every row of a match produces an output row, unless
it is excluded from the output by the exclusion syntax. Output consists
of PARTITION BY columns, ORDER BY columns, measures and remaining
columns from the input table. By default, empty matches are shown and unmatched
rows are skipped, similarly as with the ONE ROW PER MATCH option. However,
this behavior can be changed by modifiers:
ALL ROWS PER MATCH SHOW EMPTY MATCHES


shows empty matches and skips unmatched rows, like the default.
ALL ROWS PER MATCH OMIT EMPTY MATCHES


excludes empty matches from the output.
ALL ROWS PER MATCH WITH UNMATCHED ROWS


shows empty matches and produces additional output row for each unmatched row.
There are special rules for computing row pattern measures for empty matches
and unmatched rows. They are explained in
Evaluating expressions in empty matches and unmatched rows.
Unmatched rows can only occur when the pattern does not allow an empty match.
Otherwise, they are considered as starting rows of empty matches. The option
ALL ROWS PER MATCH WITH UNMATCHED ROWS is recommended when pattern
recognition is expected to pass all input rows, and it is not certain whether
the pattern allows an empty match.


After match skip#
The AFTER MATCH SKIP clause specifies where pattern matching resumes after
a non-empty match is found.
The default option is:
AFTER MATCH SKIP PAST LAST ROW


With this option, pattern matching starts from the row after the last row of
the match. Overlapping matches are not detected.
With the following option, pattern matching starts from the second row of the
match:
AFTER MATCH SKIP TO NEXT ROW


In the example, if a V-shape is detected, further overlapping matches are
found, starting from consecutive rows on the descending slope of the “V”.
Skipping to the next row is the default behavior after detecting an empty match
or unmatched row.
The following AFTER MATCH SKIP options allow to resume pattern matching
based on the components of the pattern. Pattern matching starts from the last
(default) or first row matched to a certain row pattern variable. It can be
either a primary pattern variable (they are explained in
Row pattern syntax) or a
union variable:
AFTER MATCH SKIP TO [ FIRST | LAST ] pattern_variable


It is forbidden to skip to the first row of the current match, because it
results in an infinite loop. For example specifying AFTER MATCH SKIP TO A
fails, because A is the first element of the pattern, and jumping back to
it creates an infinite loop. Similarly, skipping to a pattern variable which is
not present in the match causes failure.
All other options than the default AFTER MATCH SKIP PAST LAST ROW allow
detection of overlapping matches. The combination of ALL ROWS PER MATCH WITH UNMATCHED ROWS with AFTER MATCH SKIP PAST LAST ROW is the only
configuration that guarantees exactly one output row for each input row.


Row pattern syntax#
Row pattern is a form of a regular expression with some syntactical extensions
specific to row pattern recognition. It is specified in the PATTERN
clause:
PATTERN ( row_pattern )


The basic element of row pattern is a primary pattern variable. Like pattern
matching in character strings searches for characters, pattern matching in row
sequences searches for rows which can be “labeled” with certain primary pattern
variables. A primary pattern variable has a form of an identifier and is
defined by a boolean condition. This
condition determines whether a particular input row can be mapped to this
variable and take part in the match.
In the example PATTERN (A B+ C+ D+), there are four primary pattern
variables: A, B, C, and D.
Row pattern syntax includes the following usage:

concatenation#
A B+ C+ D+


It is a sequence of components without operators between them. All components
are matched in the same order as they are specified.


alternation#
A | B | C


It is a sequence of components separated by |. Exactly one of the
components is matched. In case when multiple components can be matched, the
leftmost matching component is chosen.


permutation#
PERMUTE(A, B, C)


It is equivalent to alternation of all permutations of its components. All
components are matched in some order. If multiple matches are possible for
different orderings of the components, the match is chosen based on the
lexicographical order established by the order of components in the PERMUTE
list. In the above example, the most preferred option is A B C, and the
least preferred option is C B A.


grouping#
(A B C)




partition start anchor#
^




partition end anchor#
$




empty pattern#
()




exclusion syntax#
{- row_pattern -}


Exclusion syntax is used to specify portions of the match to exclude from the
output. It is useful in combination with the ALL ROWS PER MATCH option,
when only certain sections of the match are interesting.
If you change the example to use ALL ROWS PER MATCH, and the pattern is
modified to PATTERN (A {- B+ C+ -} D+), the result consists of the initial
matched row and the trailing section of rows.
Specifying pattern exclusions does not affect the computation of expressions in
MEASURES and DEFINE clauses. Exclusions also do not affect pattern
matching. They have the same semantics as regular grouping with parentheses.
It is forbidden to specify pattern exclusions with the option ALL ROWS PER MATCH WITH UNMATCHED ROWS.


quantifiers#
Pattern quantifiers allow to specify the desired number of repetitions of a
sub-pattern in a match. They are appended after the relevant pattern
component:
(A | B)*


There are following row pattern quantifiers:

zero or more repetitions:

*



one or more repetitions:

+



zero or one repetition:

?



exact number of repetitions, specified by a non-negative integer number:

{n}



number of repetitions ranging between bounds, specified by non-negative
integer numbers:

{m, n}


Specifying bounds is optional. If the left bound is omitted, it defaults to
0. So, {, 5} can be described as “between zero and five repetitions”.
If the right bound is omitted, the number of accepted repetitions is unbounded.
So, {5, } can be described as “at least five repetitions”. Also, {,} is
equivalent to *.
Quantifiers are greedy by default. It means that higher number of repetitions
is preferred over lower number. This behavior can be changed to reluctant by
appending ? immediately after the quantifier. With {3, 5}, 3
repetitions is the least desired option and 5 repetitions – the most desired.
With {3, 5}?, 3 repetitions are most desired. Similarly, ? prefers 1
repetition, while ?? prefers 0 repetitions.



Row pattern union variables#
As explained in Row pattern syntax, primary pattern variables are the
basic elements of row pattern. In addition to primary pattern variables, you
can define union variables. They are introduced in the SUBSET clause:
SUBSET U = (C, D), ...


In the preceding example, union variable U is defined as union of primary
variables C and D. Union variables are useful in MEASURES,
DEFINE and AFTER MATCH SKIP clauses. They allow you to refer to set of
rows matched to either primary variable from a subset.
With the pattern: PATTERN((A | B){5} C+) it cannot be determined upfront if
the match contains any A or any B. A union variable can be used to
access the last row matched to either A or B. Define SUBSET U = (A, B), and the expression LAST(U.totalprice) returns the value of the
totalprice column from the last row mapped to either A or B. Also,
AFTER MATCH SKIP TO LAST A or AFTER MATCH SKIP TO LAST B can result in
failure if A or B is not present in the match. AFTER MATCH SKIP TO LAST U does not fail.


Row pattern variable definitions#
The DEFINE clause is where row pattern primary variables are defined. Each
variable is associated with a boolean condition:
DEFINE B AS totalprice < PREV(totalprice), ...


During pattern matching, when a certain variable is considered for the next
step of the match, the boolean condition is evaluated in context of the current
match. If the result is true, then the current row, “labeled” with the
variable, becomes part of the match.
In the preceding example, assume that the pattern allows to match B at some
point. There are some rows already matched to some pattern variables. Now,
variable B is being considered for the current row. Before the match is
made, the defining condition for B is evaluated. In this example, it is
only true if the value of the totalprice column in the current row is lower
than totalprice in the preceding row.
The mechanism of matching variables to rows shows the difference between
pattern matching in row sequences and regular expression matching in text. In
text, characters remain constantly in their positions. In row pattern matching,
a row can be mapped to different variables in different matches, depending on
the preceding part of the match, and even on the match number.
It is not required that every primary variable has a definition in the
DEFINE clause. Variables not mentioned in the DEFINE clause are
implicitly associated with true condition, which means that they can be
matched to every row.
Boolean expressions in the DEFINE clause allow the same special syntax as
expressions in the MEASURES clause. Details are explained in
Row pattern recognition expressions.


Row pattern recognition expressions#
Expressions in MEASURES and
DEFINE clauses are scalar expressions
evaluated over rows of the input table. They support special syntax, specific
to pattern recognition context. They can combine input information with the
information about the current match. Special syntax allows to access pattern
variables assigned to rows, browse rows based on how they are matched, and
refer to the sequential number of the match.

pattern variable references#
A.totalprice

U.orderdate

orderstatus


A column name prefixed with a pattern variable refers to values of this column
in all rows matched to this variable, or to any variable from the subset in
case of union variable. If a column name is not prefixed, it is considered as
prefixed with the universal pattern variable, defined as union of all
primary pattern variables. In other words, a non-prefixed column name refers to
all rows of the current match.
It is forbidden to prefix a column name with a table name in the pattern
recognition context.


classifier function#
CLASSIFIER()

CLASSIFIER(A)

CLASSIFIER(U)


The classifier function returns the primary pattern variable associated
with the row. The return type is varchar. The optional argument is a
pattern variable. It limits the rows of interest, the same way as with prefixed
column references. The classifier function is particularly useful with a
union variable as the argument. It allows you to determine which variable from
the subset actually matched.


match_number function#
MATCH_NUMBER()


The match_number function returns the sequential number of the match within
partition, starting from 1. Empty matches are assigned sequential numbers
as well as non-empty matches. The return type is bigint.


logical navigation functions#
FIRST(A.totalprice, 2)


In the above example, the first function navigates to the first row matched
to pattern variable A, and then searches forward until it finds two more
occurrences of variable A within the match. The result is the value of the
totalprice column in that row.
LAST(A.totalprice, 2)


In the above example, the last function navigates to the last row matched
to pattern variable A, and then searches backwards until it finds two more
occurrences of variable A within the match. The result is the value of the
totalprice column in that row.
With the first and last functions the result is null, if the
searched row is not found in the mach.
The second argument is optional. The default value is 0, which means that
by default these functions navigate to the first or last row of interest. If
specified, the second argument must be a non-negative integer number.


physical navigation functions#
PREV(A.totalprice, 2)


In the above example, the prev function navigates to the last row matched
to pattern variable A, and then searches two rows backward. The result is
the value of the totalprice column in that row.
NEXT(A.totalprice, 2)


In the above example, the next function navigates to the last row matched
to pattern variable A, and then searches two rows forward. The result is
the value of the totalprice column in that row.
With the prev and next functions, it is possible to navigate and
retrieve values outside the match. If the navigation goes beyond partition
bounds, the result is null.
The second argument is optional. The default value is 1, which means that
by default these functions navigate to previous or next row. If specified, the
second argument must be a non-negative integer number.


nesting of navigation functions#
It is possible to nest logical navigation functions within physical navigation
functions:
PREV(FIRST(A.totalprice, 3), 2)


In case of nesting, first the logical navigation is performed. It establishes
the starting row for the physical navigation. When both navigation operations
succeed, the value is retrieved from the designated row.
Pattern navigation functions require at least one column reference or
classifier function inside of their first argument. The following examples
are correct:
LAST("pattern_variable_" || CLASSIFIER())

NEXT(U.totalprice + 10)


This is incorrect:
LAST(1)


It is also required that all column references and all classifier calls
inside a pattern navigation function are consistent in referred pattern
variables. They must all refer either to the same primary variable, the same
union variable, or to the implicit universal pattern variable. The following
examples are correct:
LAST(CLASSIFIER() = 'A' OR totalprice > 10) /* universal pattern variable */

LAST(CLASSIFIER(U) = 'A' OR U.totalprice > 10) /* pattern variable U */


This is incorrect:
LAST(A.totalprice + B.totalprice)




Aggregate functions#
It is allowed to use aggregate functions in a row pattern recognition context.
Aggregate functions are evaluated over all rows of the current match or over a
subset of rows based on the matched pattern variables. The
running and final semantics are supported, with
running as the default.
The following expression returns the average value of the totalprice column
for all rows matched to pattern variable A:
avg(A.totalprice)


The following expression returns the average value of the totalprice column
for all rows matched to pattern variables from subset U:
avg(U.totalprice)


The following expression returns the average value of the totalprice column
for all rows of the match:
avg(totalprice)



Aggregation arguments#
In case when the aggregate function has multiple arguments, it is required that
all arguments refer consistently to the same set of rows:
max_by(totalprice, tax) /* aggregate over all rows of the match */

max_by(CLASSIFIER(A), A.tax) /* aggregate over all rows matched to A */


This is incorrect:
max_by(A.totalprice, tax)

max_by(A.totalprice, A.tax + B.tax)


If an aggregate argument does not contain any column reference or
classifier function, it does not refer to any pattern variable. In such a
case other aggregate arguments determine the set of rows to aggregate over. If
none of the arguments contains a pattern variable reference, the universal row
pattern variable is implicit. This means that the aggregate function applies to
all rows of the match:
count(1) /* aggregate over all rows of the match */

min_by(1, 2) /* aggregate over all rows of the match */

min_by(1, totalprice) /* aggregate over all rows of the match */

min_by(totalprice, 1) /* aggregate over all rows of the match */

min_by(A.totalprice, 1) /* aggregate over all rows matched to A */

max_by(1, A.totalprice) /* aggregate over all rows matched to A */




Nesting of aggregate functions#
Aggregate function arguments must not contain pattern navigation functions.
Similarly, aggregate functions cannot be nested in pattern navigation
functions.


Usage of the classifier and match_number functions#
It is allowed to use the classifier and match_number functions in
aggregate function arguments. The following expression returns an array
containing all matched pattern variables:
array_agg(CLASSIFIER())


This is particularly useful in combination with the option
ONE ROW PER MATCH. It allows to get all the components of the match while
keeping the output size reduced.


Row pattern count aggregation#
Like other aggregate functions in a row pattern recognition context, the
count function can be applied to all rows of the match, or to rows
associated with certain row pattern variables:
count(*), count() /* count all rows of the match */

count(totalprice) /* count non-null values of the totalprice column
                     in all rows of the match */

count(A.totalprice) /* count non-null values of the totalprice column
                       in all rows matched to A */


The count function in a row pattern recognition context allows special syntax
to support the count(*) behavior over a limited set of rows:
count(A.*) /* count rows matched to A */

count(U.*) /* count rows matched to pattern variables from subset U */





RUNNING and FINAL semantics#
During pattern matching in a sequence of rows, one row after another is
examined to determine if it fits the pattern. At any step, a partial match is
known, but it is not yet known what rows will be added in the future or what
pattern variables they will be mapped to. So, when evaluating a boolean
condition in the DEFINE clause for the current row, only the preceding part
of the match (plus the current row) is “visible”. This is the running
semantics.
When evaluating expressions in the MEASURES clause, the match is complete.
It is then possible to apply the final semantics. In the final
semantics, the whole match is “visible” as from the position of the final row.
In the MEASURES clause, the running semantics can also be applied. When
outputting information row by row (as in ALL ROWS PER MATCH), the
running semantics evaluate expressions from the positions of consecutive
rows.
The running and final semantics are denoted by the keywords:
RUNNING and FINAL, preceding a logical navigation function first or
last, or an aggregate function:
RUNNING LAST(A.totalprice)

FINAL LAST(A.totalprice)

RUNNING avg(A.totalprice)

FINAL count(A.*)


The running semantics is default in MEASURES and DEFINE clauses.
FINAL can only be specified in the MEASURES clause.
With the option ONE ROW PER MATCH, row pattern measures are evaluated from
the position of the final row in the match. Therefore, running and
final semantics are the same.



Evaluating expressions in empty matches and unmatched rows#
An empty match occurs when the row pattern is successfully matched, but no
pattern variables are assigned. The following pattern produces an empty match
for every row:
PATTERN(())


When evaluating row pattern measures for an empty match:

all column references return null
all navigation operations return null
classifier function returns null
match_number function returns the sequential number of the match
all aggregate functions are evaluated over an empty set of rows

Like every match, an empty match has its starting row. All input values which
are to be output along with the measures (as explained in
Rows per match), are the values from the starting row.
An unmatched row is a row that is neither part of any non-empty match nor the
starting row of an empty match. With the option ALL ROWS PER MATCH WITH UNMATCHED ROWS, a single output row is produced. In that row, all row pattern
measures are null. All input values which are to be output along with the
measures (as explained in Rows per match), are the values from the
unmatched row. Using the match_number function as a measure can help
differentiate between an empty match and unmatched row.
















 Previous  INSERT 



  Next  MERGE 











































MERGE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 MERGE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE



 MERGE 
MERGE

Contents

Synopsis

Description

Examples

Limitations





PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations









MERGE#

Synopsis#
MERGE INTO target_table [ [ AS ]  target_alias ]
USING { source_table | query } [ [ AS ] source_alias ]
ON search_condition
when_clause [...]


where when_clause is one of
WHEN MATCHED [ AND condition ]
    THEN DELETE


WHEN MATCHED [ AND condition ]
    THEN UPDATE SET ( column = expression [, ...] )


WHEN NOT MATCHED [ AND condition ]
    THEN INSERT [ column_list ] VALUES (expression, ...)




Description#
Conditionally update and/or delete rows of a table and/or insert new
rows into a table.
MERGE changes data in the target_table based on the contents of the
source_table. The search_condition defines a condition, such as a relation
from identical columns, to associate the source and target data.
MERGE supports an arbitrary number of WHEN clauses. MATCHED conditions can
execute DELETE or UPDATE operations on the target data, while NOT MATCHED
conditions can add data from the source to the target table with INSERT.
Additional conditions can narrow down the affected rows.
For each source row, the WHEN clauses are processed in order. Only the first
matching WHEN clause is executed and subsequent clauses are ignored. The query
fails if a single target table row matches more than one source row.
In WHEN clauses with UPDATE operations, the column value expressions
can depend on any field of the target or the source. In the NOT MATCHED
case, the INSERT expressions can depend on any field of the source.
Typical usage of MERGE involves two tables with similar structure, containing
different data. For example, the source table is part of a transactional usage
in a production system, while the target table is located in a data warehouse
used for analytics. Periodically, MERGE operations are run to combine recent
production data with long-term data in the analytics warehouse. As long as you
can define a search condition between the two tables, you can also use very
different tables.


Examples#
Delete all customers mentioned in the source table:
MERGE INTO accounts t USING monthly_accounts_update s
    ON t.customer = s.customer
    WHEN MATCHED
        THEN DELETE


For matching customer rows, increment the purchases, and if there is no
match, insert the row from the source table:
MERGE INTO accounts t USING monthly_accounts_update s
    ON (t.customer = s.customer)
    WHEN MATCHED
        THEN UPDATE SET purchases = s.purchases + t.purchases
    WHEN NOT MATCHED
        THEN INSERT (customer, purchases, address)
              VALUES(s.customer, s.purchases, s.address)


MERGE into the target table from the source table, deleting any matching
target row for which the source address is Centreville. For all other matching
rows, add the source purchases and set the address to the source address. If
there is no match in the target table, insert the source table row:
MERGE INTO accounts t USING monthly_accounts_update s
    ON (t.customer = s.customer)
    WHEN MATCHED AND s.address = 'Centreville'
        THEN DELETE
    WHEN MATCHED
        THEN UPDATE
            SET purchases = s.purchases + t.purchases, address = s.address
    WHEN NOT MATCHED
        THEN INSERT (customer, purchases, address)
              VALUES(s.customer, s.purchases, s.address)




Limitations#
Any connector can be used as a source table for a MERGE statement.
Only connectors which support the MERGE statement can be the target of a
merge operation. See the connector documentation for more
information.
















 Previous  MATCH_RECOGNIZE 



  Next  PREPARE 











































PREPARE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 PREPARE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE



 PREPARE 
PREPARE

Contents

Synopsis

Description

Examples

See also





REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









PREPARE#

Synopsis#
PREPARE statement_name FROM statement




Description#
Prepares a statement for execution at a later time. Prepared statements are
queries that are saved in a session with a given name. The statement can
include parameters in place of literals to be replaced at execution time.
Parameters are represented by question marks.


Examples#
Prepare a select query:
PREPARE my_select1 FROM
SELECT * FROM nation;


Prepare a select query that includes parameters. The values to compare with
regionkey and nationkey will be filled in with the EXECUTE statement:
PREPARE my_select2 FROM
SELECT name FROM nation WHERE regionkey = ? AND nationkey < ?;


Prepare an insert query:
PREPARE my_insert FROM
INSERT INTO cities VALUES (1, 'San Francisco');




See also#
EXECUTE, DEALLOCATE PREPARE, EXECUTE IMMEDIATE, DESCRIBE INPUT, DESCRIBE OUTPUT
















 Previous  MERGE 



  Next  REFRESH MATERIALIZED VIEW 











































REFRESH MATERIALIZED VIEW — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 REFRESH MATERIALIZED VIEW 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE



 REFRESH MATERIALIZED VIEW 
REFRESH MATERIALIZED VIEW

Contents

Synopsis

Description

See also





RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

See also









REFRESH MATERIALIZED VIEW#

Synopsis#
REFRESH MATERIALIZED VIEW view_name




Description#
Initially populate or refresh the data stored in the materialized view
view_name. The materialized view must be defined with
CREATE MATERIALIZED VIEW. Data is retrieved from the underlying tables
accessed by the defined query.
The initial population of the materialized view is typically processing
intensive since it reads the data from the source tables and performs physical
write operations.
The refresh operation can be less intensive, if the underlying data has not
changed and the connector has implemented a mechanism to be aware of that. The
specific implementation and performance varies by connector used to create the
materialized view.


See also#

CREATE MATERIALIZED VIEW
DROP MATERIALIZED VIEW
SHOW CREATE MATERIALIZED VIEW

















 Previous  PREPARE 



  Next  RESET SESSION 











































RESET SESSION — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 RESET SESSION 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW



 RESET SESSION 
RESET SESSION

Contents

Synopsis

Description

Examples

See also





RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









RESET SESSION#

Synopsis#
RESET SESSION name
RESET SESSION catalog.name




Description#
Reset a session property value to the
default value.


Examples#
RESET SESSION query_max_run_time;
RESET SESSION hive.optimized_reader_enabled;




See also#
SET SESSION, SHOW SESSION
















 Previous  REFRESH MATERIALIZED VIEW 



  Next  RESET SESSION AUTHORIZATION 











































RESET SESSION AUTHORIZATION — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 RESET SESSION AUTHORIZATION 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION



 RESET SESSION AUTHORIZATION 
RESET SESSION AUTHORIZATION

Contents

Synopsis

Description

See also





REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

See also









RESET SESSION AUTHORIZATION#

Synopsis#
RESET SESSION AUTHORIZATION




Description#
Resets the current authorization user back to the original user. The original
user is usually the authenticated user (principal), or it can be the session
user when the session user is provided by the client.


See also#
SET SESSION AUTHORIZATION
















 Previous  RESET SESSION 



  Next  REVOKE privilege 











































REVOKE privilege — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 REVOKE privilege 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION



 REVOKE privilege 
REVOKE privilege

Contents

Synopsis

Description

Examples

Limitations

See also





REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations

See also









REVOKE privilege#

Synopsis#
REVOKE [ GRANT OPTION FOR ]
( privilege [, ...] | ALL PRIVILEGES )
ON ( table_name | TABLE table_name | SCHEMA schema_name )
FROM ( user | USER user | ROLE role )




Description#
Revokes the specified privileges from the specified grantee.
Specifying ALL PRIVILEGES revokes DELETE, INSERT and SELECT privileges.
Specifying ROLE PUBLIC revokes privileges from the PUBLIC role. Users will retain privileges assigned to them directly or via other roles.
If the optional GRANT OPTION FOR clause is specified, only the GRANT OPTION
is removed. Otherwise, both the GRANT and GRANT OPTION are revoked.
For REVOKE statement to succeed, the user executing it should possess the specified privileges as well as the GRANT OPTION for those privileges.
Revoke on a table revokes the specified privilege on all columns of the table.
Revoke on a schema revokes the specified privilege on all columns of all tables of the schema.


Examples#
Revoke INSERT and SELECT privileges on the table orders from user alice:
REVOKE INSERT, SELECT ON orders FROM alice;


Revoke DELETE privilege on the schema finance from user bob:
REVOKE DELETE ON SCHEMA finance FROM bob;


Revoke SELECT privilege on the table nation from everyone, additionally revoking the privilege to grant SELECT privilege:
REVOKE GRANT OPTION FOR SELECT ON nation FROM ROLE PUBLIC;


Revoke all privileges on the table test from user alice:
REVOKE ALL PRIVILEGES ON test FROM alice;




Limitations#
Some connectors have no support for REVOKE.
See connector documentation for more details.


See also#
DENY, GRANT privilege, SHOW GRANTS
















 Previous  RESET SESSION AUTHORIZATION 



  Next  REVOKE role 











































REVOKE role — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 REVOKE role 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege



 REVOKE role 
REVOKE role

Contents

Synopsis

Description

Examples

Limitations

See also





ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations

See also









REVOKE role#

Synopsis#
REVOKE
[ ADMIN OPTION FOR ]
role_name [, ...]
FROM ( user | USER user | ROLE role) [, ...]
[ GRANTED BY ( user | USER user | ROLE role | CURRENT_USER | CURRENT_ROLE ) ]
[ IN catalog ]




Description#
Revokes the specified role(s) from the specified principal(s).
If the ADMIN OPTION FOR clause is specified, the GRANT permission is
revoked instead of the role.
For the REVOKE statement for roles to succeed, the user executing it either should
be the role admin or should possess the GRANT option for the given role.
The optional GRANTED BY clause causes the role(s) to be revoked with
the specified principal as a revoker. If the GRANTED BY clause is not
specified, the roles are revoked by the current user as a revoker.
The optional IN catalog clause revokes the roles in a catalog as opposed
to a system roles.


Examples#
Revoke role bar from user foo
REVOKE bar FROM USER foo;


Revoke admin option for roles bar and foo from user baz and role qux
REVOKE ADMIN OPTION FOR bar, foo FROM USER baz, ROLE qux;




Limitations#
Some connectors do not support role management.
See connector documentation for more details.


See also#
CREATE ROLE, DROP ROLE, SET ROLE, GRANT role
















 Previous  REVOKE privilege 



  Next  ROLLBACK 











































ROLLBACK — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 ROLLBACK 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role



 ROLLBACK 
ROLLBACK

Contents

Synopsis

Description

Examples

See also





SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









ROLLBACK#

Synopsis#
ROLLBACK [ WORK ]




Description#
Rollback the current transaction.


Examples#
ROLLBACK;
ROLLBACK WORK;




See also#
COMMIT, START TRANSACTION
















 Previous  REVOKE role 



  Next  SELECT 











































SELECT — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SELECT 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK



 SELECT 
SELECT

Contents

Synopsis

Description

WITH SESSION clause

WITH FUNCTION clause

WITH clause

WITH RECURSIVE clause

SELECT clause

Select expressions



GROUP BY clause

Complex grouping operations

GROUPING SETS

CUBE

ROLLUP

Combining multiple grouping expressions

GROUPING operation



HAVING clause

WINDOW clause

Set operations

UNION clause

INTERSECT clause

EXCEPT clause



ORDER BY clause

OFFSET clause

LIMIT or FETCH FIRST clause

TABLESAMPLE

UNNEST

JSON_TABLE

Joins

CROSS JOIN

LATERAL

Qualifying column names



Subqueries

EXISTS

IN

Scalar subquery







SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

WITH SESSION clause

WITH FUNCTION clause

WITH clause

WITH RECURSIVE clause

SELECT clause

Select expressions



GROUP BY clause

Complex grouping operations

GROUPING SETS

CUBE

ROLLUP

Combining multiple grouping expressions

GROUPING operation



HAVING clause

WINDOW clause

Set operations

UNION clause

INTERSECT clause

EXCEPT clause



ORDER BY clause

OFFSET clause

LIMIT or FETCH FIRST clause

TABLESAMPLE

UNNEST

JSON_TABLE

Joins

CROSS JOIN

LATERAL

Qualifying column names



Subqueries

EXISTS

IN

Scalar subquery











SELECT#

Synopsis#
[ WITH SESSION [ name = expression [, ...] ]
[ WITH [ FUNCTION udf ] [, ...] ]
[ WITH [ RECURSIVE ] with_query [, ...] ]
SELECT [ ALL | DISTINCT ] select_expression [, ...]
[ FROM from_item [, ...] ]
[ WHERE condition ]
[ GROUP BY [ ALL | DISTINCT ] grouping_element [, ...] ]
[ HAVING condition]
[ WINDOW window_definition_list]
[ { UNION | INTERSECT | EXCEPT } [ ALL | DISTINCT ] select ]
[ ORDER BY expression [ ASC | DESC ] [, ...] ]
[ OFFSET count [ ROW | ROWS ] ]
[ LIMIT { count | ALL } ]
[ FETCH { FIRST | NEXT } [ count ] { ROW | ROWS } { ONLY | WITH TIES } ]


where from_item is one of
table_name [ [ AS ] alias [ ( column_alias [, ...] ) ] ]


from_item join_type from_item
  [ ON join_condition | USING ( join_column [, ...] ) ]


table_name [ [ AS ] alias [ ( column_alias [, ...] ) ] ]
  MATCH_RECOGNIZE pattern_recognition_specification
    [ [ AS ] alias [ ( column_alias [, ...] ) ] ]


For detailed description of MATCH_RECOGNIZE clause, see pattern recognition in FROM clause.
TABLE (table_function_invocation) [ [ AS ] alias [ ( column_alias [, ...] ) ] ]


For description of table functions usage, see table functions.
and join_type is one of
[ INNER ] JOIN
LEFT [ OUTER ] JOIN
RIGHT [ OUTER ] JOIN
FULL [ OUTER ] JOIN
CROSS JOIN


and grouping_element is one of
()
expression
GROUPING SETS ( ( column [, ...] ) [, ...] )
CUBE ( column [, ...] )
ROLLUP ( column [, ...] )




Description#
Retrieve rows from zero or more tables.


WITH SESSION clause#
The WITH SESSION clause allows you to set session and catalog session
property values applicable for the processing of the current
SELECT statement only. The defined values override any other configuration and
session property settings. Multiple properties are separated by commas.
The following example overrides the global configuration property
query.max-execution-time with the session property query_max_execution_time
to reduce the time to 2h. It also overrides the catalog property
iceberg.query-partition-filter-required from the example catalog using
Iceberg connector setting the catalog session property
query_partition_filter_required to true:
WITH
  SESSION
    query_max_execution_time='2h',
    example.query_partition_filter_required=true
SELECT *
FROM example.default.thetable
LIMIT 100;




WITH FUNCTION clause#
The WITH FUNCTION clause allows you to define a list of Inline user-defined functions that
are available for use in the rest of the query.
The following example declares and uses two inline UDFs:
WITH 
  FUNCTION hello(name varchar)
    RETURNS varchar
    RETURN format('Hello %s!', 'name'),
  FUNCTION bye(name varchar)
    RETURNS varchar
    RETURN format('Bye %s!', 'name')
SELECT hello('Finn') || ' and ' || bye('Joe');
-- Hello Finn! and Bye Joe!


Find further information about UDFs in general, inline UDFs, all supported
statements, and examples in User-defined functions.


WITH clause#
The WITH clause defines named relations for use within a query.
It allows flattening nested queries or simplifying subqueries.
For example, the following queries are equivalent:
SELECT a, b
FROM (
  SELECT a, MAX(b) AS b FROM t GROUP BY a
) AS x;

WITH x AS (SELECT a, MAX(b) AS b FROM t GROUP BY a)
SELECT a, b FROM x;


This also works with multiple subqueries:
WITH
  t1 AS (SELECT a, MAX(b) AS b FROM x GROUP BY a),
  t2 AS (SELECT a, AVG(d) AS d FROM y GROUP BY a)
SELECT t1.*, t2.*
FROM t1
JOIN t2 ON t1.a = t2.a;


Additionally, the relations within a WITH clause can chain:
WITH
  x AS (SELECT a FROM t),
  y AS (SELECT a AS b FROM x),
  z AS (SELECT b AS c FROM y)
SELECT c FROM z;



Warning
Currently, the SQL for the WITH clause will be inlined anywhere the named
relation is used. This means that if the relation is used more than once and the query
is non-deterministic, the results may be different each time.



WITH RECURSIVE clause#
The WITH RECURSIVE clause is a variant of the WITH clause. It defines
a list of queries to process, including recursive processing of suitable
queries.

Warning
This feature is experimental only. Proceed to use it only if you understand
potential query failures and the impact of the recursion processing on your
workload.

A recursive WITH-query must be shaped as a UNION of two relations. The
first relation is called the recursion base, and the second relation is called
the recursion step. Trino supports recursive WITH-queries with a single
recursive reference to a WITH-query from within the query. The name T of
the query T can be mentioned once in the FROM clause of the recursion
step relation.
The following listing shows a simple example, that displays a commonly used
form of a single query in the list:
WITH RECURSIVE t(n) AS (
    VALUES (1)
    UNION ALL
    SELECT n + 1 FROM t WHERE n < 4
)
SELECT sum(n) FROM t;


In the preceding query the simple assignment VALUES (1) defines the
recursion base relation. SELECT n + 1 FROM t WHERE n < 4 defines the
recursion step relation. The recursion processing performs these steps:

recursive base yields 1
first recursion yields 1 + 1 = 2
second recursion uses the result from the first and adds one: 2 + 1 = 3
third recursion uses the result from the second and adds one again:
3 + 1 = 4
fourth recursion aborts since n = 4
this results in t having values 1, 2, 3 and 4
the final statement performs the sum operation of these elements with the
final result value 10

The types of the returned columns are those of the base relation. Therefore it
is required that types in the step relation can be coerced to base relation
types.
The RECURSIVE clause applies to all queries in the WITH list, but not
all of them must be recursive. If a WITH-query is not shaped according to
the rules mentioned above or it does not contain a recursive reference, it is
processed like a regular WITH-query. Column aliases are mandatory for all
the queries in the recursive WITH list.
The following limitations apply as a result of following the SQL standard and
due to implementation choices, in addition to WITH clause limitations:

only single-element recursive cycles are supported. Like in regular
WITH-queries, references to previous queries in the WITH list are
allowed. References to following queries are forbidden.
usage of outer joins, set operations, limit clause, and others is not always
allowed in the step relation
recursion depth is fixed, defaults to 10, and doesn’t depend on the actual
query results

You can adjust the recursion depth with the session property max_recursion_depth. When changing the value consider
that the size of the query plan growth is quadratic with the recursion depth.


SELECT clause#
The SELECT clause specifies the output of the query. Each select_expression
defines a column or columns to be included in the result.
SELECT [ ALL | DISTINCT ] select_expression [, ...]


The ALL and DISTINCT quantifiers determine whether duplicate rows
are included in the result set. If the argument ALL is specified,
all rows are included. If the argument DISTINCT is specified, only unique
rows are included in the result set. In this case, each output column must
be of a type that allows comparison. If neither argument is specified,
the behavior defaults to ALL.

Select expressions#
Each select_expression must be in one of the following forms:
expression [ [ AS ] column_alias ]


row_expression.* [ AS ( column_alias [, ...] ) ]


relation.*


*


In the case of expression [ [ AS ] column_alias ], a single output column
is defined.
In the case of row_expression.* [ AS ( column_alias [, ...] ) ],
the row_expression is an arbitrary expression of type ROW.
All fields of the row define output columns to be included in the result set.
In the case of relation.*, all columns of relation are included
in the result set. In this case column aliases are not allowed.
In the case of *, all columns of the relation defined by the query
are included in the result set.
In the result set, the order of columns is the same as the order of their
specification by the select expressions. If a select expression returns multiple
columns, they are ordered the same way they were ordered in the source
relation or row type expression.
If column aliases are specified, they override any preexisting column
or row field names:
SELECT (CAST(ROW(1, true) AS ROW(field1 bigint, field2 boolean))).* AS (alias1, alias2);


 alias1 | alias2
--------+--------
      1 | true
(1 row)


Otherwise, the existing names are used:
SELECT (CAST(ROW(1, true) AS ROW(field1 bigint, field2 boolean))).*;


 field1 | field2
--------+--------
      1 | true
(1 row)


and in their absence, anonymous columns are produced:
SELECT (ROW(1, true)).*;


 _col0 | _col1
-------+-------
     1 | true
(1 row)





GROUP BY clause#
The GROUP BY clause divides the output of a SELECT statement into
groups of rows containing matching values. A simple GROUP BY clause may
contain any expression composed of input columns or it may be an ordinal
number selecting an output column by position (starting at one).
The following queries are equivalent. They both group the output by
the nationkey input column with the first query using the ordinal
position of the output column and the second query using the input
column name:
SELECT count(*), nationkey FROM customer GROUP BY 2;

SELECT count(*), nationkey FROM customer GROUP BY nationkey;


GROUP BY clauses can group output by input column names not appearing in
the output of a select statement. For example, the following query generates
row counts for the customer table using the input column mktsegment:
SELECT count(*) FROM customer GROUP BY mktsegment;


 _col0
-------
 29968
 30142
 30189
 29949
 29752
(5 rows)


When a GROUP BY clause is used in a SELECT statement all output
expressions must be either aggregate functions or columns present in
the GROUP BY clause.

Complex grouping operations#
Trino also supports complex aggregations using the GROUPING SETS, CUBE
and ROLLUP syntax. This syntax allows users to perform analysis that requires
aggregation on multiple sets of columns in a single query. Complex grouping
operations do not support grouping on expressions composed of input columns.
Only column names are allowed.
Complex grouping operations are often equivalent to a UNION ALL of simple
GROUP BY expressions, as shown in the following examples. This equivalence
does not apply, however, when the source of data for the aggregation
is non-deterministic.


GROUPING SETS#
Grouping sets allow users to specify multiple lists of columns to group on.
The columns not part of a given sublist of grouping columns are set to NULL.
SELECT * FROM shipping;


 origin_state | origin_zip | destination_state | destination_zip | package_weight
--------------+------------+-------------------+-----------------+----------------
 California   |      94131 | New Jersey        |            8648 |             13
 California   |      94131 | New Jersey        |            8540 |             42
 New Jersey   |       7081 | Connecticut       |            6708 |            225
 California   |      90210 | Connecticut       |            6927 |           1337
 California   |      94131 | Colorado          |           80302 |              5
 New York     |      10002 | New Jersey        |            8540 |              3
(6 rows)


GROUPING SETS semantics are demonstrated by this example query:
SELECT origin_state, origin_zip, destination_state, sum(package_weight)
FROM shipping
GROUP BY GROUPING SETS (
    (origin_state),
    (origin_state, origin_zip),
    (destination_state));


 origin_state | origin_zip | destination_state | _col0
--------------+------------+-------------------+-------
 New Jersey   | NULL       | NULL              |   225
 California   | NULL       | NULL              |  1397
 New York     | NULL       | NULL              |     3
 California   |      90210 | NULL              |  1337
 California   |      94131 | NULL              |    60
 New Jersey   |       7081 | NULL              |   225
 New York     |      10002 | NULL              |     3
 NULL         | NULL       | Colorado          |     5
 NULL         | NULL       | New Jersey        |    58
 NULL         | NULL       | Connecticut       |  1562
(10 rows)


The preceding query may be considered logically equivalent to a UNION ALL of
multiple GROUP BY queries:
SELECT origin_state, NULL, NULL, sum(package_weight)
FROM shipping GROUP BY origin_state

UNION ALL

SELECT origin_state, origin_zip, NULL, sum(package_weight)
FROM shipping GROUP BY origin_state, origin_zip

UNION ALL

SELECT NULL, NULL, destination_state, sum(package_weight)
FROM shipping GROUP BY destination_state;


However, the query with the complex grouping syntax (GROUPING SETS, CUBE
or ROLLUP) will only read from the underlying data source once, while the
query with the UNION ALL reads the underlying data three times. This is why
queries with a UNION ALL may produce inconsistent results when the data
source is not deterministic.


CUBE#
The CUBE operator generates all possible grouping sets (i.e. a power set)
for a given set of columns. For example, the query:
SELECT origin_state, destination_state, sum(package_weight)
FROM shipping
GROUP BY CUBE (origin_state, destination_state);


is equivalent to:
SELECT origin_state, destination_state, sum(package_weight)
FROM shipping
GROUP BY GROUPING SETS (
    (origin_state, destination_state),
    (origin_state),
    (destination_state),
    ()
);


 origin_state | destination_state | _col0
--------------+-------------------+-------
 California   | New Jersey        |    55
 California   | Colorado          |     5
 New York     | New Jersey        |     3
 New Jersey   | Connecticut       |   225
 California   | Connecticut       |  1337
 California   | NULL              |  1397
 New York     | NULL              |     3
 New Jersey   | NULL              |   225
 NULL         | New Jersey        |    58
 NULL         | Connecticut       |  1562
 NULL         | Colorado          |     5
 NULL         | NULL              |  1625
(12 rows)




ROLLUP#
The ROLLUP operator generates all possible subtotals for a given set of
columns. For example, the query:
SELECT origin_state, origin_zip, sum(package_weight)
FROM shipping
GROUP BY ROLLUP (origin_state, origin_zip);


 origin_state | origin_zip | _col2
--------------+------------+-------
 California   |      94131 |    60
 California   |      90210 |  1337
 New Jersey   |       7081 |   225
 New York     |      10002 |     3
 California   | NULL       |  1397
 New York     | NULL       |     3
 New Jersey   | NULL       |   225
 NULL         | NULL       |  1625
(8 rows)


is equivalent to:
SELECT origin_state, origin_zip, sum(package_weight)
FROM shipping
GROUP BY GROUPING SETS ((origin_state, origin_zip), (origin_state), ());




Combining multiple grouping expressions#
Multiple grouping expressions in the same query are interpreted as having
cross-product semantics. For example, the following query:
SELECT origin_state, destination_state, origin_zip, sum(package_weight)
FROM shipping
GROUP BY
    GROUPING SETS ((origin_state, destination_state)),
    ROLLUP (origin_zip);


which can be rewritten as:
SELECT origin_state, destination_state, origin_zip, sum(package_weight)
FROM shipping
GROUP BY
    GROUPING SETS ((origin_state, destination_state)),
    GROUPING SETS ((origin_zip), ());


is logically equivalent to:
SELECT origin_state, destination_state, origin_zip, sum(package_weight)
FROM shipping
GROUP BY GROUPING SETS (
    (origin_state, destination_state, origin_zip),
    (origin_state, destination_state)
);


 origin_state | destination_state | origin_zip | _col3
--------------+-------------------+------------+-------
 New York     | New Jersey        |      10002 |     3
 California   | New Jersey        |      94131 |    55
 New Jersey   | Connecticut       |       7081 |   225
 California   | Connecticut       |      90210 |  1337
 California   | Colorado          |      94131 |     5
 New York     | New Jersey        | NULL       |     3
 New Jersey   | Connecticut       | NULL       |   225
 California   | Colorado          | NULL       |     5
 California   | Connecticut       | NULL       |  1337
 California   | New Jersey        | NULL       |    55
(10 rows)


The ALL and DISTINCT quantifiers determine whether duplicate grouping
sets each produce distinct output rows. This is particularly useful when
multiple complex grouping sets are combined in the same query. For example, the
following query:
SELECT origin_state, destination_state, origin_zip, sum(package_weight)
FROM shipping
GROUP BY ALL
    CUBE (origin_state, destination_state),
    ROLLUP (origin_state, origin_zip);


is equivalent to:
SELECT origin_state, destination_state, origin_zip, sum(package_weight)
FROM shipping
GROUP BY GROUPING SETS (
    (origin_state, destination_state, origin_zip),
    (origin_state, origin_zip),
    (origin_state, destination_state, origin_zip),
    (origin_state, origin_zip),
    (origin_state, destination_state),
    (origin_state),
    (origin_state, destination_state),
    (origin_state),
    (origin_state, destination_state),
    (origin_state),
    (destination_state),
    ()
);


However, if the query uses the DISTINCT quantifier for the GROUP BY:
SELECT origin_state, destination_state, origin_zip, sum(package_weight)
FROM shipping
GROUP BY DISTINCT
    CUBE (origin_state, destination_state),
    ROLLUP (origin_state, origin_zip);


only unique grouping sets are generated:
SELECT origin_state, destination_state, origin_zip, sum(package_weight)
FROM shipping
GROUP BY GROUPING SETS (
    (origin_state, destination_state, origin_zip),
    (origin_state, origin_zip),
    (origin_state, destination_state),
    (origin_state),
    (destination_state),
    ()
);


The default set quantifier is ALL.


GROUPING operation#
grouping(col1, ..., colN) -> bigint
The grouping operation returns a bit set converted to decimal, indicating which columns are present in a
grouping. It must be used in conjunction with GROUPING SETS, ROLLUP, CUBE  or GROUP BY
and its arguments must match exactly the columns referenced in the corresponding GROUPING SETS,
ROLLUP, CUBE or GROUP BY clause.
To compute the resulting bit set for a particular row, bits are assigned to the argument columns with
the rightmost column being the least significant bit. For a given grouping, a bit is set to 0 if the
corresponding column is included in the grouping and to 1 otherwise. For example, consider the query
below:
SELECT origin_state, origin_zip, destination_state, sum(package_weight),
       grouping(origin_state, origin_zip, destination_state)
FROM shipping
GROUP BY GROUPING SETS (
    (origin_state),
    (origin_state, origin_zip),
    (destination_state)
);


origin_state | origin_zip | destination_state | _col3 | _col4
--------------+------------+-------------------+-------+-------
California   | NULL       | NULL              |  1397 |     3
New Jersey   | NULL       | NULL              |   225 |     3
New York     | NULL       | NULL              |     3 |     3
California   |      94131 | NULL              |    60 |     1
New Jersey   |       7081 | NULL              |   225 |     1
California   |      90210 | NULL              |  1337 |     1
New York     |      10002 | NULL              |     3 |     1
NULL         | NULL       | New Jersey        |    58 |     6
NULL         | NULL       | Connecticut       |  1562 |     6
NULL         | NULL       | Colorado          |     5 |     6
(10 rows)


The first grouping in the above result only includes the origin_state column and excludes
the origin_zip and destination_state columns. The bit set constructed for that grouping
is 011 where the most significant bit represents origin_state.



HAVING clause#
The HAVING clause is used in conjunction with aggregate functions and
the GROUP BY clause to control which groups are selected. A HAVING
clause eliminates groups that do not satisfy the given conditions.
HAVING filters groups after groups and aggregates are computed.
The following example queries the customer table and selects groups
with an account balance greater than the specified value:
SELECT count(*), mktsegment, nationkey,
       CAST(sum(acctbal) AS bigint) AS totalbal
FROM customer
GROUP BY mktsegment, nationkey
HAVING sum(acctbal) > 5700000
ORDER BY totalbal DESC;


 _col0 | mktsegment | nationkey | totalbal
-------+------------+-----------+----------
  1272 | AUTOMOBILE |        19 |  5856939
  1253 | FURNITURE  |        14 |  5794887
  1248 | FURNITURE  |         9 |  5784628
  1243 | FURNITURE  |        12 |  5757371
  1231 | HOUSEHOLD  |         3 |  5753216
  1251 | MACHINERY  |         2 |  5719140
  1247 | FURNITURE  |         8 |  5701952
(7 rows)




WINDOW clause#
The WINDOW clause is used to define named window specifications. The defined named
window specifications can be referred to in the SELECT and ORDER BY clauses
of the enclosing query:
SELECT orderkey, clerk, totalprice,
      rank() OVER w AS rnk
FROM orders
WINDOW w AS (PARTITION BY clerk ORDER BY totalprice DESC)
ORDER BY count() OVER w, clerk, rnk


The window definition list of WINDOW clause can contain one or multiple named window
specifications of the form
window_name AS (window_specification)


A window specification has the following components:

The existing window name, which refers to a named window specification in the
WINDOW clause. The window specification associated with the referenced name
is the basis of the current specification.
The partition specification, which separates the input rows into different
partitions. This is analogous to how the GROUP BY clause separates rows
into different groups for aggregate functions.
The ordering specification, which determines the order in which input rows
will be processed by the window function.
The window frame, which specifies a sliding window of rows to be processed
by the function for a given row. If the frame is not specified, it defaults
to RANGE UNBOUNDED PRECEDING, which is the same as
RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW. This frame contains all
rows from the start of the partition up to the last peer of the current row.
In the absence of ORDER BY, all rows are considered peers, so RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW is equivalent to BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING. The window frame syntax
supports additional clauses for row pattern recognition. If the row pattern
recognition clauses are specified, the window frame for a particular row
consists of the rows matched by a pattern starting from that row.
Additionally, if the frame specifies row pattern measures, they can be
called over the window, similarly to window functions. For more details, see
Row pattern recognition in window structures .

Each window component is optional. If a window specification does not specify
window partitioning, ordering or frame, those components are obtained from
the window specification referenced by the existing window name, or from
another window specification in the reference chain. In case when there is no
existing window name specified, or none of the referenced window
specifications contains the component, the default value is used.


Set operations#
UNION INTERSECT and EXCEPT are all set operations.  These clauses are used
to combine the results of more than one select statement into a single result set:
query UNION [ALL | DISTINCT] query


query INTERSECT [ALL | DISTINCT] query


query EXCEPT [ALL | DISTINCT] query


The argument ALL or DISTINCT controls which rows are included in
the final result set. If the argument ALL is specified all rows are
included even if the rows are identical.  If the argument DISTINCT
is specified only unique rows are included in the combined result set.
If neither is specified, the behavior defaults to DISTINCT.
Multiple set operations are processed left to right, unless the order is explicitly
specified via parentheses. Additionally, INTERSECT binds more tightly
than EXCEPT and UNION. That means A UNION B INTERSECT C EXCEPT D
is the same as A UNION (B INTERSECT C) EXCEPT D.

UNION clause#
UNION combines all the rows that are in the result set from the
first query with those that are in the result set for the second query.
The following is an example of one of the simplest possible UNION clauses.
It selects the value 13 and combines this result set with a second query
that selects the value 42:
SELECT 13
UNION
SELECT 42;


 _col0
-------
    13
    42
(2 rows)


The following query demonstrates the difference between UNION and UNION ALL.
It selects the value 13 and combines this result set with a second query that
selects the values 42 and 13:
SELECT 13
UNION
SELECT * FROM (VALUES 42, 13);


 _col0
-------
    13
    42
(2 rows)


SELECT 13
UNION ALL
SELECT * FROM (VALUES 42, 13);


 _col0
-------
    13
    42
    13
(2 rows)




INTERSECT clause#
INTERSECT returns only the rows that are in the result sets of both the first and
the second queries. The following is an example of one of the simplest
possible INTERSECT clauses. It selects the values 13 and 42 and combines
this result set with a second query that selects the value 13.  Since 42
is only in the result set of the first query, it is not included in the final results.:
SELECT * FROM (VALUES 13, 42)
INTERSECT
SELECT 13;


 _col0
-------
    13
(2 rows)




EXCEPT clause#
EXCEPT returns the rows that are in the result set of the first query,
but not the second. The following is an example of one of the simplest
possible EXCEPT clauses. It selects the values 13 and 42 and combines
this result set with a second query that selects the value 13.  Since 13
is also in the result set of the second query, it is not included in the final result.:
SELECT * FROM (VALUES 13, 42)
EXCEPT
SELECT 13;


 _col0
-------
   42
(2 rows)





ORDER BY clause#
The ORDER BY clause is used to sort a result set by one or more
output expressions:
ORDER BY expression [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, ...]


Each expression may be composed of output columns, or it may be an ordinal
number selecting an output column by position, starting at one. The
ORDER BY clause is evaluated after any GROUP BY or HAVING clause,
and before any OFFSET, LIMIT or FETCH FIRST clause.
The default null ordering is NULLS LAST, regardless of the ordering direction.
Note that, following the SQL specification, an ORDER BY clause only
affects the order of rows for queries that immediately contain the clause.
Trino follows that specification, and drops redundant usage of the clause to
avoid negative performance impacts.
In the following example, the clause only applies to the select statement.
INSERT INTO some_table
SELECT * FROM another_table
ORDER BY field;


Since tables in SQL are inherently unordered, and the ORDER BY clause in
this case does not result in any difference, but negatively impacts performance
of running the overall insert statement, Trino skips the sort operation.
Another example where the ORDER BY clause is redundant, and does not affect
the outcome of the overall statement, is a nested query:
SELECT *
FROM some_table
    JOIN (SELECT * FROM another_table ORDER BY field) u
    ON some_table.key = u.key;


More background information and details can be found in
a blog post about this optimization.


OFFSET clause#
The OFFSET clause is used to discard a number of leading rows
from the result set:
OFFSET count [ ROW | ROWS ]


If the ORDER BY clause is present, the OFFSET clause is evaluated
over a sorted result set, and the set remains sorted after the
leading rows are discarded:
SELECT name FROM nation ORDER BY name OFFSET 22;


      name
----------------
 UNITED KINGDOM
 UNITED STATES
 VIETNAM
(3 rows)


Otherwise, it is arbitrary which rows are discarded.
If the count specified in the OFFSET clause equals or exceeds the size
of the result set, the final result is empty.


LIMIT or FETCH FIRST clause#
The LIMIT or FETCH FIRST clause restricts the number of rows
in the result set.
LIMIT { count | ALL }


FETCH { FIRST | NEXT } [ count ] { ROW | ROWS } { ONLY | WITH TIES }


The following example queries a large table, but the LIMIT clause
restricts the output to only have five rows (because the query lacks an ORDER BY,
exactly which rows are returned is arbitrary):
SELECT orderdate FROM orders LIMIT 5;


 orderdate
------------
 1994-07-25
 1993-11-12
 1992-10-06
 1994-01-04
 1997-12-28
(5 rows)


LIMIT ALL is the same as omitting the LIMIT clause.
The FETCH FIRST clause supports either the FIRST or NEXT keywords
and the ROW or ROWS keywords. These keywords are equivalent and
the choice of keyword has no effect on query execution.
If the count is not specified in the FETCH FIRST clause, it defaults to 1:
SELECT orderdate FROM orders FETCH FIRST ROW ONLY;


 orderdate
------------
 1994-02-12
(1 row)


If the OFFSET clause is present, the LIMIT or FETCH FIRST clause
is evaluated after the OFFSET clause:
SELECT * FROM (VALUES 5, 2, 4, 1, 3) t(x) ORDER BY x OFFSET 2 LIMIT 2;


 x
---
 3
 4
(2 rows)


For the FETCH FIRST clause, the argument ONLY or WITH TIES
controls which rows are included in the result set.
If the argument ONLY is specified, the result set is limited to the exact
number of leading rows determined by the count.
If the argument WITH TIES is specified, it is required that the ORDER BY
clause be present. The result set consists of the same set of leading rows
and all of the rows in the same peer group as the last of them (‘ties’)
as established by the ordering in the ORDER BY clause. The result set is sorted:
SELECT name, regionkey
FROM nation
ORDER BY regionkey FETCH FIRST ROW WITH TIES;


    name    | regionkey
------------+-----------
 ETHIOPIA   |         0
 MOROCCO    |         0
 KENYA      |         0
 ALGERIA    |         0
 MOZAMBIQUE |         0
(5 rows)




TABLESAMPLE#
There are multiple sample methods:

BERNOULLIEach row is selected to be in the table sample with a probability of
the sample percentage. When a table is sampled using the Bernoulli
method, all physical blocks of the table are scanned and certain
rows are skipped (based on a comparison between the sample percentage
and a random value calculated at runtime).
The probability of a row being included in the result is independent
from any other row. This does not reduce the time required to read
the sampled table from disk. It may have an impact on the total
query time if the sampled output is processed further.

SYSTEMThis sampling method divides the table into logical segments of data
and samples the table at this granularity. This sampling method either
selects all the rows from a particular segment of data or skips it
(based on a comparison between the sample percentage and a random
value calculated at runtime).
The rows selected in a system sampling will be dependent on which
connector is used. For example, when used with Hive, it is dependent
on how the data is laid out on HDFS. This method does not guarantee
independent sampling probabilities.



Note
Neither of the two methods allow deterministic bounds on the number of rows returned.

Examples:
SELECT *
FROM users TABLESAMPLE BERNOULLI (50);

SELECT *
FROM users TABLESAMPLE SYSTEM (75);


Using sampling with joins:
SELECT o.*, i.*
FROM orders o TABLESAMPLE SYSTEM (10)
JOIN lineitem i TABLESAMPLE BERNOULLI (40)
  ON o.orderkey = i.orderkey;




UNNEST#
UNNEST can be used to expand an ARRAY or MAP into a relation.
Arrays are expanded into a single column:
SELECT * FROM UNNEST(ARRAY[1,2]) AS t(number);


 number
--------
      1
      2
(2 rows)


Maps are expanded into two columns (key, value):
SELECT * FROM UNNEST(
        map_from_entries(
            ARRAY[
                ('SQL',1974),
                ('Java', 1995)
            ]
        )
) AS t(language, first_appeared_year);


 language | first_appeared_year
----------+---------------------
 SQL      |                1974
 Java     |                1995
(2 rows)


UNNEST can be used in combination with an ARRAY of ROW structures for expanding each
field of the ROW into a corresponding column:
SELECT *
FROM UNNEST(
        ARRAY[
            ROW('Java',  1995),
            ROW('SQL' , 1974)],
        ARRAY[
            ROW(false),
            ROW(true)]
) as t(language,first_appeared_year,declarative);


 language | first_appeared_year | declarative
----------+---------------------+-------------
 Java     |                1995 | false
 SQL      |                1974 | true
(2 rows)


UNNEST can optionally have a WITH ORDINALITY clause, in which case an additional ordinality column
is added to the end:
SELECT a, b, rownumber
FROM UNNEST (
    ARRAY[2, 5],
    ARRAY[7, 8, 9]
     ) WITH ORDINALITY AS t(a, b, rownumber);


  a   | b | rownumber
------+---+-----------
    2 | 7 |         1
    5 | 8 |         2
 NULL | 9 |         3
(3 rows)


UNNEST returns zero entries when the array/map is empty:
SELECT * FROM UNNEST (ARRAY[]) AS t(value);


 value
-------
(0 rows)


UNNEST returns zero entries when the array/map is null:
SELECT * FROM UNNEST (CAST(null AS ARRAY(integer))) AS t(number);


 number
--------
(0 rows)


UNNEST is normally used with a JOIN, and can reference columns
from relations on the left side of the join:
SELECT student, score
FROM (
   VALUES
      ('John', ARRAY[7, 10, 9]),
      ('Mary', ARRAY[4, 8, 9])
) AS tests (student, scores)
CROSS JOIN UNNEST(scores) AS t(score);


 student | score
---------+-------
 John    |     7
 John    |    10
 John    |     9
 Mary    |     4
 Mary    |     8
 Mary    |     9
(6 rows)


UNNEST can also be used with multiple arguments, in which case they are expanded into multiple columns,
with as many rows as the highest cardinality argument (the other columns are padded with nulls):
SELECT numbers, animals, n, a
FROM (
  VALUES
    (ARRAY[2, 5], ARRAY['dog', 'cat', 'bird']),
    (ARRAY[7, 8, 9], ARRAY['cow', 'pig'])
) AS x (numbers, animals)
CROSS JOIN UNNEST(numbers, animals) AS t (n, a);


  numbers  |     animals      |  n   |  a
-----------+------------------+------+------
 [2, 5]    | [dog, cat, bird] |    2 | dog
 [2, 5]    | [dog, cat, bird] |    5 | cat
 [2, 5]    | [dog, cat, bird] | NULL | bird
 [7, 8, 9] | [cow, pig]       |    7 | cow
 [7, 8, 9] | [cow, pig]       |    8 | pig
 [7, 8, 9] | [cow, pig]       |    9 | NULL
(6 rows)


LEFT JOIN is preferable in order to avoid losing the row containing the array/map field in question
when referenced columns from relations on the left side of the join can be empty or have NULL values:
SELECT runner, checkpoint
FROM (
   VALUES
      ('Joe', ARRAY[10, 20, 30, 42]),
      ('Roger', ARRAY[10]),
      ('Dave', ARRAY[]),
      ('Levi', NULL)
) AS marathon (runner, checkpoints)
LEFT JOIN UNNEST(checkpoints) AS t(checkpoint) ON TRUE;


 runner | checkpoint
--------+------------
 Joe    |         10
 Joe    |         20
 Joe    |         30
 Joe    |         42
 Roger  |         10
 Dave   |       NULL
 Levi   |       NULL
(7 rows)


Note that in case of using LEFT JOIN the only condition supported by the current implementation is ON TRUE.


JSON_TABLE#
JSON_TABLE transforms JSON data into a relational table format. Like UNNEST
and LATERAL, use JSON_TABLE in the FROM clause of a SELECT statement.
For more information, see JSON_TABLE.


Joins#
Joins allow you to combine data from multiple relations.

CROSS JOIN#
A cross join returns the Cartesian product (all combinations) of two
relations. Cross joins can either be specified using the explit
CROSS JOIN syntax or by specifying multiple relations in the
FROM clause.
Both of the following queries are equivalent:
SELECT *
FROM nation
CROSS JOIN region;

SELECT *
FROM nation, region;


The nation table contains 25 rows and the region table contains 5 rows,
so a cross join between the two tables produces 125 rows:
SELECT n.name AS nation, r.name AS region
FROM nation AS n
CROSS JOIN region AS r
ORDER BY 1, 2;


     nation     |   region
----------------+-------------
 ALGERIA        | AFRICA
 ALGERIA        | AMERICA
 ALGERIA        | ASIA
 ALGERIA        | EUROPE
 ALGERIA        | MIDDLE EAST
 ARGENTINA      | AFRICA
 ARGENTINA      | AMERICA
...
(125 rows)




LATERAL#
Subqueries appearing in the FROM clause can be preceded by the keyword LATERAL.
This allows them to reference columns provided by preceding FROM items.
A LATERAL join can appear at the top level in the FROM list, or anywhere
within a parenthesized join tree. In the latter case, it can also refer to any items
that are on the left-hand side of a JOIN for which it is on the right-hand side.
When a FROM item contains LATERAL cross-references, evaluation proceeds as follows:
for each row of the FROM item providing the cross-referenced columns,
the LATERAL item is evaluated using that row set’s values of the columns.
The resulting rows are joined as usual with the rows they were computed from.
This is repeated for set of rows from the column source tables.
LATERAL is primarily useful when the cross-referenced column is necessary for
computing the rows to be joined:
SELECT name, x, y
FROM nation
CROSS JOIN LATERAL (SELECT name || ' :-' AS x)
CROSS JOIN LATERAL (SELECT x || ')' AS y);




Qualifying column names#
When two relations in a join have columns with the same name, the column
references must be qualified using the relation alias (if the relation
has an alias), or with the relation name:
SELECT nation.name, region.name
FROM nation
CROSS JOIN region;

SELECT n.name, r.name
FROM nation AS n
CROSS JOIN region AS r;

SELECT n.name, r.name
FROM nation n
CROSS JOIN region r;


The following query will fail with the error Column 'name' is ambiguous:
SELECT name
FROM nation
CROSS JOIN region;





Subqueries#
A subquery is an expression which is composed of a query. The subquery
is correlated when it refers to columns outside of the subquery.
Logically, the subquery will be evaluated for each row in the surrounding
query. The referenced columns will thus be constant during any single
evaluation of the subquery.

Note
Support for correlated subqueries is limited. Not every standard form is supported.


EXISTS#
The EXISTS predicate determines if a subquery returns any rows:
SELECT name
FROM nation
WHERE EXISTS (
     SELECT *
     FROM region
     WHERE region.regionkey = nation.regionkey
);




IN#
The IN predicate determines if any values produced by the subquery
are equal to the provided expression. The result of IN follows the
standard rules for nulls. The subquery must produce exactly one column:
SELECT name
FROM nation
WHERE regionkey IN (
     SELECT regionkey
     FROM region
     WHERE name = 'AMERICA' OR name = 'AFRICA'
);




Scalar subquery#
A scalar subquery is a non-correlated subquery that returns zero or
one row. It is an error for the subquery to produce more than one
row. The returned value is NULL if the subquery produces no rows:
SELECT name
FROM nation
WHERE regionkey = (SELECT max(regionkey) FROM region);



Note
Currently only single column can be returned from the scalar subquery.


















 Previous  ROLLBACK 



  Next  SET PATH 











































SET PATH — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SET PATH 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT



 SET PATH 
SET PATH

Contents

Synopsis

Description

Examples

See also





SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









SET PATH#

Synopsis#
SET PATH path-element[, ...]




Description#
Define a collection of paths to functions or table functions in specific
catalogs and schemas for the current session.
Each path-element uses a period-separated syntax to specify the catalog name and
schema location <catalog>.<schema> of the function, or only the schema
location <schema> in the current catalog. The current catalog is set with
USE, or as part of a client tool connection. Catalog and schema must
exist.


Examples#
The following example sets a path to access functions in the system schema
of the example catalog:
SET PATH example.system;


The catalog uses the PostgreSQL connector, and you can therefore use the
query table function directly, without the
full catalog and schema qualifiers:
SELECT
  *
FROM
  TABLE(
    query(
      query => 'SELECT
        *
      FROM
        tpch.nation'
    )
  );




See also#

USE
SQL environment properties

















 Previous  SELECT 



  Next  SET ROLE 











































SET ROLE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SET ROLE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH



 SET ROLE 
SET ROLE

Contents

Synopsis

Description

Limitations

See also





SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Limitations

See also









SET ROLE#

Synopsis#
SET ROLE ( role | ALL | NONE )
[ IN catalog ]




Description#
SET ROLE sets the enabled role for the current session.
SET ROLE role enables a single specified role for the current session.
For the SET ROLE role statement to succeed, the user executing it should
have a grant for the given role.
SET ROLE ALL enables all roles that the current user has been granted for the
current session.
SET ROLE NONE disables all the roles granted to the current user for the
current session.
The optional IN catalog clause sets the role in a catalog as opposed
to a system role.


Limitations#
Some connectors do not support role management.
See connector documentation for more details.


See also#
CREATE ROLE, DROP ROLE, GRANT role, REVOKE role
















 Previous  SET PATH 



  Next  SET SESSION 











































SET SESSION — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SET SESSION 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE



 SET SESSION 
SET SESSION

Contents

Synopsis

Description

Session properties

Examples

See also





SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Session properties

Examples

See also









SET SESSION#

Synopsis#
SET SESSION name = expression
SET SESSION catalog.name = expression




Description#
Set a session property value or a catalog session property.


Session properties#
A session property is a configuration property that
can be temporarily modified by a user for the duration of the current
connection session to the Trino cluster. Many configuration properties have a
corresponding session property that accepts the same values as the config
property.
There are two types of session properties:

System session properties apply to the whole cluster. Most session
properties are system session properties unless specified otherwise.
Catalog session properties are connector-defined session properties that
can be set on a per-catalog basis. These properties must be set separately for
each catalog by including the catalog name as a prefix, such as
catalogname.property_name.

Session properties are tied to the current session, so a user can have multiple
connections to a cluster that each have different values for the same session
properties. Once a session ends, either by disconnecting or creating a new
session, any changes made to session properties during the previous session are
lost.


Examples#
The following example sets a system session property change maximum query run time:
SET SESSION query_max_run_time = '10m';


The following example sets the incremental_refresh_enabled catalog session
property for a catalog using the Iceberg connector named example:
SET SESSION example.incremental_refresh_enabled=false;


The related catalog configuration property iceberg.incremental-refresh-enabled
defaults to true, and the session property allows you to override this setting
in for specific catalog and the current session. The
example.incremental_refresh_enabled catalog session property does not apply to
any other catalog, even if another catalog also uses the Iceberg connector.


See also#
RESET SESSION, SHOW SESSION
















 Previous  SET ROLE 



  Next  SET SESSION AUTHORIZATION 











































SET SESSION AUTHORIZATION — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SET SESSION AUTHORIZATION 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION



 SET SESSION AUTHORIZATION 
SET SESSION AUTHORIZATION

Contents

Synopsis

Description

Examples

See also





SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









SET SESSION AUTHORIZATION#

Synopsis#
SET SESSION AUTHORIZATION username




Description#
Changes the current user of the session. For the SET SESSION AUTHORIZATION username statement to succeed, the original user (that the client connected
with) must be able to impersonate the specified user. User impersonation can be
enabled in the system access control.


Examples#
In the following example, the original user when the connection to Trino is made
is Kevin. The following sets the session authorization user to John:
SET SESSION AUTHORIZATION 'John';


Queries will now execute as John instead of Kevin.
All supported syntax to change the session authorization users are shown below.
Changing the session authorization with single quotes:
SET SESSION AUTHORIZATION 'John';


Changing the session authorization with double quotes:
SET SESSION AUTHORIZATION "John";


Changing the session authorization without quotes:
SET SESSION AUTHORIZATION John;




See also#
RESET SESSION AUTHORIZATION
















 Previous  SET SESSION 



  Next  SET TIME ZONE 











































SET TIME ZONE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SET TIME ZONE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION



 SET TIME ZONE 
SET TIME ZONE

Contents

Synopsis

Description

Examples

Limitations

See also





SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations

See also









SET TIME ZONE#

Synopsis#
SET TIME ZONE LOCAL
SET TIME ZONE expression




Description#
Sets the default time zone for the current session.
If the LOCAL option is specified, the time zone for the current session
is set to the initial time zone of the session.
If the expression option is specified:

if the type of the expression is a string, the time zone for the current
session is set to the corresponding region-based time zone ID or the
corresponding zone offset.
if the type of the expression is an interval, the time zone for the
current session is set to the corresponding zone offset relative to UTC.
It must be in the range of [-14,14] hours.



Examples#
Use the default time zone for the current session:
SET TIME ZONE LOCAL;


Use a zone offset for specifying the time zone:
SET TIME ZONE '-08:00';


Use an interval literal for specifying the time zone:
SET TIME ZONE INTERVAL '10' HOUR;
SET TIME ZONE INTERVAL -'08:00' HOUR TO MINUTE;


Use a region-based time zone identifier for specifying the time zone:
SET TIME ZONE 'America/Los_Angeles';


The time zone identifier to be used can be passed as the output of a
function call:
SET TIME ZONE concat_ws('/', 'America', 'Los_Angeles');




Limitations#
Setting the default time zone for the session has no effect if
the sql.forced-session-time-zone configuration property is already set.


See also#

current_timezone()

















 Previous  SET SESSION AUTHORIZATION 



  Next  SHOW CATALOGS 











































SHOW CATALOGS — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW CATALOGS 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE



 SHOW CATALOGS 
SHOW CATALOGS

Contents

Synopsis

Description





SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description









SHOW CATALOGS#

Synopsis#
SHOW CATALOGS [ LIKE pattern ]




Description#
List the available catalogs.
Specify a pattern in the optional LIKE clause to
filter the results to the desired subset. For example, the following query
allows you to find catalogs that begin with t:
SHOW CATALOGS LIKE 't%'


















 Previous  SET TIME ZONE 



  Next  SHOW COLUMNS 











































SHOW COLUMNS — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW COLUMNS 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS



 SHOW COLUMNS 
SHOW COLUMNS

Contents

Synopsis

Description





SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description









SHOW COLUMNS#

Synopsis#
SHOW COLUMNS FROM table [ LIKE pattern ]




Description#
List the columns in a table along with their data type and other attributes:
SHOW COLUMNS FROM nation;


  Column   |     Type     | Extra | Comment
-----------+--------------+-------+---------
 nationkey | bigint       |       |
 name      | varchar(25)  |       |
 regionkey | bigint       |       |
 comment   | varchar(152) |       |


Specify a pattern in the optional LIKE clause to
filter the results to the desired subset. For example, the following query
allows you to find columns ending in key:
SHOW COLUMNS FROM nation LIKE '%key';


  Column   |     Type     | Extra | Comment
-----------+--------------+-------+---------
 nationkey | bigint       |       |
 regionkey | bigint       |       |


















 Previous  SHOW CATALOGS 



  Next  SHOW CREATE FUNCTION 











































SHOW CREATE FUNCTION — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW CREATE FUNCTION 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS



 SHOW CREATE FUNCTION 
SHOW CREATE FUNCTION

Contents

Synopsis

Description

Examples

See also





SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









SHOW CREATE FUNCTION#

Synopsis#
SHOW CREATE FUNCTION function_name




Description#
Show the SQL statement that creates the specified function.


Examples#
Show the SQL that can be run to create the meaning_of_life function:
SHOW CREATE FUNCTION example.default.meaning_of_life;




See also#

CREATE FUNCTION
DROP FUNCTION
SHOW FUNCTIONS
User-defined functions
SQL environment properties

















 Previous  SHOW COLUMNS 



  Next  SHOW CREATE MATERIALIZED VIEW 











































SHOW CREATE MATERIALIZED VIEW — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW CREATE MATERIALIZED VIEW 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION



 SHOW CREATE MATERIALIZED VIEW 
SHOW CREATE MATERIALIZED VIEW

Contents

Synopsis

Description

See also





SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

See also









SHOW CREATE MATERIALIZED VIEW#

Synopsis#
SHOW CREATE MATERIALIZED VIEW view_name




Description#
Show the SQL statement that creates the specified materialized view
view_name.


See also#

CREATE MATERIALIZED VIEW
DROP MATERIALIZED VIEW
REFRESH MATERIALIZED VIEW

















 Previous  SHOW CREATE FUNCTION 



  Next  SHOW CREATE SCHEMA 











































SHOW CREATE SCHEMA — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW CREATE SCHEMA 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW



 SHOW CREATE SCHEMA 
SHOW CREATE SCHEMA

Contents

Synopsis

Description

See also





SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

See also









SHOW CREATE SCHEMA#

Synopsis#
SHOW CREATE SCHEMA schema_name




Description#
Show the SQL statement that creates the specified schema.


See also#
CREATE SCHEMA
















 Previous  SHOW CREATE MATERIALIZED VIEW 



  Next  SHOW CREATE TABLE 











































SHOW CREATE TABLE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW CREATE TABLE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA



 SHOW CREATE TABLE 
SHOW CREATE TABLE

Contents

Synopsis

Description

Examples

See also





SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









SHOW CREATE TABLE#

Synopsis#
SHOW CREATE TABLE table_name




Description#
Show the SQL statement that creates the specified table.


Examples#
Show the SQL that can be run to create the orders table:
SHOW CREATE TABLE sf1.orders;


              Create Table
-----------------------------------------
 CREATE TABLE tpch.sf1.orders (
    orderkey bigint,
    orderstatus varchar,
    totalprice double,
    orderdate varchar
 )
 WITH (
    format = 'ORC',
    partitioned_by = ARRAY['orderdate']
 )
(1 row)




See also#
CREATE TABLE
















 Previous  SHOW CREATE SCHEMA 



  Next  SHOW CREATE VIEW 











































SHOW CREATE VIEW — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW CREATE VIEW 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE



 SHOW CREATE VIEW 
SHOW CREATE VIEW

Contents

Synopsis

Description

See also





SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

See also









SHOW CREATE VIEW#

Synopsis#
SHOW CREATE VIEW view_name




Description#
Show the SQL statement that creates the specified view.


See also#
CREATE VIEW
















 Previous  SHOW CREATE TABLE 



  Next  SHOW FUNCTIONS 











































SHOW FUNCTIONS — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW FUNCTIONS 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW



 SHOW FUNCTIONS 
SHOW FUNCTIONS

Contents

Synopsis

Description

Examples

See also





SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









SHOW FUNCTIONS#

Synopsis#
SHOW FUNCTIONS [ FROM schema ] [ LIKE pattern ]




Description#
List functions in schema or all functions in the current session path. This
can include built-in functions, functions from a custom
plugin, and User-defined functions.
For each function returned, the following information is displayed:

Function name
Return type
Argument types
Function type
Deterministic
Description

Use the optional FROM keyword to only list functions in a specific catalog and
schema. The location in schema must be specified as
cataglog_name.schema_name.
Specify a pattern in the optional LIKE clause to
filter the results to the desired subset.


Examples#
List all UDFs and plugin functions in the default schema of the example
catalog:
SHOW FUNCTIONS FROM example.default;


List all functions with a name beginning with array:
SHOW FUNCTIONS LIKE 'array%';


List all functions with a name beginning with cf:
SHOW FUNCTIONS LIKE 'cf%';


Example output:
     Function      | Return Type | Argument Types | Function Type | Deterministic |               Description
 ------------------+-------------+----------------+---------------+---------------+-----------------------------------------
 cf_getgroups      | varchar     |                | scalar        | true          | Returns the current session's groups
 cf_getprincipal   | varchar     |                | scalar        | true          | Returns the current session's principal
 cf_getuser        | varchar     |                | scalar        | true          | Returns the current session's user




See also#

Functions and operators
User-defined functions
Functions
CREATE FUNCTION
DROP FUNCTION
SHOW CREATE FUNCTION

















 Previous  SHOW CREATE VIEW 



  Next  SHOW GRANTS 











































SHOW GRANTS — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW GRANTS 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS



 SHOW GRANTS 
SHOW GRANTS

Contents

Synopsis

Description

Examples

Limitations

See also





SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations

See also









SHOW GRANTS#

Synopsis#
SHOW GRANTS [ ON [ TABLE ] table_name ]




Description#
List the grants for the current user on the specified table in the current catalog.
If no table name is specified, the command lists the grants for the current user on all the tables in all schemas of the current catalog.
The command requires the current catalog to be set.

Note
Ensure that authentication has been enabled before running any of the authorization commands.



Examples#
List the grants for the current user on table orders:
SHOW GRANTS ON TABLE orders;


List the grants for the current user on all the tables in all schemas of the current catalog:
SHOW GRANTS;




Limitations#
Some connectors have no support for SHOW GRANTS.
See connector documentation for more details.


See also#
GRANT privilege, REVOKE privilege
















 Previous  SHOW FUNCTIONS 



  Next  SHOW ROLE GRANTS 











































SHOW ROLE GRANTS — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW ROLE GRANTS 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS



 SHOW ROLE GRANTS 
SHOW ROLE GRANTS

Contents

Synopsis

Description





SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description









SHOW ROLE GRANTS#

Synopsis#
SHOW ROLE GRANTS [ FROM catalog ]




Description#
List non-recursively the system roles or roles in catalog that have been granted to the session user.
















 Previous  SHOW GRANTS 



  Next  SHOW ROLES 











































SHOW ROLES — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW ROLES 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS



 SHOW ROLES 
SHOW ROLES

Contents

Synopsis

Description





SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description









SHOW ROLES#

Synopsis#
SHOW [CURRENT] ROLES [ FROM catalog ]




Description#
SHOW ROLES lists all the system roles or all the roles in catalog.
SHOW CURRENT ROLES lists the enabled system roles or roles in catalog.
















 Previous  SHOW ROLE GRANTS 



  Next  SHOW SCHEMAS 











































SHOW SCHEMAS — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW SCHEMAS 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES



 SHOW SCHEMAS 
SHOW SCHEMAS

Contents

Synopsis

Description





SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description









SHOW SCHEMAS#

Synopsis#
SHOW SCHEMAS [ FROM catalog ] [ LIKE pattern ]




Description#
List the schemas in catalog or in the current catalog.
Specify a pattern in the optional LIKE clause to
filter the results to the desired subset. For example, the following query
allows you to find schemas that have 3 as the third character:
SHOW SCHEMAS FROM tpch LIKE '__3%'


















 Previous  SHOW ROLES 



  Next  SHOW SESSION 











































SHOW SESSION — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW SESSION 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS



 SHOW SESSION 
SHOW SESSION

Contents

Synopsis

Description

See also





SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

See also









SHOW SESSION#

Synopsis#
SHOW SESSION [ LIKE pattern ]




Description#
List the current session properties.
Specify a pattern in the optional LIKE clause to
filter the results to the desired subset. For example, the following query
allows you to find session properties that begin with query:
SHOW SESSION LIKE 'query%'




See also#
RESET SESSION, SET SESSION
















 Previous  SHOW SCHEMAS 



  Next  SHOW STATS 











































SHOW STATS — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW STATS 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION



 SHOW STATS 
SHOW STATS

Contents

Synopsis

Description





SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description









SHOW STATS#

Synopsis#
SHOW STATS FOR table
SHOW STATS FOR ( query )




Description#
Returns approximated statistics for the named table or for the results of a
query. Returns NULL for any statistics that are not populated or
unavailable on the data source.
Statistics are returned as a row for each column, plus a summary row for
the table (identifiable by a NULL value for column_name). The following
table lists the returned columns and what statistics they represent. Any
additional statistics collected on the data source, other than those listed
here, are not included.

Statistics#






Column
Description
Notes



column_name
The name of the column
NULL in the table summary row

data_size
The total size in bytes of all of the values in the column
NULL in the table summary row. Available for columns of
string data types with variable widths.

distinct_values_count
The estimated number of distinct values in the column
NULL in the table summary row

nulls_fractions
The portion of the values in the column that are NULL
NULL in the table summary row.

row_count
The estimated number of rows in the table
NULL in column statistic rows

low_value
The lowest value found in this column
NULL in the table summary row. Available for columns of
DATE, integer,
floating-point, and
exact numeric data types.

high_value
The highest value found in this column
NULL in the table summary row. Available for columns of
DATE, integer,
floating-point, and
exact numeric data types.



















 Previous  SHOW SESSION 



  Next  SHOW TABLES 











































SHOW TABLES — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 SHOW TABLES 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS



 SHOW TABLES 
SHOW TABLES

Contents

Synopsis

Description

Examples

See also





START TRANSACTION


TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









SHOW TABLES#

Synopsis#
SHOW TABLES [ FROM schema ] [ LIKE pattern ]




Description#
List the tables and views in the current schema, for example set with
USE or by a client connection.
Use a fully qualified path to a schema in the form of catalog_name.schema_name
to specify any schema in any catalog in the FROM clause.
Specify a pattern in the optional LIKE clause to filter
the results to the desired subset.


Examples#
The following query lists tables and views that begin with p in
the tiny schema of the tpch catalog:
SHOW TABLES FROM tpch.tiny LIKE 'p%';




See also#

Schema and table management
View management

















 Previous  SHOW STATS 



  Next  START TRANSACTION 











































START TRANSACTION — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 START TRANSACTION 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES



 START TRANSACTION 
START TRANSACTION

Contents

Synopsis

Description

Examples

See also





TRUNCATE


UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









START TRANSACTION#

Synopsis#
START TRANSACTION [ mode [, ...] ]


where mode is one of
ISOLATION LEVEL { READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE }
READ { ONLY | WRITE }




Description#
Start a new transaction for the current session.


Examples#
START TRANSACTION;
START TRANSACTION ISOLATION LEVEL REPEATABLE READ;
START TRANSACTION READ WRITE;
START TRANSACTION ISOLATION LEVEL READ COMMITTED, READ ONLY;
START TRANSACTION READ WRITE, ISOLATION LEVEL SERIALIZABLE;




See also#
COMMIT, ROLLBACK
















 Previous  SHOW TABLES 



  Next  TRUNCATE 











































TRUNCATE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 TRUNCATE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION



 TRUNCATE 
TRUNCATE

Contents

Synopsis

Description

Examples





UPDATE


USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples









TRUNCATE#

Synopsis#
TRUNCATE TABLE table_name




Description#
Delete all rows from a table.


Examples#
Truncate the table orders:
TRUNCATE TABLE orders;


















 Previous  START TRANSACTION 



  Next  UPDATE 











































UPDATE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 UPDATE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE



 UPDATE 
UPDATE

Contents

Synopsis

Description

Examples

Limitations





USE


VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

Limitations









UPDATE#

Synopsis#
UPDATE table_name SET [ ( column = expression [, ... ] ) ] [ WHERE condition ]




Description#
Update selected columns values in existing rows in a table.
The columns named in the column = expression assignments will be updated
for all rows that match the WHERE condition.  The values of all column update
expressions for a matching row are evaluated before any column value is changed.
When the type of the expression and the type of the column differ, the usual implicit
CASTs, such as widening numeric fields, are applied to the UPDATE expression values.


Examples#
Update the status of all purchases that haven’t been assigned a ship date:
UPDATE
  purchases
SET
  status = 'OVERDUE'
WHERE
  ship_date IS NULL;


Update the account manager and account assign date for all customers:
UPDATE
  customers
SET
  account_manager = 'John Henry',
  assign_date = now();


Update the manager to be the name of the employee who matches the manager ID:
UPDATE
  new_hires
SET
  manager = (
    SELECT
      e.name
    FROM
      employees e
    WHERE
      e.employee_id = new_hires.manager_id
  );




Limitations#
Some connectors have limited or no support for UPDATE.
See connector documentation for more details.
















 Previous  TRUNCATE 



  Next  USE 











































USE — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 USE 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE



 USE 
USE

Contents

Synopsis

Description

Examples





VALUES


Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples









USE#

Synopsis#
USE catalog.schema
USE schema




Description#
Update the session to use the specified catalog and schema. If a
catalog is not specified, the schema is resolved relative to the
current catalog.


Examples#
USE hive.finance;
USE information_schema;


















 Previous  UPDATE 



  Next  VALUES 











































VALUES — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 VALUES 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


ALTER MATERIALIZED VIEW


ALTER SCHEMA


ALTER TABLE


ALTER VIEW


ANALYZE


CALL


COMMENT


COMMIT


CREATE CATALOG


CREATE FUNCTION


CREATE MATERIALIZED VIEW


CREATE ROLE


CREATE SCHEMA


CREATE TABLE


CREATE TABLE AS


CREATE VIEW


DEALLOCATE PREPARE


DELETE


DENY


DESCRIBE


DESCRIBE INPUT


DESCRIBE OUTPUT


DROP CATALOG


DROP FUNCTION


DROP MATERIALIZED VIEW


DROP ROLE


DROP SCHEMA


DROP TABLE


DROP VIEW


EXECUTE


EXECUTE IMMEDIATE


EXPLAIN


EXPLAIN ANALYZE


GRANT privilege


GRANT role


INSERT


MATCH_RECOGNIZE


MERGE


PREPARE


REFRESH MATERIALIZED VIEW


RESET SESSION


RESET SESSION AUTHORIZATION


REVOKE privilege


REVOKE role


ROLLBACK


SELECT


SET PATH


SET ROLE


SET SESSION


SET SESSION AUTHORIZATION


SET TIME ZONE


SHOW CATALOGS


SHOW COLUMNS


SHOW CREATE FUNCTION


SHOW CREATE MATERIALIZED VIEW


SHOW CREATE SCHEMA


SHOW CREATE TABLE


SHOW CREATE VIEW


SHOW FUNCTIONS


SHOW GRANTS


SHOW ROLE GRANTS


SHOW ROLES


SHOW SCHEMAS


SHOW SESSION


SHOW STATS


SHOW TABLES


START TRANSACTION


TRUNCATE


UPDATE


USE



 VALUES 
VALUES

Contents

Synopsis

Description

Examples

See also





Row pattern recognition in window structures



Developer guide


Glossary


Appendix


Release notes










Contents

Synopsis

Description

Examples

See also









VALUES#

Synopsis#
VALUES row [, ...]


where row is a single expression or
( column_expression [, ...] )




Description#
Defines a literal inline table.
VALUES can be used anywhere a query can be used (e.g., the FROM clause
of a SELECT, an INSERT, or even at the top level). VALUES creates
an anonymous table without column names, but the table and columns can be named
using an AS clause with column aliases.


Examples#
Return a table with one column and three rows:
VALUES 1, 2, 3


Return a table with two columns and three rows:
VALUES
    (1, 'a'),
    (2, 'b'),
    (3, 'c')


Return table with column id and name:
SELECT * FROM (
    VALUES
        (1, 'a'),
        (2, 'b'),
        (3, 'c')
) AS t (id, name)


Create a new table with column id and name:
CREATE TABLE example AS
SELECT * FROM (
    VALUES
        (1, 'a'),
        (2, 'b'),
        (3, 'c')
) AS t (id, name)




See also#
INSERT, SELECT
















 Previous  USE 



  Next  Row pattern recognition in window structures 











































Table statistics — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Table statistics 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer



 Table statistics 
Table statistics

Contents

Available statistics





Cost in EXPLAIN


Cost-based optimizations


Pushdown


Adaptive plan optimizations



Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Available statistics









Table statistics#
Trino supports statistics based optimizations for queries. For a query to take
advantage of these optimizations, Trino must have statistical information for
the tables in that query.
Table statistics are estimates about the stored data. They are provided to the
query planner by connectors and enable performance improvements for query
processing.

Available statistics#
The following statistics are available in Trino:

For a table:

row count: the total number of rows in the table


For each column in a table:

data size: the size of the data that needs to be read
nulls fraction: the fraction of null values
distinct value count: the number of distinct values
low value: the smallest value in the column
high value: the largest value in the column



The set of statistics available for a particular query depends on the connector
being used and can also vary by table. For example, the
Hive connector does not currently provide statistics on data size.
Table statistics can be displayed via the Trino SQL interface using the
SHOW STATS command.
Depending on the connector support, table statistics are updated by Trino when
executing data management statements like INSERT,
UPDATE, or DELETE. For example, the Delta Lake
connector, the Hive connector, and
the Iceberg connector all support table statistics
management from Trino.
You can also initialize statistics collection with the ANALYZE command.
This is needed when other systems manipulate the data without Trino, and
therefore statistics tracked by Trino are out of date. Other connectors rely on
the underlying data source to manage table statistics or do not support table
statistics use at all.
















 Previous  Query optimizer 



  Next  Cost in EXPLAIN 











































Cost in EXPLAIN — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Cost in EXPLAIN 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Table statistics



 Cost in EXPLAIN 
Cost in EXPLAIN






Cost-based optimizations


Pushdown


Adaptive plan optimizations



Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes



















Cost in EXPLAIN#
During planning, the cost associated with each node of the plan is computed
based on the table statistics for the tables in the query. This calculated
cost is printed as part of the output of an EXPLAIN statement.
Cost information is displayed in the plan tree using the format {rows: XX (XX), cpu: XX, memory: XX, network: XX}.  rows refers to the expected
number of rows output by each plan node during execution.  The value in the
parentheses following the number of rows refers to the expected size of the data
output by each plan node in bytes. Other parameters indicate the estimated
amount of CPU, memory, and network utilized by the execution of a plan node.
These values do not represent any actual unit, but are numbers that are used to
compare the relative costs between plan nodes, allowing the optimizer to choose
the best plan for executing a query. If any of the values is not known, a ?
is printed.
For example:
EXPLAIN SELECT comment FROM tpch.sf1.nation WHERE nationkey > 3;


- Output[comment] => [[comment]]
        Estimates: {rows: 22 (1.69kB), cpu: 6148.25, memory: 0.00, network: 1734.25}
    - RemoteExchange[GATHER] => [[comment]]
            Estimates: {rows: 22 (1.69kB), cpu: 6148.25, memory: 0.00, network: 1734.25}
        - ScanFilterProject[table = tpch:nation:sf1.0, filterPredicate = ("nationkey" > BIGINT '3')] => [[comment]]
                Estimates: {rows: 25 (1.94kB), cpu: 2207.00, memory: 0.00, network: 0.00}/{rows: 22 (1.69kB), cpu: 4414.00, memory: 0.00, network: 0.00}/{rows: 22 (1.69kB), cpu: 6148.25, memory: 0.00, network: 0.00}
                nationkey := tpch:nationkey
                comment := tpch:comment


Generally, there is only one cost printed for each plan node.  However, when a
Scan operator is combined with a Filter and/or Project operator,
then multiple cost structures are printed, each corresponding to an
individual logical part of the combined operator. For example, three cost
structures are printed for a ScanFilterProject operator, corresponding
to the Scan, Filter, and Project parts of the operator, in that order.
Estimated cost is also printed in EXPLAIN ANALYZE in addition to actual
runtime statistics.















 Previous  Table statistics 



  Next  Cost-based optimizations 











































Cost-based optimizations — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Cost-based optimizations 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Table statistics


Cost in EXPLAIN



 Cost-based optimizations 
Cost-based optimizations

Contents

Join enumeration

Join distribution selection

Capping replicated table size



Syntactic join order

Connector implementations





Pushdown


Adaptive plan optimizations



Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Join enumeration

Join distribution selection

Capping replicated table size



Syntactic join order

Connector implementations









Cost-based optimizations#
Trino supports several cost based optimizations, described below.

Join enumeration#
The order in which joins are executed in a query can have a significant impact
on the query’s performance. The aspect of join ordering that has the largest
impact on performance is the size of the data being processed and transferred
over the network. If a join which produces a lot of data is performed early in
the query’s execution, then subsequent stages need to process large amounts of
data for longer than necessary, increasing the time and resources needed for
processing the query.
With cost-based join enumeration, Trino uses Table statistics
provided by connectors to estimate the costs for different join orders and
automatically picks the join order with the lowest computed costs.
The join enumeration strategy is governed by the join_reordering_strategy
session property, with the
optimizer.join-reordering-strategy configuration property providing the
default value.
The possible values are:

AUTOMATIC (default) - enable full automatic join enumeration
ELIMINATE_CROSS_JOINS - eliminate unnecessary cross joins
NONE - purely syntactic join order

If you are using AUTOMATIC join enumeration and statistics are not
available or a cost can not be computed for any other reason, the
ELIMINATE_CROSS_JOINS strategy is used instead.


Join distribution selection#
Trino uses a hash-based join algorithm. For each join operator, a hash table
must be created from one join input, referred to as the build side. The other
input, called the probe side, is then iterated on. For each row, the hash table
is queried to find matching rows.
There are two types of join distributions:

Partitioned: each node participating in the query builds a hash table from
only a fraction of the data
Broadcast: each node participating in the query builds a hash table from all
of the data. The data is replicated to each node.

Each type has advantages and disadvantages. Partitioned joins require
redistributing both tables using a hash of the join key. These joins can be much
slower than broadcast joins, but they allow much larger joins overall. Broadcast
joins are faster if the build side is much smaller than the probe side. However,
broadcast joins require that the tables on the build side of the join after
filtering fit in memory on each node, whereas distributed joins only need to fit
in distributed memory across all nodes.
With cost-based join distribution selection, Trino automatically chooses whether
to use a partitioned or broadcast join. With cost-based join enumeration, Trino
automatically chooses which sides are probe and build.
The join distribution strategy is governed by the join_distribution_type
session property, with the join-distribution-type configuration property
providing the default value.
The valid values are:

AUTOMATIC (default) - join distribution type is determined automatically
for each join
BROADCAST - broadcast join distribution is used for all joins
PARTITIONED - partitioned join distribution is used for all join


Capping replicated table size#
The join distribution type is automatically chosen when the join reordering
strategy is set to AUTOMATIC or when the join distribution type is set to
AUTOMATIC. In both cases, it is possible to cap the maximum size of the
replicated table with the join-max-broadcast-table-size configuration
property or with the join_max_broadcast_table_size session property. This
allows you to improve cluster concurrency and prevent bad plans when the
cost-based optimizer misestimates the size of the joined tables.
By default, the replicated table size is capped to 100MB.



Syntactic join order#
If not using cost-based optimization, Trino defaults to syntactic join ordering.
While there is no formal way to optimize queries for this case, it is possible
to take advantage of how Trino implements joins to make them more performant.
Trino uses in-memory hash joins. When processing a join statement, Trino loads
the right-most table of the join into memory as the build side, then streams the
next right-most table as the probe side to execute the join. If a query has
multiple joins, the result of this first join stays in memory as the build side,
and the third right-most table is then used as the probe side, and so on for
additional joins. In the case where join order is made more complex, such as
when using parentheses to specify specific parents for joins, Trino may execute
multiple lower-level joins at once, but each step of that process follows the
same logic, and the same applies when the results are ultimately joined
together.
Because of this behavior, it is optimal to syntactically order joins in your SQL
queries from the largest tables to the smallest, as this minimizes memory usage.
As an example, if you have a small, medium, and large table and are using left
joins:
SELECT
  *
FROM
  large_table l
  LEFT JOIN medium_table m ON l.user_id = m.user_id
  LEFT JOIN small_table s ON s.user_id = l.user_id



Warning
This means of optimization is not a feature of Trino. It is an artifact of
how joins are implemented, and therefore this behavior may change without
notice.



Connector implementations#
In order for the Trino optimizer to use the cost based strategies,
the connector implementation must provide Table statistics.
















 Previous  Cost in EXPLAIN 



  Next  Pushdown 











































Pushdown — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Pushdown 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Table statistics


Cost in EXPLAIN


Cost-based optimizations



 Pushdown 
Pushdown

Contents

Predicate pushdown

Projection pushdown

Dereference pushdown

Aggregation pushdown

Limitations



Join pushdown

Limit pushdown

Top-N pushdown





Adaptive plan optimizations



Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Predicate pushdown

Projection pushdown

Dereference pushdown

Aggregation pushdown

Limitations



Join pushdown

Limit pushdown

Top-N pushdown









Pushdown#
Trino can push down the processing of queries, or parts of queries, into the
connected data source. This means that a specific predicate, aggregation
function, or other operation, is passed through to the underlying database or
storage system for processing.
The results of this pushdown can include the following benefits:

Improved overall query performance
Reduced network traffic between Trino and the data source
Reduced load on the remote data source

These benefits often result in significant cost reduction.
Support for pushdown is specific to each connector and the relevant underlying
database or storage system.

Predicate pushdown#
Predicate pushdown optimizes row-based filtering. It uses the inferred filter,
typically resulting from a condition in a WHERE clause to omit unnecessary
rows. The processing is pushed down to the data source by the connector and then
processed by the data source.
If predicate pushdown for a specific clause is successful, the EXPLAIN plan
for the query does not include a ScanFilterProject operation for that
clause.


Projection pushdown#
Projection pushdown optimizes column-based filtering. It uses the columns
specified in the SELECT clause and other parts of the query to limit access
to these columns. The processing is pushed down to the data source by the
connector and then the data source only reads and returns the necessary
columns.
If projection pushdown is successful, the EXPLAIN plan for the query only
accesses the relevant columns in the Layout of the TableScan operation.


Dereference pushdown#
Projection pushdown and dereference pushdown limit access to relevant columns,
except dereference pushdown is more selective. It limits access to only read the
specified fields within a top level or nested ROW data type.
For example, consider a table in the Hive connector that has a ROW type
column with several fields. If a query only accesses one field, dereference
pushdown allows the file reader to read only that single field within the row.
The same applies to fields of a row nested within the top level row. This can
result in significant savings in the amount of data read from the storage
system.


Aggregation pushdown#
Aggregation pushdown can take place provided the following conditions are satisfied:

If aggregation pushdown is generally supported by the connector.
If pushdown of the specific function or functions is supported by the connector.
If the query structure allows pushdown to take place.

You can check if pushdown for a specific query is performed by looking at the
EXPLAIN plan of the query. If an aggregate function is successfully
pushed down to the connector, the explain plan does not show that Aggregate operator.
The explain plan only shows the operations that are performed by Trino.
As an example, we loaded the TPC-H data set into a PostgreSQL database and then
queried it using the PostgreSQL connector:
SELECT regionkey, count(*)
FROM nation
GROUP BY regionkey;


You can get the explain plan by prepending the above query with EXPLAIN:
EXPLAIN
SELECT regionkey, count(*)
FROM nation
GROUP BY regionkey;


The explain plan for this query does not show any Aggregate operator with
the count function, as this operation is now performed by the connector. You
can see the count(*) function as part of the PostgreSQL TableScan
operator. This shows you that the pushdown was successful.
Fragment 0 [SINGLE]
    Output layout: [regionkey_0, _generated_1]
    Output partitioning: SINGLE []
    Output[regionkey, _col1]
    │   Layout: [regionkey_0:bigint, _generated_1:bigint]
    │   Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: ?}
    │   regionkey := regionkey_0
    │   _col1 := _generated_1
    └─ RemoteSource[1]
            Layout: [regionkey_0:bigint, _generated_1:bigint]

Fragment 1 [SOURCE]
    Output layout: [regionkey_0, _generated_1]
    Output partitioning: SINGLE []
    TableScan[postgresql:tpch.nation tpch.nation columns=[regionkey:bigint:int8, count(*):_generated_1:bigint:bigint] groupingSets=[[regionkey:bigint:int8]], gro
        Layout: [regionkey_0:bigint, _generated_1:bigint]
        Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: 0B}
        _generated_1 := count(*):_generated_1:bigint:bigint
        regionkey_0 := regionkey:bigint:int8


A number of factors can prevent a push down:

adding a condition to the query
using a different aggregate function that cannot be pushed down into the connector
using a connector without pushdown support for the specific function

As a result, the explain plan shows the Aggregate operation being performed
by Trino. This is a clear sign that now pushdown to the remote data source is not
performed, and instead Trino performs the aggregate processing.
Fragment 0 [SINGLE]
    Output layout: [regionkey, count]
    Output partitioning: SINGLE []
    Output[regionkey, _col1]
    │   Layout: [regionkey:bigint, count:bigint]
    │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
    │   _col1 := count
    └─ RemoteSource[1]
           Layout: [regionkey:bigint, count:bigint]

Fragment 1 [HASH]
    Output layout: [regionkey, count]
    Output partitioning: SINGLE []
    Aggregate(FINAL)[regionkey]
    │   Layout: [regionkey:bigint, count:bigint]
    │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
    │   count := count("count_0")
    └─ LocalExchange[HASH][$hashvalue] ("regionkey")
       │   Layout: [regionkey:bigint, count_0:bigint, $hashvalue:bigint]
       │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
       └─ RemoteSource[2]
              Layout: [regionkey:bigint, count_0:bigint, $hashvalue_1:bigint]

Fragment 2 [SOURCE]
    Output layout: [regionkey, count_0, $hashvalue_2]
    Output partitioning: HASH [regionkey][$hashvalue_2]
    Project[]
    │   Layout: [regionkey:bigint, count_0:bigint, $hashvalue_2:bigint]
    │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
    │   $hashvalue_2 := combine_hash(bigint '0', COALESCE("$operator$hash_code"("regionkey"), 0))
    └─ Aggregate(PARTIAL)[regionkey]
       │   Layout: [regionkey:bigint, count_0:bigint]
       │   count_0 := count(*)
       └─ TableScan[tpch:nation:sf0.01, grouped = false]
              Layout: [regionkey:bigint]
              Estimates: {rows: 25 (225B), cpu: 225, memory: 0B, network: 0B}
              regionkey := tpch:regionkey



Limitations#
Aggregation pushdown does not support a number of more complex statements:

complex grouping operations such as ROLLUP, CUBE, or GROUPING SETS
expressions inside the aggregation function call: sum(a * b)
coercions: sum(integer_column)
aggregations with ordering
aggregations with filter




Join pushdown#
Join pushdown allows the connector to delegate the table join operation to the
underlying data source. This can result in performance gains, and allows Trino
to perform the remaining query processing on a smaller amount of data.
The specifics for the supported pushdown of table joins varies for each data
source, and therefore for each connector.
However, there are some generic conditions that must be met in order for a join
to be pushed down:

all predicates that are part of the join must be possible to be pushed down
the tables in the join must be from the same catalog

You can verify if pushdown for a specific join is performed by looking at the
EXPLAIN  plan of the query. The explain plan does not
show a Join operator, if the join is pushed down to the data source by the
connector:
EXPLAIN SELECT c.custkey, o.orderkey
FROM orders o JOIN customer c ON c.custkey = o.custkey;


The following plan results from the PostgreSQL connector querying TPC-H
data in a PostgreSQL database. It does not show any Join operator as a
result of the successful join push down.
Fragment 0 [SINGLE]
    Output layout: [custkey, orderkey]
    Output partitioning: SINGLE []
    Output[custkey, orderkey]
    │   Layout: [custkey:bigint, orderkey:bigint]
    │   Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: ?}
    └─ RemoteSource[1]
           Layout: [orderkey:bigint, custkey:bigint]

Fragment 1 [SOURCE]
    Output layout: [orderkey, custkey]
    Output partitioning: SINGLE []
    TableScan[postgres:Query[SELECT l."orderkey" AS "orderkey_0", l."custkey" AS "custkey_1", r."custkey" AS "custkey_2" FROM (SELECT "orderkey", "custkey" FROM "tpch"."orders") l INNER JOIN (SELECT "custkey" FROM "tpch"."customer") r O
        Layout: [orderkey:bigint, custkey:bigint]
        Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: 0B}
        orderkey := orderkey_0:bigint:int8
        custkey := custkey_1:bigint:int8


It is typically beneficial to push down a join. Pushing down a join can also
increase the row count compared to the size of the input to the join. This
may impact performance.


Limit pushdown#
A LIMIT or FETCH FIRST clause reduces the number of returned records for a statement.
Limit pushdown enables a connector to push processing of such queries of
unsorted record to the underlying data source.
A pushdown of this clause can improve the performance of the query and
significantly reduce the amount of data transferred from the data source to
Trino.
Queries include sections such as LIMIT N or FETCH FIRST N ROWS.
Implementation and support is connector-specific since different data sources have varying capabilities.


Top-N pushdown#
The combination of a LIMIT or FETCH FIRST clause with an ORDER BY clause creates
a small set of records to return out of a large sorted dataset. It relies on the
order to determine which records need to be returned, and is therefore quite
different to optimize compared to a Limit pushdown.
The pushdown for such a query is called a Top-N pushdown, since the operation is
returning the top N rows. It enables a connector to push processing of such
queries to the underlying data source, and therefore significantly reduces the
amount of data transferred to and processed by Trino.
Queries include sections such as ORDER BY ... LIMIT N or ORDER BY ... FETCH FIRST N ROWS.
Implementation and support is connector-specific since different data sources
support different SQL syntax and processing.
For example, you can find two queries to learn how to identify Top-N pushdown behavior in the following section.
First, a concrete example of a Top-N pushdown query on top of a PostgreSQL database:
SELECT id, name
FROM postgresql.public.company
ORDER BY id
LIMIT 5;


You can get the explain plan by prepending the above query with EXPLAIN:
EXPLAIN SELECT id, name
FROM postgresql.public.company
ORDER BY id
LIMIT 5;


Fragment 0 [SINGLE]
    Output layout: [id, name]
    Output partitioning: SINGLE []
    Stage Execution Strategy: UNGROUPED_EXECUTION
    Output[id, name]
    │   Layout: [id:integer, name:varchar]
    │   Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: ?}
    └─ RemoteSource[1]
           Layout: [id:integer, name:varchar]

Fragment 1 [SOURCE]
    Output layout: [id, name]
    Output partitioning: SINGLE []
    Stage Execution Strategy: UNGROUPED_EXECUTION
    TableScan[postgresql:public.company public.company sortOrder=[id:integer:int4 ASC NULLS LAST] limit=5, grouped = false]
        Layout: [id:integer, name:varchar]
        Estimates: {rows: ? (?), cpu: ?, memory: 0B, network: 0B}
        name := name:varchar:text
        id := id:integer:int4


Second, an example of a Top-N query on the tpch connector which does not support
Top-N pushdown functionality:
SELECT custkey, name
FROM tpch.sf1.customer
ORDER BY custkey
LIMIT 5;


The related query plan:
Fragment 0 [SINGLE]
    Output layout: [custkey, name]
    Output partitioning: SINGLE []
    Stage Execution Strategy: UNGROUPED_EXECUTION
    Output[custkey, name]
    │   Layout: [custkey:bigint, name:varchar(25)]
    │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
    └─ TopN[5 by (custkey ASC NULLS LAST)]
       │   Layout: [custkey:bigint, name:varchar(25)]
       └─ LocalExchange[SINGLE] ()
          │   Layout: [custkey:bigint, name:varchar(25)]
          │   Estimates: {rows: ? (?), cpu: ?, memory: ?, network: ?}
          └─ RemoteSource[1]
                 Layout: [custkey:bigint, name:varchar(25)]

Fragment 1 [SOURCE]
    Output layout: [custkey, name]
    Output partitioning: SINGLE []
    Stage Execution Strategy: UNGROUPED_EXECUTION
    TopNPartial[5 by (custkey ASC NULLS LAST)]
    │   Layout: [custkey:bigint, name:varchar(25)]
    └─ TableScan[tpch:customer:sf1.0, grouped = false]
           Layout: [custkey:bigint, name:varchar(25)]
           Estimates: {rows: 150000 (4.58MB), cpu: 4.58M, memory: 0B, network: 0B}
           custkey := tpch:custkey
           name := tpch:name


In the preceding query plan, the Top-N operation TopN[5 by (custkey ASC NULLS LAST)]
is being applied in the Fragment 0 by Trino and not by the source database.
Note that, compared to the query executed on top of the tpch connector,
the explain plan of the query applied on top of the postgresql connector
is missing the reference to the operation TopN[5 by (id ASC NULLS LAST)]
in the Fragment 0.
The absence of the TopN Trino operator in the Fragment 0 from the query plan
demonstrates that the query benefits of the Top-N pushdown optimization.
















 Previous  Cost-based optimizations 



  Next  Adaptive plan optimizations 











































Adaptive plan optimizations — Trino 474 Documentation





























 Skip to content 














Trino 474 Documentation
 Adaptive plan optimizations 











        
      





            Type to start searching
          
















    Trino
  




















Trino 474 Documentation









    Trino
  




Overview


Installation


Clients


Security


Administration


Query optimizer


Table statistics


Cost in EXPLAIN


Cost-based optimizations


Pushdown



 Adaptive plan optimizations 
Adaptive plan optimizations

Contents

Adaptive reordering of partitioned joins






Connectors


Object storage


Functions and operators


User-defined functions


SQL language


SQL statement syntax


Developer guide


Glossary


Appendix


Release notes










Contents

Adaptive reordering of partitioned joins









Adaptive plan optimizations#
Trino offers several adaptive plan optimizations that adjust query
execution plans dynamically based on runtime statistics. These
optimizations are only available when
Fault-tolerant execution is enabled.
To deactivate all adaptive plan optimizations, set the
fault-tolerant-execution-adaptive-query-planning-enabled
configuration property to false. The equivalent session property is
fault_tolerant_execution_adaptive_query_planning_enabled.

Adaptive reordering of partitioned joins#
By default, Trino enables adaptive reordering of partitioned joins. This
optimization allows Trino to dynamically reorder the join inputs, based
on the actual size of the build and probe sides during query execution.
This is particularly useful when table statistics are not available
beforehand, as it can improve query performance by making more efficient
join order decisions based on runtime information.
To deactivate this optimization, set the
fault-tolerant-execution-adaptive-join-reordering-enabled
configuration property to false. The equivalent session property is
fault_tolerant_execution_adaptive_join_reordering_enabled.
















 Previous  Pushdown 



  Next  Connectors 
















